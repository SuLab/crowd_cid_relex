{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the chemical highlighting abilities of tmChem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2015-06-16 Tong Shu Li"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our crowdsourcing approach relies upon being able to exhaustively annotate all chemical annotations in the original raw text. Here we test to see how well tmChem can annotate chemicals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/toby/Code/util\")\n",
    "from file_util import read_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We first take the data for biocreative V and strip it down to the original raw text:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"data/tmchem_training.txt\", \"w\") as out:\n",
    "    for line in read_file(\"data/training/CDR_TrainingSet.txt\"):\n",
    "        vals = line.split('|')\n",
    "        if len(vals) == 3 or len(line) == 0:\n",
    "            out.write(\"{0}\\n\".format(\"|\".join(vals)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Development data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"data/tmchem_development.txt\", \"w\") as out:\n",
    "    for line in read_file(\"data/development/CDR_DevelopmentSet.txt\"):\n",
    "        vals = line.split('|')\n",
    "        if len(vals) == 3 or len(line) == 0:\n",
    "            out.write(\"{0}\\n\".format(\"|\".join(vals)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run tmChem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% mv data/tmchem_*.txt ~/Code/tmChem/tmChem/input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/toby/Code/tmChem/tmChem\n"
     ]
    }
   ],
   "source": [
    "% cd ~/Code/tmChem/tmChem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/home/toby/Code/tmChem/tmChem'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "% pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input format: PubTator\n",
      "Running tmChem on 500 docs in tmchem_training.txt ... Finished in 56 seconds. \n",
      "Input format: PubTator\n",
      "Running tmChem on 500 docs in tmchem_development.txt ... Finished in 57 seconds. \n"
     ]
    }
   ],
   "source": [
    "! perl tmChem.pl -i input -o output Model/All.Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% mv output/*.tmChem ~/Research/Projects/biocreativeV/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/toby/Research/Projects/biocreativeV\n"
     ]
    }
   ],
   "source": [
    "% cd ~/Research/Projects/biocreativeV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/home/toby/Research/Projects/biocreativeV'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "% pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our representations of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Annotation:\n",
    "    def __init__(self, uid, stype, text, start, stop):\n",
    "        if uid.startswith(\"MESH:\"):\n",
    "            uid = uid[5 : ]\n",
    "        \n",
    "        self.uid = uid\n",
    "        self.stype = stype.lower()\n",
    "        assert self.stype in [\"chemical\", \"disease\"]\n",
    "        self.text = text\n",
    "        self.start = int(start)\n",
    "        self.stop = int(stop)\n",
    "        assert self.start < self.stop\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, self.__class__):\n",
    "            return self.__dict__ == other.__dict__\n",
    "            \n",
    "        return False\n",
    "    \n",
    "    def __ne__(self, other):\n",
    "        return not self.__eq__(other)\n",
    "        \n",
    "    def output(self):\n",
    "        print self.uid\n",
    "        print self.start\n",
    "        print self.stop\n",
    "        print self.text\n",
    "        print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Relation:\n",
    "    def __init__(self, drug, disease):\n",
    "        assert drug != \"-1\"\n",
    "        assert disease != \"-1\"\n",
    "        self.drug = drug\n",
    "        self.disease = disease\n",
    "        \n",
    "    def output(self):\n",
    "        print self.drug, self.disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_annotations(annotations):\n",
    "    \"\"\"\n",
    "    Annotations with an identifier of -1 or with\n",
    "    no known identifier are ignored because they\n",
    "    never show up in a relationship.\n",
    "    \n",
    "    Ignored for comparision too for the above\n",
    "    reason.\n",
    "    \"\"\"\n",
    "    chemicals = []\n",
    "    diseases = []\n",
    "    \n",
    "    for group in annotations:\n",
    "        if group[5] != \"-1\":\n",
    "            res = Annotation(group[5], group[4], group[3], group[1], group[2])\n",
    "            if res.stype == \"chemical\":\n",
    "                chemicals.append(res)\n",
    "            else:\n",
    "                diseases.append(res)\n",
    "                \n",
    "    return (chemicals, diseases)\n",
    "\n",
    "def make_relations(relations):\n",
    "    res = []\n",
    "    for group in relations:\n",
    "        res.append(Relation(group[2], group[3]))\n",
    "    \n",
    "    return res\n",
    "        \n",
    "class Paper:\n",
    "    def __init__(self, pmid, title, abstract, annotations, relations):\n",
    "        self.pmid = pmid\n",
    "        self.title = title\n",
    "        self.abstract = abstract\n",
    "        \n",
    "        self.chemicals, self.diseases = make_annotations(annotations)\n",
    "        self.relations = make_relations(relations)\n",
    "        \n",
    "    def output(self):\n",
    "        print self.pmid\n",
    "        print len(self.annotations), len(self.relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_input(loc, fname):\n",
    "    \"\"\"\n",
    "    Parses the given input file and returns a list\n",
    "    of Paper objects.\n",
    "    \"\"\"\n",
    "    papers = []\n",
    "\n",
    "    counter = 0\n",
    "    annotations = []\n",
    "    relations = []\n",
    "    for i, line in enumerate(read_file(fname, loc)):\n",
    "        if len(line) == 0:\n",
    "            # time to finish up this paper and prepare a new one\n",
    "            papers.append(Paper(pmid, title, abstract, annotations, relations))\n",
    "\n",
    "            counter = 0\n",
    "\n",
    "            annotations = []\n",
    "            relations = []\n",
    "        else:\n",
    "            if 0 <= counter <= 1:\n",
    "                vals = line.split('|')\n",
    "                assert len(vals) == 3\n",
    "            else:\n",
    "                vals = line.split('\\t')\n",
    "\n",
    "            if counter == 0:\n",
    "                assert vals[1] == 't'\n",
    "                pmid = vals[0]            \n",
    "                title = vals[2]\n",
    "            elif counter == 1:\n",
    "                assert vals[1] == 'a'\n",
    "                abstract = vals[2]\n",
    "            elif len(vals) == 4:\n",
    "                relations.append(vals)\n",
    "            else:\n",
    "                assert 5 <= len(vals) <= 7, pmid\n",
    "                # 5 fields means it determined that the text span\n",
    "                # was a chemical, but could not assign an identifier\n",
    "                \n",
    "                # 7 means it was a mistake in the original input (extra tab)\n",
    "                # 6 is the ideal output\n",
    "                \n",
    "                if len(vals) == 5:\n",
    "                    vals.append(\"-1\")\n",
    "                \n",
    "                annotations.append(vals) # 6 or 7 fields\n",
    "\n",
    "            counter += 1\n",
    "            \n",
    "    return papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab tmChem's output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmchem_training = parse_input(\"data\", \"tmchem_training.txt.tmChem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmchem_development = parse_input(\"data\", \"tmchem_development.txt.tmChem\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab the gold standard data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gold_training = parse_input(\"data/training\", \"CDR_TrainingSet.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gold_development = parse_input(\"data/development\", \"CDR_DevelopmentSet.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the performance of tmChem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def results(program_output, gold_std_data):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    sum_chemicals = 0\n",
    "    for p_data, gold_std in zip(program_output, gold_std_data):\n",
    "        assert p_data.pmid == gold_std.pmid\n",
    "\n",
    "        # check tmChem's output against the gold standard\n",
    "\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        for annot in p_data.chemicals:\n",
    "            if annot in gold_std.chemicals:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "\n",
    "        sum_chemicals += len(gold_std.chemicals)\n",
    "        TP += tp\n",
    "        FP += fp\n",
    "\n",
    "    print \"recall: {0}\".format(TP / sum_chemicals)\n",
    "    print \"precision: {0}\".format(TP / (TP + FP))\n",
    "\n",
    "    print \"TP: {0}\".format(TP)\n",
    "    print \"FP: {0}\".format(FP)\n",
    "    print \"all gold annotations: {0}\".format(sum_chemicals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: 0.984350850077\n",
      "precision: 0.993952399532\n",
      "TP: 5095\n",
      "FP: 31\n",
      "all gold annotations: 5176\n"
     ]
    }
   ],
   "source": [
    "results(tmchem_training, gold_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: 0.812028657617\n",
      "precision: 0.940803844474\n",
      "TP: 4307\n",
      "FP: 271\n",
      "all gold annotations: 5304\n"
     ]
    }
   ],
   "source": [
    "results(tmchem_development, gold_development)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In conclusion, it looks like tmChem does pretty well at identifying the chemicals in a piece of text. The recall is a lot lower on the development set, but is still high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we really were worried about recall, then we could always add more concept recognizers to drive up total recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for the development set, look at the loss of recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
