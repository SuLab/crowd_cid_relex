{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caching abstract section headings\n",
    "\n",
    "Tong Shu Li<br>\n",
    "Created on Wednesday 2015-07-22<br>\n",
    "Last updated: 2015-08-21\n",
    "\n",
    "For the abstract-level chemical-induced disease relation extraction task, we want to format the text into sections ([like PMID 20003049](http://www.ncbi.nlm.nih.gov/pubmed/?term=20003049%5Buid%5D)) to make it easier for the workers to read. Previously this was done by querying PubMed for the paper directly, and using the returned information to format the text.\n",
    "\n",
    "Since the input text is supposed to be treated as free text, we cannot use the PubMed querying method to determine the section headings. Instead, we will query PubMed for the section names of every abstract in the training and development data, and use the cached section headings to parse any new input. We of course will miss some, but assume that those papers will be infrequent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import xml.etree.cElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from src.lingpipe.file_util import read_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the training and development data to grab all the PMIDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_pmids(fname):\n",
    "    pmids = set()\n",
    "    for line in read_file(fname):\n",
    "        vals = line.split('|')\n",
    "        if len(vals) == 3 and vals[1] in ['a', 't']:\n",
    "            pmids.add(vals[0])\n",
    "            \n",
    "    return pmids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = \"data/training/CDR_TrainingSet.txt\"\n",
    "trainingset = parse_pmids(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainingset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = \"data/development/CDR_DevelopmentSet.txt\"\n",
    "developmentset = parse_pmids(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(developmentset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query PubMed for the section names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def query_ncbi(tool, settings):\n",
    "    BASE = \"http://eutils.ncbi.nlm.nih.gov/entrez/eutils/{0}\".format(tool)\n",
    "    resp = requests.get(BASE, params = settings)\n",
    "    assert resp.status_code == requests.codes.ok\n",
    "    return resp.text\n",
    "\n",
    "def get_pubmed_article_xml_tree(pubmed_id):\n",
    "    response = query_ncbi(\"efetch.fcgi\",\n",
    "                          {\"db\": \"pubmed\", \"id\": pubmed_id, \"rettype\": \"abstract\"})\n",
    "\n",
    "    return ET.fromstring(response)\n",
    "\n",
    "def parse_article_xml_tree(article_xml_tree):\n",
    "    \"\"\"Return title as a unicode string, and abstract as an Element\"\"\"\n",
    "    for element in article_xml_tree.iter(\"ArticleTitle\"):\n",
    "        article_title = element.text\n",
    "        break\n",
    "\n",
    "    for element in article_xml_tree.iter():\n",
    "        if element.tag == \"Abstract\":\n",
    "            return (article_title, element)\n",
    "\n",
    "    return (article_title, False) # no abstract, title only\n",
    "\n",
    "def get_section_labels(abstract_xml_tree):\n",
    "    \"\"\"Split an abstract XML tree into individual chunks, if they exist.\n",
    "\n",
    "    Preserves the background/methods/etc format of some papers (eg pmid 24885308)\n",
    "    \"\"\"\n",
    "    section_labels = set()\n",
    "    for child in abstract_xml_tree.iter(\"AbstractText\"):\n",
    "        section_name = child.get(\"Label\")\n",
    "        \n",
    "        if section_name is not None and section_name != \"UNLABELLED\":\n",
    "            section_labels.add(section_name)\n",
    "            \n",
    "    return section_labels\n",
    "\n",
    "def get_abstract_information(pubmed_id):\n",
    "    article_xml_tree = get_pubmed_article_xml_tree(pubmed_id)\n",
    "    title, abstract_xml_tree = parse_article_xml_tree(article_xml_tree)\n",
    "\n",
    "    if abstract_xml_tree:\n",
    "        return get_section_labels(abstract_xml_tree)\n",
    "    \n",
    "    return set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query all section names and write to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_section_labels(dataset):\n",
    "    res = set()\n",
    "    for i, pmid in enumerate(dataset):\n",
    "        res |= get_abstract_information(pmid)\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_labels = get_all_section_labels(trainingset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dev_labels = get_all_section_labels(developmentset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_section_labels = train_labels | dev_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_section_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"data/all_uniq_section_names.txt\", \"w\") as fout:\n",
    "    temp = sorted(list(all_section_labels))\n",
    "    for name in temp:\n",
    "        v = fout.write(\"{0}\\n\".format(name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
