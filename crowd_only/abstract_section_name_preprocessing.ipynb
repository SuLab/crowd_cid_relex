{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Determining abstract section headings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tong Shu Li<br>\n",
    "Created on Wednesday 2015-07-22<br>\n",
    "Last updated 2015-07-22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the abstract-level chemical-induced disease relation extraction task, we want to format the text into sections ([like PMID 20003049](http://www.ncbi.nlm.nih.gov/pubmed/?term=20003049%5Buid%5D)) to make it easier for the workers to read. Since we are treating the input text as freetext, we cannot use PubMed to determine the section headings.\n",
    "\n",
    "What we will do instead is query PubMed for the section names of every abstract in the 1000 abstracts of the training data, and use those to parse any new input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from src.file_util import read_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Preprocess the training and development data to grab all the PMIDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_pmids(fname):\n",
    "    pmids = set()\n",
    "    for line in read_file(fname):\n",
    "        vals = line.split('|')\n",
    "        if len(vals) == 3 and vals[1] in ['a', 't']:\n",
    "            pmids.add(vals[0])\n",
    "            \n",
    "    return pmids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = \"data/training/CDR_TrainingSet.txt\"\n",
    "trainingset = parse_pmids(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainingset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = \"data/development/CDR_DevelopmentSet.txt\"\n",
    "developmentset = parse_pmids(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(developmentset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Function for grabbing the section names from PubMed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# last updated 2015-06-12 toby\n",
    "import sys\n",
    "sys.path.append(\"/home/toby/Code/util/\")\n",
    "from convert import query_ncbi\n",
    "\n",
    "import xml.etree.cElementTree as ET\n",
    "from unicode_to_ascii import convert_unicode_to_ascii\n",
    "\n",
    "def get_pubmed_article_xml_tree(pubmed_id):\n",
    "    request = \"efetch.fcgi?db=pubmed&id={0}&rettype=abstract\".format(pubmed_id)\n",
    "    response = query_ncbi(request)\n",
    "    return ET.fromstring(response)\n",
    "\n",
    "def parse_article_xml_tree(article_xml_tree):\n",
    "    \"\"\"Returns title as a unicode string, and abstract as an Element\"\"\"\n",
    "    for element in article_xml_tree.iter(\"ArticleTitle\"):\n",
    "        article_title = element.text\n",
    "        break\n",
    "\n",
    "    for element in article_xml_tree.iter():\n",
    "        if element.tag == \"Abstract\":\n",
    "            return (article_title, element)\n",
    "\n",
    "    return (article_title, False) # no abstract, title only\n",
    "\n",
    "def get_section_labels(abstract_xml_tree):\n",
    "    \"\"\"\n",
    "    Splits an abstract XML tree into individual chunks, if they exist.\n",
    "\n",
    "    Preserves the background/methods/etc format of some papers (eg pmid 24885308)\n",
    "    \"\"\"\n",
    "    section_labels = set()\n",
    "    for child in abstract_xml_tree.iter(\"AbstractText\"):\n",
    "        section_name = child.get(\"Label\")\n",
    "        \n",
    "        if section_name is not None and section_name != \"UNLABELLED\":\n",
    "            section_labels.add(section_name)\n",
    "            \n",
    "    return section_labels\n",
    "\n",
    "def get_abstract_information(pubmed_id):\n",
    "    article_xml_tree = get_pubmed_article_xml_tree(pubmed_id)\n",
    "    title, abstract_xml_tree = parse_article_xml_tree(article_xml_tree)\n",
    "\n",
    "    if abstract_xml_tree:\n",
    "        return get_section_labels(abstract_xml_tree)\n",
    "    \n",
    "    return set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_section_labels(fname, dataset, limit = -1):\n",
    "    for i, pmid in enumerate(dataset):\n",
    "        if i == limit:\n",
    "            break\n",
    "            \n",
    "        if i % 100 == 0:\n",
    "            print i\n",
    "            \n",
    "        sections = get_abstract_information(pmid)\n",
    "        with open(fname, \"a\") as fout:\n",
    "            for section_name in sections:\n",
    "                fout.write(\"{0}\\n\".format(section_name))\n",
    "            \n",
    "    print \"done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Getting the section names for all 1000 abstracts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "get_all_section_labels(\"data/training_section_names.txt\", trainingset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "get_all_section_labels(\"data/development_section_names.txt\", developmentset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Creating the unique set of section names for future use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def uniq_section_names(fname):\n",
    "    names = set()\n",
    "    for line in read_file(fname):\n",
    "        names.add(line)\n",
    "        \n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dev_names = uniq_section_names(\"data/development_section_names.txt\")\n",
    "train_names = uniq_section_names(\"data/training_section_names.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_names = dev_names | train_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"data/all_uniq_section_names.txt\", \"w\") as fout:\n",
    "    temp = sorted(list(all_names))\n",
    "    for name in temp:\n",
    "        fout.write(\"{0}\\n\".format(name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
