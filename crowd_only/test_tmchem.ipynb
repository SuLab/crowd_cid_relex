{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the chemical highlighting abilities of tmChem\n",
    "\n",
    "Tong Shu Li<br>\n",
    "Created on: 2015-06-16<br>\n",
    "Last updated: 2015-08-21\n",
    "\n",
    "Our crowdsourcing approach relies upon being able to exhaustively annotate all chemical annotations in the original raw text. Here we test to see how well tmChem can annotate chemicals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from src.lingpipe.file_util import read_file\n",
    "from src.data_model import parse_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strip the gold standard down to raw text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def strip_file(fin_loc, fout_loc):\n",
    "    with open(fout_loc, \"w\") as fout:\n",
    "        for line in read_file(fin_loc):\n",
    "            if len(line) == 0:\n",
    "                fout.write(\"\\n\")\n",
    "            elif (len(line) > 0) and (\"|\" in line) and (line.split(\"|\")[1] in [\"t\", \"a\"]):\n",
    "                fout.write(\"{0}\\n\".format(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "strip_file(\"data/training/CDR_TrainingSet.txt\", \"data/tmchem/tmchem_training.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "strip_file(\"data/development/CDR_DevelopmentSet.txt\", \"data/tmchem/tmchem_development.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run tmChem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input format: PubTator\n",
      "Running tmChem on 500 docs in tmchem_training.txt ...\r",
      "Running tmChem on 500 docs in tmchem_training.txt ... Finished in 61 seconds. \n",
      "Input format: PubTator\n",
      "Running tmChem on 500 docs in tmchem_development.txt ...\r",
      "Running tmChem on 500 docs in tmchem_development.txt ... Finished in 63 seconds. \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# move things to the correct directory\n",
    "cur_path=$(pwd)\n",
    "cp data/tmchem/tmchem_*.txt src/tmChem.M2.ver02/input\n",
    "cd src/tmChem.M2.ver02\n",
    "\n",
    "# run tmChem\n",
    "perl tmChem.pl -i input -o output Model/All.Model\n",
    "\n",
    "# move results back\n",
    "rm input/*.txt\n",
    "mv output/*.tmChem $cur_path/data/tmchem\n",
    "cd $cur_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the gold standard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gold_train = parse_input(\"data/training\", \"CDR_TrainingSet.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gold_dev = parse_input(\"data/development\", \"CDR_DevelopmentSet.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read tmChem's output, with and without acronym resolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmchem_train_raw = parse_input(\"data/tmchem\", \"tmchem_training.txt.tmChem\",\n",
    "                              is_gold = False, return_format = \"list\", fix_acronyms = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmchem_train_fixed = parse_input(\"data/tmchem\", \"tmchem_training.txt.tmChem\",\n",
    "                              is_gold = False, return_format = \"list\", fix_acronyms = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmchem_dev_raw = parse_input(\"data/tmchem\", \"tmchem_development.txt.tmChem\",\n",
    "                              is_gold = False, return_format = \"list\", fix_acronyms = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmchem_dev_fixed = parse_input(\"data/tmchem\", \"tmchem_development.txt.tmChem\",\n",
    "                              is_gold = False, return_format = \"list\", fix_acronyms = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine performance against gold standard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def results(program_output, gold_data):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    sum_chemicals = 0\n",
    "    \n",
    "    for prog_data, gold_std in zip(program_output, gold_data):\n",
    "        assert prog_data.pmid == gold_std.pmid\n",
    "        \n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        for prog_annot in prog_data.annotations:\n",
    "            if prog_annot.stype == \"chemical\":\n",
    "                for gold_annot in gold_std.annotations:\n",
    "                    if prog_annot.stype == \"chemical\":\n",
    "                        if (prog_annot.text == gold_annot.text\n",
    "                            and prog_annot.start == gold_annot.start\n",
    "                            and prog_annot.stop == gold_annot.stop):\n",
    "                            \n",
    "                            p = {v for v in prog_annot.uid if v.uid_type == \"MESH\"}\n",
    "                            g = {v for v in gold_annot.uid if v.uid_type == \"MESH\"}\n",
    "                            \n",
    "                            if p == g:\n",
    "                                tp += 1\n",
    "                            else:\n",
    "                                fp += 1\n",
    "                            \n",
    "        for gold_annot in gold_std.annotations:\n",
    "            if gold_annot.stype == \"chemical\":\n",
    "                sum_chemicals += 1\n",
    "                \n",
    "        TP += tp\n",
    "        FP += fp\n",
    "        \n",
    "    recall = TP / sum_chemicals\n",
    "    precision = TP / (TP + FP)\n",
    "    \n",
    "    f_score = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    print(\"F score:\", f_score)\n",
    "\n",
    "    print(\"recall: {0}\".format(TP / sum_chemicals))\n",
    "    print(\"precision: {0}\".format(TP / (TP + FP)))\n",
    "\n",
    "    print(\"TP: {0}\".format(TP))\n",
    "    print(\"FP: {0}\".format(FP))\n",
    "    print(\"all gold annotations: {0}\".format(sum_chemicals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tmChem results without acronym resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F score: 0.9924608544364972\n",
      "recall: 0.9867384201422257\n",
      "precision: 0.9982500486097609\n",
      "TP: 5134\n",
      "FP: 9\n",
      "all gold annotations: 5203\n"
     ]
    }
   ],
   "source": [
    "results(tmchem_train_raw, gold_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F score: 0.8776680771039022\n",
      "recall: 0.8728258836730877\n",
      "precision: 0.8825642965204236\n",
      "TP: 4667\n",
      "FP: 621\n",
      "all gold annotations: 5347\n"
     ]
    }
   ],
   "source": [
    "results(tmchem_dev_raw, gold_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tmChem results with acronym resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F score: 0.9924608544364972\n",
      "recall: 0.9867384201422257\n",
      "precision: 0.9982500486097609\n",
      "TP: 5134\n",
      "FP: 9\n",
      "all gold annotations: 5203\n"
     ]
    }
   ],
   "source": [
    "results(tmchem_train_fixed, gold_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F score: 0.9348377997179126\n",
      "recall: 0.9296801945015897\n",
      "precision: 0.9400529500756429\n",
      "TP: 4971\n",
      "FP: 317\n",
      "all gold annotations: 5347\n"
     ]
    }
   ],
   "source": [
    "results(tmchem_dev_fixed, gold_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "tmChem performs very well on the training set. Performance on the development set is lower, but still respectable. Acronym resolution makes no difference for the training set, but improves F-score by 0.05 (a significant amount) for the development set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
