{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worker clustering for job 758438\n",
    "\n",
    "Tong Shu Li<br>\n",
    "Created on Thursday 2015-08-06<br>\n",
    "Last updated: 2015-08-06"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we try to calculate Cohen's Kappa for each pair of workers for job #758438. We then use the Kappa to try and cluster workers by agreement. Our hope is to determine clusters of workers who are likely to be cheaters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from collections import defaultdict\n",
    "from itertools import combinations_with_replacement\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\"data/crowdflower/results/job_758438_full_with_untrusted.csv\", sep = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kappa_matrix(worker_id_col, resp_col, poss_resp, raw_data):\n",
    "    \"\"\"\n",
    "    Given a dataframe representing the choices of multiple workers\n",
    "    on a categorization task with mutually exclusive categories,\n",
    "    this function calculates the Cohen's kappa for each unique\n",
    "    pair of workers.\n",
    "    \n",
    "    worker_id_col = column with unique worker ids\n",
    "    resp_col = column with the worker responses\n",
    "    poss_resp = set of all possible responses in the resp_col\n",
    "    \"\"\"\n",
    "    # for each worker determine which question ids they chose for each possible response\n",
    "    worker_resp = defaultdict(dict)\n",
    "    for worker_id, user_work in raw_data.groupby(worker_id_col):\n",
    "        for resp_choice in poss_resp:\n",
    "            sub = user_work.query(\"{0} == '{1}'\".format(resp_col, resp_choice))\n",
    "            work_ids = set(sub[\"uniq_id\"])\n",
    "            worker_resp[worker_id][resp_choice] = work_ids\n",
    "\n",
    "    # calculate kappa matrix\n",
    "    kappa = defaultdict(dict)\n",
    "    all_workers = set(raw_data[worker_id_col])\n",
    "    for worker_A, worker_B in combinations_with_replacement(all_workers, 2):\n",
    "        # for all unique worker pairs\n",
    "        if worker_A == worker_B:\n",
    "            kappa[worker_A][worker_A] = 1\n",
    "            continue\n",
    "        \n",
    "        # find work done by each worker (including test questions)\n",
    "        work_A = raw_data.query(\"{0} == {1}\".format(worker_id_col, worker_A))\n",
    "        work_B = raw_data.query(\"{0} == {1}\".format(worker_id_col, worker_B))\n",
    "        \n",
    "        work_A_ids = set(work_A[\"uniq_id\"])\n",
    "        work_B_ids = set(work_B[\"uniq_id\"])\n",
    "        \n",
    "        in_common = work_A_ids & work_B_ids\n",
    "        if not in_common:\n",
    "            # no way to calculate agreement\n",
    "            kappa[worker_A][worker_B] = np.nan\n",
    "            kappa[worker_B][worker_A] = np.nan\n",
    "        else:\n",
    "            common_work = raw_data.query(\"uniq_id in {0}\".format(list(in_common)))\n",
    "            \n",
    "            # size of work units both A and B worked on\n",
    "            M = len(in_common)\n",
    "            \n",
    "            # determine how many work units both workers agreed upon\n",
    "            agree = 0\n",
    "            for resp_choice in poss_resp:\n",
    "                agree += len(worker_resp[worker_A][resp_choice] & worker_resp[worker_B][resp_choice])\n",
    "                \n",
    "            assert agree <= M\n",
    "            p_naught = agree / M\n",
    "            \n",
    "            A_resp = common_work.query(\"{0} == {1}\".format(worker_id_col, worker_A))\n",
    "            A_distribution = A_resp[resp_col].value_counts(normalize = True)\n",
    "            \n",
    "            B_resp = common_work.query(\"{0} == {1}\".format(worker_id_col, worker_B))\n",
    "            B_distribution = B_resp[resp_col].value_counts(normalize = True)\n",
    "            \n",
    "            # using python sum() if nan exists converts answer to nan\n",
    "            p_e = (A_distribution * B_distribution).sum()\n",
    "            \n",
    "            val = (p_naught - p_e) / (1 - p_e)\n",
    "            kappa[worker_A][worker_B] = val\n",
    "            kappa[worker_B][worker_A] = val\n",
    "            \n",
    "    return pd.DataFrame(kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "responses = {\"yes_direct\", \"yes_indirect\", \"no_relation\", \"ner_mistake\"}\n",
    "ans = kappa_matrix(\"_worker_id\", \"verify_relationship\", responses, raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>33081299</th>\n",
       "      <th>33081469</th>\n",
       "      <th>33301062</th>\n",
       "      <th>33387828</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33081299</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.932345</td>\n",
       "      <td>0.938906</td>\n",
       "      <td>0.621318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33081469</th>\n",
       "      <td>0.932345</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.917081</td>\n",
       "      <td>0.425150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33301062</th>\n",
       "      <td>0.938906</td>\n",
       "      <td>0.917081</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.433298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33387828</th>\n",
       "      <td>0.621318</td>\n",
       "      <td>0.425150</td>\n",
       "      <td>0.433298</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          33081299  33081469  33301062  33387828\n",
       "33081299  1.000000  0.932345  0.938906  0.621318\n",
       "33081469  0.932345  1.000000  0.917081  0.425150\n",
       "33301062  0.938906  0.917081  1.000000  0.433298\n",
       "33387828  0.621318  0.425150  0.433298  1.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
