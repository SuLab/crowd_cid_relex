{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation analysis of final evaluation results between different techniques\n",
    "\n",
    "Tong Shu Li<br>\n",
    "Created on: 2015-10-08<br>\n",
    "Last updated: 2015-11-10\n",
    "\n",
    "The team at UTexas was kind enough to send their final predictions for the CID task. We will compare their results to the crowd's and see where their outputs differed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "from IPython.display import Image\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import rpy2\n",
    "import rpy2.robjects as robjects\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RAND_KEY = np.random.RandomState(20151007)\n",
    "matplotlib.rcParams.update({'font.size': 12})\n",
    "TRIPLE = [\"pmid\", \"chemical_id\", \"disease_id\"]\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option(\"max_colwidth\", 55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from src.lingpipe.file_util import read_file\n",
    "from src.lingpipe.file_util import save_file\n",
    "\n",
    "from src.data_model import Ontology_ID\n",
    "from src.data_model import Relation\n",
    "from src.data_model import parse_input\n",
    "from src.data_model import parse_file\n",
    "from src.data_model import Annotation\n",
    "\n",
    "from src.eval_perf import performance\n",
    "from src.eval_perf import official_F_score\n",
    "from src.parse_mesh import load_mesh\n",
    "from src.get_mesh_terms import Article\n",
    "\n",
    "from src.get_AUC_value import get_AUC_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_df(triples):\n",
    "    \"\"\"Converts a given set of (pmid, chemical_id, disease_id)\n",
    "    triples into a three column dataframe.\"\"\"\n",
    "    return pd.DataFrame(list(triples), columns = TRIPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_triples(dataframe):\n",
    "    return set(dataframe[TRIPLE].apply(\n",
    "                lambda row: (int(row[\"pmid\"]), row[\"chemical_id\"], row[\"disease_id\"]), axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_set(v):\n",
    "    return \"\\n\".join(map(str, v))\n",
    "\n",
    "def print_to_file(fname, dataset):\n",
    "    with open(fname, \"w\") as fout:\n",
    "        fout.write(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def expand_df(df):\n",
    "    res = []\n",
    "    for triple, group in df.groupby(TRIPLE):\n",
    "        assert len(group) == 1\n",
    "        temp = pd.Series(group.iloc[0][\"link\"]).to_frame()\n",
    "        \n",
    "        for col in group.columns:\n",
    "            temp.loc[:, col] = group.iloc[0][col]\n",
    "            \n",
    "        res.append(temp)\n",
    "        \n",
    "    return pd.concat(res).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the gold standard and various solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_output(fname):\n",
    "    \"\"\"Read only the CID relations from a Pubtator-formatted\n",
    "    text file.\n",
    "    \"\"\"\n",
    "    temp = defaultdict(list)\n",
    "    for line in read_file(fname):\n",
    "        vals = line.split(\"\\t\")\n",
    "        \n",
    "        if len(vals) > 1 and vals[1] == \"CID\":\n",
    "            temp[\"pmid\"].append(int(vals[0]))\n",
    "            temp[\"chemical_id\"].append(Ontology_ID(vals[2]).flat_repr)\n",
    "            temp[\"disease_id\"].append(Ontology_ID(vals[3]).flat_repr)\n",
    "            \n",
    "            if len(vals) > 4:\n",
    "                temp[\"threshold\"].append(float(vals[4]))\n",
    "\n",
    "    return pd.DataFrame(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_gold_standard(dataset, file_format = \"list\"):\n",
    "    assert dataset in [\"training\", \"development\", \"test\"]\n",
    "    assert file_format in [\"list\", \"dict\"]\n",
    "    \n",
    "    fname = \"parsed_{0}_set_{1}.pickle\".format(dataset, file_format)\n",
    "    \n",
    "    save_loc = os.path.abspath(os.path.join(\"..\", \"data\", \"gold_standard\", fname))\n",
    "    \n",
    "    fname = \"CDR_{0}Set.txt\".format(dataset.capitalize())\n",
    "    loc = os.path.abspath(os.path.join(\"..\", \"data\", \"gold_standard\"))\n",
    "    \n",
    "    return parse_file(save_loc, loc = loc, fname = fname,\n",
    "        is_gold = True, return_format = file_format, fix_acronyms = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def has_concept(paper, concept_id):\n",
    "    concepts = set()\n",
    "    for annot in paper.annotations:\n",
    "        concepts |= set([iden.flat_repr for iden in annot.uid if iden.uid_type == \"MESH\"])\n",
    "    \n",
    "    return concept_id in concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_exists(df, reference):\n",
    "    for col in [\"chemical\", \"disease\"]:\n",
    "        df.loc[:, \"{}_exists\".format(col[:4])] = df[TRIPLE].apply(\n",
    "            lambda row: has_concept(reference[int(row[\"pmid\"])], row[\"{}_id\".format(col)]), axis = 1)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the PMID mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paper_mapping = save_file(\"testset_mapping.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the gold standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_gold = read_gold_standard(\"test\", file_format = \"dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fname = os.path.abspath(os.path.join(\"..\", \"data\", \"gold_standard\", \"CDR_TestSet.txt\"))\n",
    "gold_std = read_output(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab the official MeSH terms for the testset and save to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grab_mesh(papers):\n",
    "    loc = os.path.abspath(os.path.join(\"..\", \"data\", \"gold_standard\", \"testset_mesh_terms.pickle\"))\n",
    "\n",
    "    res = save_file(loc)\n",
    "    if res is not None:\n",
    "        return res\n",
    "    \n",
    "    res = dict()\n",
    "    for pmid in papers:\n",
    "        res[pmid] = Article(pmid)\n",
    "        \n",
    "    save_file(loc, res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mesh_terms = grab_mesh(set(eval_gold.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the crowd's results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loc = os.path.abspath(os.path.join(\"..\", \"data\", \"final_eval\", \"results\", \"crowd_testset.pickle\"))\n",
    "crowd_full = save_file(loc)\n",
    "crowd_res = save_file(\"testset_final_res.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loc = os.path.abspath(os.path.join(\"..\", \"data\", \"final_eval\", \"results\", \"abstract_relation_res.tsv\"))\n",
    "\n",
    "abs_res = pd.read_csv(loc, sep = '\\t', dtype = {\"unit_id\": str})\n",
    "abs_res = abs_res.rename(columns = {\"percent_agree\": \"norm_conf_score\",\n",
    "                                   \"unit_id\": \"unit_ids\"})\n",
    "\n",
    "abs_res.loc[:, \"pmid\"] = abs_res.loc[:, \"pmid\"].map(lambda val: paper_mapping[val])\n",
    "abs_res.loc[:, \"unit_ids\"] = abs_res.loc[:, \"unit_ids\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loc = os.path.abspath(os.path.join(\"..\", \"data\", \"final_eval\", \"results\", \"sentence_relation_abs_res.tsv\"))\n",
    "sent_res = pd.read_csv(loc, sep = '\\t', dtype = {\"unit_ids\": str})\n",
    "\n",
    "sent_res = sent_res.rename(columns = {\"conf_score\": \"norm_conf_score\",\n",
    "                                      \"score_vote_max\": \"num_votes\"})\n",
    "\n",
    "sent_res.loc[:, \"pmid\"] = sent_res.loc[:, \"pmid\"].map(lambda val: paper_mapping[val])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read UTexas results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loc = os.path.abspath(os.path.join(\"..\", \"data\", \"utexas\", \"texas_full_testset.pickle\"))\n",
    "texas_full = save_file(loc)\n",
    "\n",
    "loc = os.path.abspath(os.path.join(\"..\", \"data\", \"utexas\", \"CDR_TestSet.BiC.V.CID.Run3.txt\"))\n",
    "ut_res = read_output(loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read BeFree's results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = os.path.abspath(os.path.join(\"..\", \"data\", \"befree\", \"final_eval\", \"befree_testset_results.txt\"))\n",
    "befree_res = read_output(fname)\n",
    "\n",
    "befree_res.loc[:, \"pmid\"] = befree_res[\"pmid\"].map(lambda val: paper_mapping[val])\n",
    "befree_res[\"threshold\"] = 1\n",
    "\n",
    "#----------------------------------\n",
    "\n",
    "def get_befree():\n",
    "    loc = os.path.join(\"..\", \"data\", \"befree\", \"final_eval\")\n",
    "\n",
    "    save_loc = os.path.abspath(os.path.join(loc, \"befree_testset_full.pickle\"))\n",
    "    res = save_file(save_loc)\n",
    "    if res is not None:\n",
    "        return res\n",
    "\n",
    "    befree_full = parse_input(os.path.abspath(loc), \"befree_testset_results.txt\",\n",
    "                         is_gold = True, return_format = \"dict\", fix_acronyms = False)\n",
    "\n",
    "    temp = dict()\n",
    "    for pmid, paper in befree_full.items():\n",
    "        paper.pmid = paper_mapping[pmid]\n",
    "        temp[paper_mapping[pmid]] = paper\n",
    "\n",
    "    save_file(save_loc, temp)\n",
    "    return temp\n",
    "    \n",
    "befree_full = get_befree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chemical_id</th>\n",
       "      <th>disease_id</th>\n",
       "      <th>pmid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MESH:D015738</td>\n",
       "      <td>MESH:D003693</td>\n",
       "      <td>8701013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MESH:D007213</td>\n",
       "      <td>MESH:D007022</td>\n",
       "      <td>439781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MESH:D016572</td>\n",
       "      <td>MESH:D057049</td>\n",
       "      <td>22836123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MESH:D000305</td>\n",
       "      <td>MESH:D012595</td>\n",
       "      <td>22836123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MESH:D016559</td>\n",
       "      <td>MESH:D012595</td>\n",
       "      <td>22836123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    chemical_id    disease_id      pmid\n",
       "0  MESH:D015738  MESH:D003693   8701013\n",
       "1  MESH:D007213  MESH:D007022    439781\n",
       "2  MESH:D016572  MESH:D057049  22836123\n",
       "3  MESH:D000305  MESH:D012595  22836123\n",
       "4  MESH:D016559  MESH:D012595  22836123"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chemical_id</th>\n",
       "      <th>disease_id</th>\n",
       "      <th>norm_conf_score</th>\n",
       "      <th>num_votes</th>\n",
       "      <th>pmid</th>\n",
       "      <th>rel_origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MESH:C009695</td>\n",
       "      <td>MESH:D000699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>35781</td>\n",
       "      <td>sentence_task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MESH:C009695</td>\n",
       "      <td>MESH:D002375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>35781</td>\n",
       "      <td>sentence_task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MESH:D003000</td>\n",
       "      <td>MESH:D000699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>35781</td>\n",
       "      <td>sentence_task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MESH:D009278</td>\n",
       "      <td>MESH:D002375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>35781</td>\n",
       "      <td>sentence_task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MESH:D009638</td>\n",
       "      <td>MESH:D000699</td>\n",
       "      <td>0.185347</td>\n",
       "      <td>1</td>\n",
       "      <td>35781</td>\n",
       "      <td>abstract_task</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    chemical_id    disease_id  norm_conf_score  num_votes   pmid  \\\n",
       "0  MESH:C009695  MESH:D000699         0.000000          0  35781   \n",
       "1  MESH:C009695  MESH:D002375         0.000000          0  35781   \n",
       "2  MESH:D003000  MESH:D000699         0.000000          0  35781   \n",
       "3  MESH:D009278  MESH:D002375         0.000000          0  35781   \n",
       "4  MESH:D009638  MESH:D000699         0.185347          1  35781   \n",
       "\n",
       "      rel_origin  \n",
       "0  sentence_task  \n",
       "1  sentence_task  \n",
       "2  sentence_task  \n",
       "3  sentence_task  \n",
       "4  abstract_task  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crowd_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chemical_id</th>\n",
       "      <th>disease_id</th>\n",
       "      <th>pmid</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MESH:D015738</td>\n",
       "      <td>MESH:D003693</td>\n",
       "      <td>8701013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MESH:D007213</td>\n",
       "      <td>MESH:D007022</td>\n",
       "      <td>439781</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MESH:D016559</td>\n",
       "      <td>MESH:D045743</td>\n",
       "      <td>22836123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MESH:D008694</td>\n",
       "      <td>MESH:D011618</td>\n",
       "      <td>23433219</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MESH:D007980</td>\n",
       "      <td>MESH:D004409</td>\n",
       "      <td>23535177</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    chemical_id    disease_id      pmid  threshold\n",
       "0  MESH:D015738  MESH:D003693   8701013          1\n",
       "1  MESH:D007213  MESH:D007022    439781          1\n",
       "2  MESH:D016559  MESH:D045743  22836123          1\n",
       "3  MESH:D008694  MESH:D011618  23433219          1\n",
       "4  MESH:D007980  MESH:D004409  23535177          1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "befree_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chemical_id</th>\n",
       "      <th>disease_id</th>\n",
       "      <th>pmid</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MESH:D015738</td>\n",
       "      <td>MESH:D003693</td>\n",
       "      <td>8701013</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MESH:D015738</td>\n",
       "      <td>MESH:D014456</td>\n",
       "      <td>8701013</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MESH:D007213</td>\n",
       "      <td>MESH:D007022</td>\n",
       "      <td>439781</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MESH:D016572</td>\n",
       "      <td>MESH:D057049</td>\n",
       "      <td>22836123</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MESH:D016559</td>\n",
       "      <td>MESH:D057049</td>\n",
       "      <td>22836123</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    chemical_id    disease_id      pmid  threshold\n",
       "0  MESH:D015738  MESH:D003693   8701013       0.75\n",
       "1  MESH:D015738  MESH:D014456   8701013       0.65\n",
       "2  MESH:D007213  MESH:D007022    439781       0.75\n",
       "3  MESH:D016572  MESH:D057049  22836123       0.75\n",
       "4  MESH:D016559  MESH:D057049  22836123       0.65"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ut_res.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall performance against the gold standard\n",
    "\n",
    "Using the official evaluation of the CID relation performance, how did each solution do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the gold standard triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gold_triples = get_triples(gold_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crowd performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "official_res = official_F_score(\"num_votes\", gold_triples, crowd_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.267624</td>\n",
       "      <td>0.162805</td>\n",
       "      <td>0.751407</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.356317</td>\n",
       "      <td>0.236486</td>\n",
       "      <td>0.722326</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.444779</td>\n",
       "      <td>0.327426</td>\n",
       "      <td>0.693246</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.496480</td>\n",
       "      <td>0.410288</td>\n",
       "      <td>0.628518</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.505929</td>\n",
       "      <td>0.475640</td>\n",
       "      <td>0.540338</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.465066</td>\n",
       "      <td>0.556136</td>\n",
       "      <td>0.399625</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    F_score  precision    recall  threshold\n",
       "0  0.267624   0.162805  0.751407          0\n",
       "1  0.356317   0.236486  0.722326          1\n",
       "2  0.444779   0.327426  0.693246          2\n",
       "3  0.496480   0.410288  0.628518          3\n",
       "4  0.505929   0.475640  0.540338          4\n",
       "5  0.465066   0.556136  0.399625          5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "official_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Texas performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.570252</td>\n",
       "      <td>0.556747</td>\n",
       "      <td>0.584428</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.585269</td>\n",
       "      <td>0.618600</td>\n",
       "      <td>0.555347</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.520915</td>\n",
       "      <td>0.642366</td>\n",
       "      <td>0.438086</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    F_score  precision    recall  threshold\n",
       "0  0.570252   0.556747  0.584428       0.30\n",
       "1  0.585269   0.618600  0.555347       0.65\n",
       "2  0.520915   0.642366  0.438086       0.75"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "official_F_score(\"threshold\", gold_triples, ut_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BeFree performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.486874</td>\n",
       "      <td>0.382739</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    F_score  precision    recall  threshold\n",
       "0  0.428571   0.486874  0.382739          1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "official_F_score(\"threshold\", gold_triples, befree_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My calculations show that BeFree's official published performance (F 0.4281) is slightly worse than what I have calculated, despite my method accurately reproducing both UTexas's and our results. Perhaps Alex sent me a slightly modified version of the data they submitted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crowd_trip = get_triples(crowd_res.query(\"num_votes >= 4\"))\n",
    "befree_trip = get_triples(befree_res)\n",
    "texas_trip = get_triples(ut_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Venn diagram of relations for Crowd and Befree, full workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make venn diagram for relations for the full workflow\n",
    "\n",
    "# fnames = [\"temp/gold_trips.txt\", \"temp/crowd_trips.txt\", \"temp/befree_trips.txt\", \"temp/texas_trips.txt\"]\n",
    "# dfs = [gold_std, crowd_res.query(\"num_votes >= 4\"), befree_res, ut_res]\n",
    "# for fname, df in zip(fnames, dfs):\n",
    "#     df[TRIPLE].to_csv(fname, sep = \"|\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relation comparison: full workflow for crowd and befree\n",
    "<img src=\"../data/final_eval/analysis/testset_crowd_befree_relations.png\" style=\"width: 500px;\">\n",
    "\n",
    "This is for the full workflow output of both BeFree and the crowd. Crowd relations are filtered to only those with >= 4 votes.\n",
    "\n",
    "### Relation comparison: full workflow for crowd, befree, and texas\n",
    "<img src=\"../data/notebook/testset_all_cross_validation.png\" style=\"width: 500px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full outputs of the programs are fine, but since many of these things are NER errors, it would be much better to filter those and then compare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance on a subset of relations where the annotations were perfectly identified\n",
    "\n",
    "Since we have seen that NER has a huge influence on the performance, we will look backwards to see what performance was like on relations where both the chemical and disease were perfectly identified (i.e. the annotations all match the gold standard)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_ids(annotations):\n",
    "    concepts = defaultdict(set)\n",
    "    for annot in annotations:\n",
    "        concepts[annot.stype].add(annot.uid)\n",
    "\n",
    "    return concepts\n",
    "\n",
    "def expand_set(vals):\n",
    "    res = set()\n",
    "    for v in vals:\n",
    "        res |= v\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_perfect_concepts(predict, gold_std):\n",
    "    \"\"\"Finds the concepts having the exact same annotations\n",
    "    in both data sets.\n",
    "    \"\"\"\n",
    "    res = dict()\n",
    "    for pmid, gold_paper in gold_std.items():\n",
    "        paper = predict[pmid]\n",
    "\n",
    "        # annotations\n",
    "        predict_annot = set(paper.annotations)\n",
    "        gold_annot = set(gold_paper.annotations)\n",
    "        \n",
    "        shared_concepts = extract_ids(gold_annot & predict_annot)\n",
    "        missed_concepts = extract_ids(gold_annot ^ predict_annot)\n",
    "        \n",
    "        perf_chem = shared_concepts[\"chemical\"] - missed_concepts[\"chemical\"]\n",
    "        perf_dise = shared_concepts[\"disease\"] - missed_concepts[\"disease\"]\n",
    "        \n",
    "        chems = expand_set(perf_chem)\n",
    "        dises = expand_set(perf_dise)\n",
    "\n",
    "        res[pmid] = (chems, dises)\n",
    "\n",
    "    return res\n",
    "\n",
    "def get_perf_subset_triples(perf_concepts):\n",
    "    res = set()\n",
    "    for pmid, (chem, dise) in perf_concepts.items():\n",
    "        res |= set([(pmid, c.flat_repr, d.flat_repr) for c in chem for d in dise])\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ner_filter(predict_full, predict_df, gold_full, gold_df):\n",
    "    \"\"\"Given a dataframe of a solution's predicted CID relations,\n",
    "    applies a NER filter with the gold standard to return only those\n",
    "    relations which were generated using perfectly annotated concepts.\n",
    "    \"\"\"\n",
    "    # what were the concepts perfectly annotated by the predictions and gold std?\n",
    "    common_concepts = find_perfect_concepts(predict_full, gold_full)\n",
    "    \n",
    "    # what are all possible triples using the perfect concepts?\n",
    "    poss_good_trips = get_perf_subset_triples(common_concepts)\n",
    "    \n",
    "    poss_df = make_df(poss_good_trips)\n",
    "    \n",
    "    # filter predictions and gold standard using the set of possible triples\n",
    "    predict_sub = pd.merge(predict_df, poss_df, how = \"inner\", on = TRIPLE)\n",
    "    gold_sub = pd.merge(gold_df, poss_df, how = \"inner\", on = TRIPLE)\n",
    "    \n",
    "    return (predict_sub, gold_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crowd_no_ner, crowd_good_gold = ner_filter(crowd_full, crowd_res, eval_gold, gold_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(crowd_good_gold[\"pmid\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.318346</td>\n",
       "      <td>0.189305</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.434339</td>\n",
       "      <td>0.280240</td>\n",
       "      <td>0.964948</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.381356</td>\n",
       "      <td>0.927835</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.615958</td>\n",
       "      <td>0.482477</td>\n",
       "      <td>0.851546</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.645447</td>\n",
       "      <td>0.565015</td>\n",
       "      <td>0.752577</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.603732</td>\n",
       "      <td>0.645540</td>\n",
       "      <td>0.567010</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    F_score  precision    recall  threshold\n",
       "0  0.318346   0.189305  1.000000          0\n",
       "1  0.434339   0.280240  0.964948          1\n",
       "2  0.540541   0.381356  0.927835          2\n",
       "3  0.615958   0.482477  0.851546          3\n",
       "4  0.645447   0.565015  0.752577          4\n",
       "5  0.603732   0.645540  0.567010          5"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crowd_no_ner_perf = official_F_score(\"num_votes\", get_triples(crowd_good_gold), crowd_no_ner)\n",
    "crowd_no_ner_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are slightly better than the simple NER filtering that I was using before, where I only check whether the concept was identified at all in the paper. However, the performance is basically the same, still in the low 0.6 F range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.668800</td>\n",
       "      <td>0.622951</td>\n",
       "      <td>0.721934</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.668354</td>\n",
       "      <td>0.653465</td>\n",
       "      <td>0.683938</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.600966</td>\n",
       "      <td>0.682018</td>\n",
       "      <td>0.537133</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    F_score  precision    recall  threshold\n",
       "0  0.668800   0.622951  0.721934       0.30\n",
       "1  0.668354   0.653465  0.683938       0.65\n",
       "2  0.600966   0.682018  0.537133       0.75"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texas_no_ner, texas_good_gold = ner_filter(texas_full, ut_res, eval_gold, gold_std)\n",
    "\n",
    "texas_no_ner_perf = official_F_score(\"threshold\", get_triples(texas_good_gold), texas_no_ner)\n",
    "texas_no_ner_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.588774</td>\n",
       "      <td>0.622276</td>\n",
       "      <td>0.558696</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    F_score  precision    recall  threshold\n",
       "0  0.588774   0.622276  0.558696          1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "befree_no_ner, befree_good_gold = ner_filter(befree_full, befree_res, eval_gold, gold_std)\n",
    "\n",
    "befree_no_ner_perf = official_F_score(\"threshold\", get_triples(befree_good_gold), befree_no_ner)\n",
    "befree_no_ner_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pair_perf_plot(df1, df2, title, xlabel, fontsize, figsize, linewidth, fname = None):\n",
    "    \"\"\"Plots two pairs of performances on the same figure.\n",
    "    \n",
    "    Colors are specified manually, as are legend values.\n",
    "    \"\"\"    \n",
    "    colors = {\n",
    "        \"f_score\": \"blue\",\n",
    "        \"precision\": \"green\",\n",
    "        \"recall\": \"red\"\n",
    "    }\n",
    "    \n",
    "    labels = {\n",
    "        \"recall\": Patch(color = colors[\"recall\"], label = \"Recall\"),\n",
    "        \"precision\": Patch(color = colors[\"precision\"], label = \"Precision\"),\n",
    "        \"f_score\": Patch(color = colors[\"f_score\"], label = \"F-score\"),\n",
    "        \"no_ner\": Line2D([], [], color = \"black\", linestyle = \"-\", linewidth = linewidth,\n",
    "                      label = \"Without NER filter\"),\n",
    "        \"yes_ner\": Line2D([], [], color = \"black\", linestyle = \"--\", linewidth = linewidth,\n",
    "                       label = \"With NER filter\")\n",
    "    }\n",
    "\n",
    "    matplotlib.rcParams.update({\"font.size\": fontsize})\n",
    "\n",
    "    # order determined by trial and error..\n",
    "    color = [colors[\"f_score\"], colors[\"precision\"], colors[\"recall\"]]\n",
    "\n",
    "    ax = df1.plot(\n",
    "        x = \"threshold\", figsize = figsize, title = title,\n",
    "        ylim = (0, 1.05), linewidth = linewidth, legend = False, color = color\n",
    "    )\n",
    "\n",
    "    ax = df2.plot(\n",
    "        ax = ax, x = \"threshold\", figsize = figsize, title = title,\n",
    "        linestyle = \"--\", ylim = (0, 1.05), linewidth = linewidth,\n",
    "        legend = False, color = color\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(xlabel)\n",
    "    \n",
    "    plt.legend(loc = \"best\", handles = [\n",
    "            labels[\"recall\"], labels[\"precision\"], labels[\"f_score\"],\n",
    "            labels[\"no_ner\"], labels[\"yes_ner\"]\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    if fname is not None:\n",
    "        plt.savefig(fname, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl8AAAJpCAYAAACTnFetAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb7b17e9f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# official figure for database submission\n",
    "# demonstrating the effect of the NER filter on performance\n",
    "pair_perf_plot(official_res, crowd_no_ner_perf,\n",
    "    \"\",\n",
    "    \"Number of votes\", 18, (10, 10), 3, \"crowd_testset_perf.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = pd.merge(crowd_res[TRIPLE + [\"num_votes\"]], gold_std, how = \"outer\", on = TRIPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp.loc[:, \"num_votes\"] = temp.loc[:, \"num_votes\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp.loc[:, \"in_gold\"] = temp.loc[:, TRIPLE].apply(\n",
    "    lambda r: int((r[\"pmid\"], r[\"chemical_id\"], r[\"disease_id\"]) in gold_triples),\n",
    "    axis = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# temp.to_csv(\"true_roc.tsv\", sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6934884421117169"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AUC value for no NER filtering\n",
    "get_AUC_value(temp, \"num_votes\", \"in_gold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = pd.merge(crowd_no_ner[TRIPLE + [\"num_votes\"]], crowd_good_gold, how = \"outer\", on = TRIPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = get_triples(crowd_good_gold)\n",
    "temp.loc[:, \"in_gold\"] = temp.loc[:, TRIPLE].apply(\n",
    "    lambda r: int((r[\"pmid\"], r[\"chemical_id\"], r[\"disease_id\"]) in sub),\n",
    "    axis = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# temp.to_csv(\"no_ner_roc.tsv\", sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8763695655411006"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_AUC_value(temp, \"num_votes\", \"in_gold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Actual paired ROC curve was generated using R script.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Venn diagram of relations with NER filter\n",
    "\n",
    "Relations generated using concepts that are perfectly annotated in all solutions with respect to gold standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crowd_conc = find_perfect_concepts(crowd_full, eval_gold)\n",
    "befree_conc = find_perfect_concepts(befree_full, eval_gold)\n",
    "texas_conc = find_perfect_concepts(texas_full, eval_gold)\n",
    "\n",
    "common_conc = {\n",
    "    pmid: tuple([crowd_conc[pmid][i] & befree_conc[pmid][i] & texas_conc[pmid][i] for i in range(2)])\n",
    "    for pmid in eval_gold.keys()\n",
    "}\n",
    "\n",
    "poss_good_trips = get_perf_subset_triples(common_conc)\n",
    "poss_df = make_df(poss_good_trips)\n",
    "\n",
    "gold_sub = pd.merge(gold_std, poss_df, how = \"inner\", on = TRIPLE)\n",
    "crowd_sub = pd.merge(crowd_res, poss_df, how = \"inner\", on = TRIPLE)\n",
    "befree_sub = pd.merge(befree_res, poss_df, how = \"inner\", on = TRIPLE)\n",
    "texas_sub = pd.merge(ut_res, poss_df, how = \"inner\", on = TRIPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make venn diagram for relations for the full workflow\n",
    "\n",
    "# fnames = [\"temp/gold_trips.txt\", \"temp/crowd_trips.txt\", \"temp/befree_trips.txt\", \"temp/texas_trips.txt\"]\n",
    "# dfs = [gold_sub, crowd_sub.query(\"num_votes >= 4\"), befree_sub, texas_sub]\n",
    "# for fname, df in zip(fnames, dfs):\n",
    "#     df[TRIPLE].to_csv(fname, sep = \"|\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../data/final_eval/analysis/testset_crowd_befree_common_filtered_relations.png\" style=\"width: 500px;\">\n",
    "\n",
    "This is for the NER filtered output of BeFree and crowd. Relations were subsetted on concepts which were perfectly matching gold in both solutions.\n",
    "\n",
    "<img src=\"../data/final_eval/analysis/testset_all_no_ner_cross_validation.png\" style=\"width: 500px;\">\n",
    "\n",
    "This is for the NER filtered output of all 3 solutions. Relations were subsetted on concepts which were perfectly matching gold in all solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error analysis\n",
    "\n",
    "Null hypothesis: the origin of a relation is independent of the category that the relation belongs to (true positive, false positive, false negative).\n",
    "\n",
    "We use the Chi square test to determine whether the null hypothesis is true. We will group CID and sentence bound relations together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def converter(pmid, poss_relations):\n",
    "    return [Relation(pmid, rel[0], rel[1]) for rel in poss_relations]\n",
    "\n",
    "def rel_origin(triple, paper):\n",
    "    relation = Relation(paper.pmid, triple[1], triple[2], flat = False)\n",
    "\n",
    "    rename = {\n",
    "        \"CID\": \"sent\",\n",
    "        \"sentence_non_CID\": \"sent\",\n",
    "        \"not_sentence_bound\": \"abs\"\n",
    "    }\n",
    "    \n",
    "    ans = []\n",
    "    for key, val in paper.poss_relations.items():\n",
    "        value = converter(paper.pmid, val)\n",
    "        if relation in value:\n",
    "            ans.append(rename[key])\n",
    "\n",
    "    return \"|\".join(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def single_triple(row):\n",
    "    return (int(row[\"pmid\"]), row[\"chemical_id\"], row[\"disease_id\"])\n",
    "\n",
    "def make_summary(predictions, gold_std):\n",
    "    temp = pd.merge(predictions[TRIPLE], gold_std[TRIPLE], how = \"outer\", on = TRIPLE)\n",
    "    \n",
    "    pred_trip = get_triples(predictions)\n",
    "    gold_trip = get_triples(gold_std)\n",
    "    \n",
    "    temp.loc[:, \"in_gold\"] = temp.loc[:, TRIPLE].apply(\n",
    "        lambda row: single_triple(row) in gold_trip, axis = 1\n",
    "    )\n",
    "    \n",
    "    temp.loc[:, \"in_predict\"] = temp.loc[:, TRIPLE].apply(\n",
    "        lambda row: single_triple(row) in pred_trip, axis = 1\n",
    "    )\n",
    "    \n",
    "    temp.loc[:, \"rel_origin\"] = temp.loc[:, TRIPLE].apply(\n",
    "        lambda row: rel_origin(single_triple(row), eval_gold[row[\"pmid\"]]), axis = 1\n",
    "    )\n",
    "    \n",
    "    temp.loc[:, \"pmid\"] = temp.loc[:, \"pmid\"].astype(int)\n",
    "    \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def category_splitter(predict_res, gold_std, option = \"\"):\n",
    "    \"\"\"A generator for categories of relations.\"\"\"\n",
    "    predict = make_summary(predict_res, gold_std)\n",
    "    \n",
    "    error_type = [\"TP\", \"FP\", \"FN\"]\n",
    "    vals = [(True, True), (False, True), (True, False)] # gold, predict\n",
    "    \n",
    "    for etype, val in zip(error_type, vals):\n",
    "        sub = predict.query(\"in_gold == {} and in_predict == {}{}\".format(\n",
    "            val[0], val[1], option\n",
    "        )).dropna()\n",
    "        \n",
    "        yield (etype, sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def two_samp_test(res, test_type):\n",
    "    assert test_type in [\"t.test\", \"wilcox.test\"]\n",
    "    test = robjects.r[test_type]\n",
    "    \n",
    "    #determined empirically\n",
    "    cover = {\n",
    "        \"t.test\": 8,\n",
    "        \"wilcox.test\": 6\n",
    "    }    \n",
    "    \n",
    "    for a, b in combinations([\"TP\", \"FP\", \"FN\"], 2):\n",
    "        print(\"{} between {} and {}\".format(test_type, a, b))\n",
    "        result = test(res[a], res[b])\n",
    "        # don't print the acutal series themselves\n",
    "        # overwriting with zero suppresses superfluous output\n",
    "        result[cover[test_type]] = 0\n",
    "\n",
    "        print(result)\n",
    "        print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_origin(pred_res, gold_std):\n",
    "    \"\"\"Apply the Chi-square test to see if a relation's\n",
    "    origin is independent of the category of error it\n",
    "    belongs to.\n",
    "    \"\"\"\n",
    "    chisqtest = robjects.r[\"chisq.test\"]\n",
    "    \n",
    "    res = dict()\n",
    "    for etype, sub in category_splitter(pred_res, gold_std):\n",
    "        res[etype] = sub[\"rel_origin\"].value_counts()[[\"sent\", \"abs\"]]\n",
    "        \n",
    "    res = pd.DataFrame(res).T\n",
    "    \n",
    "    print(chisqtest(res))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tPearson's Chi-squared test\n",
      "\n",
      "data:  structure(list(sent = structure(c(55L, 181L, 290L), .Dim = 3L),     abs = structure(c(65L, 100L, 74L), .Dim = 3L)), .Names = c(\"sent\", \"abs\"), row.names = c(\"FN\", \"FP\", \"TP\"), class = \"data.frame\")\n",
      "X-squared = 52.006, df = 2, p-value = 5.095e-12\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FN</th>\n",
       "      <td>55</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FP</th>\n",
       "      <td>181</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP</th>\n",
       "      <td>290</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sent  abs\n",
       "FN    55   65\n",
       "FP   181  100\n",
       "TP   290   74"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hypothesis: relation origin is independent of category the relation ends up in\n",
    "\n",
    "test_origin(crowd_no_ner.query(\"num_votes >= 4\"), crowd_good_gold)\n",
    "\n",
    "# result: null hypothesis is wrong, relation origin does affect which error group a relation falls into"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crowd_summary = make_summary(crowd_no_ner.query(\"num_votes >= 4\"), crowd_good_gold)\n",
    "\n",
    "cols = crowd_summary.columns | [\"unit_ids\", \"num_votes\"]\n",
    "\n",
    "crowd_summary = pd.merge(crowd_summary,\n",
    "    pd.concat([sent_res, abs_res]), how = \"left\", on = TRIPLE)[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-test of length for abstract scope errors\n",
    "\n",
    "For the relations which are abstract scoped, does crowd performance depend upon how long the abstracts are? I.e., do workers perform worse on longer abstracts because there's more reading?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_length(pred_res, gold_std, gold_full, test, test_type):\n",
    "    \"\"\"Apply the Student's t-test to see if the category an\n",
    "    abstract relation falls into is determined by the length\n",
    "    of the abstract or the number of sentences.\n",
    "    \"\"\"\n",
    "    assert test in [\"length\", \"sentences\"]\n",
    "    \n",
    "    res = dict()    \n",
    "    for e_type, sub in category_splitter(pred_res, gold_std, \" and rel_origin == 'abs'\"):\n",
    "        papers = list(sub[\"pmid\"])\n",
    "        if test == \"length\":\n",
    "            res[e_type] = pd.Series([\n",
    "                len(gold_full[pmid].title) + len(gold_full[pmid].abstract) + 1\n",
    "                for pmid in papers\n",
    "            ])\n",
    "        elif test == \"sentences\":\n",
    "            res[e_type] = pd.Series([\n",
    "                len(gold_full[pmid].sentences) for pmid in papers\n",
    "            ])\n",
    "        \n",
    "    two_samp_test(res, test_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t.test between TP and FP\n",
      "\n",
      "\tWelch Two Sample t-test\n",
      "\n",
      "data:  0\n",
      "t = 1.4014, df = 159.92, p-value = 0.163\n",
      "alternative hypothesis: true difference in means is not equal to 0\n",
      "95 percent confidence interval:\n",
      " -41.2189 242.6632\n",
      "sample estimates:\n",
      "mean of x mean of y \n",
      " 1364.662  1263.940 \n",
      "\n",
      "\n",
      "-----------------------------\n",
      "t.test between TP and FN\n",
      "\n",
      "\tWelch Two Sample t-test\n",
      "\n",
      "data:  0\n",
      "t = -1.9551, df = 129.78, p-value = 0.05272\n",
      "alternative hypothesis: true difference in means is not equal to 0\n",
      "95 percent confidence interval:\n",
      " -328.40695    1.94666\n",
      "sample estimates:\n",
      "mean of x mean of y \n",
      " 1364.662  1527.892 \n",
      "\n",
      "\n",
      "-----------------------------\n",
      "t.test between FP and FN\n",
      "\n",
      "\tWelch Two Sample t-test\n",
      "\n",
      "data:  0\n",
      "t = -3.3129, df = 129.25, p-value = 0.001198\n",
      "alternative hypothesis: true difference in means is not equal to 0\n",
      "95 percent confidence interval:\n",
      " -421.5881 -106.3165\n",
      "sample estimates:\n",
      "mean of x mean of y \n",
      " 1263.940  1527.892 \n",
      "\n",
      "\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "test_length(crowd_no_ner.query(\"num_votes >= 4\"), crowd_good_gold, eval_gold, \"length\", \"t.test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wilcox.test between TP and FP\n",
      "\n",
      "\tWilcoxon rank sum test with continuity correction\n",
      "\n",
      "data:  0\n",
      "W = 4182, p-value = 0.1425\n",
      "alternative hypothesis: true location shift is not equal to 0\n",
      "\n",
      "\n",
      "-----------------------------\n",
      "wilcox.test between TP and FN\n",
      "\n",
      "\tWilcoxon rank sum test with continuity correction\n",
      "\n",
      "data:  0\n",
      "W = 2004.5, p-value = 0.09099\n",
      "alternative hypothesis: true location shift is not equal to 0\n",
      "\n",
      "\n",
      "-----------------------------\n",
      "wilcox.test between FP and FN\n",
      "\n",
      "\tWilcoxon rank sum test with continuity correction\n",
      "\n",
      "data:  0\n",
      "W = 2300.5, p-value = 0.001543\n",
      "alternative hypothesis: true location shift is not equal to 0\n",
      "\n",
      "\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "test_length(crowd_no_ner.query(\"num_votes >= 4\"), crowd_good_gold, eval_gold, \"length\", \"wilcox.test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t.test between TP and FP\n",
      "\n",
      "\tWelch Two Sample t-test\n",
      "\n",
      "data:  0\n",
      "t = 0.75537, df = 165.67, p-value = 0.4511\n",
      "alternative hypothesis: true difference in means is not equal to 0\n",
      "95 percent confidence interval:\n",
      " -0.6210935  1.3908233\n",
      "sample estimates:\n",
      "mean of x mean of y \n",
      " 9.864865  9.480000 \n",
      "\n",
      "\n",
      "-----------------------------\n",
      "t.test between TP and FN\n",
      "\n",
      "\tWelch Two Sample t-test\n",
      "\n",
      "data:  0\n",
      "t = -1.8031, df = 122.4, p-value = 0.07384\n",
      "alternative hypothesis: true difference in means is not equal to 0\n",
      "95 percent confidence interval:\n",
      " -2.3168117  0.1080799\n",
      "sample estimates:\n",
      "mean of x mean of y \n",
      " 9.864865 10.969231 \n",
      "\n",
      "\n",
      "-----------------------------\n",
      "t.test between FP and FN\n",
      "\n",
      "\tWelch Two Sample t-test\n",
      "\n",
      "data:  0\n",
      "t = -2.4676, df = 125.71, p-value = 0.01495\n",
      "alternative hypothesis: true difference in means is not equal to 0\n",
      "95 percent confidence interval:\n",
      " -2.6835931 -0.2948684\n",
      "sample estimates:\n",
      "mean of x mean of y \n",
      "  9.48000  10.96923 \n",
      "\n",
      "\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "test_length(crowd_no_ner.query(\"num_votes >= 4\"), crowd_good_gold, eval_gold, \"sentences\", \"t.test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t.test between TP and FP\n",
      "\n",
      "\tWelch Two Sample t-test\n",
      "\n",
      "data:  0\n",
      "t = -1.3116, df = 80.476, p-value = 0.1934\n",
      "alternative hypothesis: true difference in means is not equal to 0\n",
      "95 percent confidence interval:\n",
      " -275.64730   56.63352\n",
      "sample estimates:\n",
      "mean of x mean of y \n",
      " 1447.822  1557.329 \n",
      "\n",
      "\n",
      "-----------------------------\n",
      "t.test between TP and FN\n",
      "\n",
      "\tWelch Two Sample t-test\n",
      "\n",
      "data:  0\n",
      "t = -0.23017, df = 104.82, p-value = 0.8184\n",
      "alternative hypothesis: true difference in means is not equal to 0\n",
      "95 percent confidence interval:\n",
      " -204.0291  161.5875\n",
      "sample estimates:\n",
      "mean of x mean of y \n",
      " 1447.822  1469.043 \n",
      "\n",
      "\n",
      "-----------------------------\n",
      "t.test between FP and FN\n",
      "\n",
      "\tWelch Two Sample t-test\n",
      "\n",
      "data:  0\n",
      "t = 1.1763, df = 164.1, p-value = 0.2412\n",
      "alternative hypothesis: true difference in means is not equal to 0\n",
      "95 percent confidence interval:\n",
      " -59.91545 236.48766\n",
      "sample estimates:\n",
      "mean of x mean of y \n",
      " 1557.329  1469.043 \n",
      "\n",
      "\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "test_length(befree_no_ner, befree_good_gold, eval_gold, \"length\", \"t.test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crowd:\n",
    "\n",
    "**Hypothesis**: Workers are more likely to have difficulty with long abstracts due to the amount of reading and long-distance word dependencies.\n",
    "\n",
    "Based on the t-test results, it seems that there is no difference in length between the true positives and false positives or false negatives. However, there does seem to be a difference in length between the false positives and the false negatives. The false positives were significantly more likely to arise from abstracts which were shorter in length, while the false negatives were more likely to be in longer abstracts.\n",
    "\n",
    "We see no such evidence of such a dependency in both of the machine learning approaches. Length of the abstract has no bearing on what kind of category the relation will fall into.\n",
    "\n",
    "Number of sentences has no effect either.\n",
    "\n",
    "I think that the last result supports the hypothesis that workers are more likely to miss relations in longer abstracts due to more reading and long scale word dependency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallelism test\n",
    "\n",
    "**Hypothesis**: false positives are likely to show up in sentences containing other true positives.\n",
    "\n",
    "Example: in PMID 3289726, the gold has three relations, between etoposide (D005047) and three diseases: confusion (D003221), seizure (D012640), and papilledema (D010211). The abstract states: \"Significant clinical manifestations have included confusion, papilledema, somnolence, exacerbation of motor deficits, and sharp increase in seizure activity.\"\n",
    "\n",
    "Therefore all of the mentioned diseases are related to etoposide. There should in reality be 5 relations in the gold, but one is not possible (motor deficits) because there is no corresponding MeSH term, and the other seems to be a missing relation (a mistake) in the gold standard. However, the missing relation was stated as true with high confidence by our crowd, so we can use this as a filter to find false positives by the crowd which are likely to be true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_concepts(stype, sentence):\n",
    "    res = set()\n",
    "    for annot in sentence.annotations:\n",
    "        if annot.stype == stype:\n",
    "            res |= annot.uid\n",
    "        \n",
    "    return res\n",
    "\n",
    "def count_parallel(pmid, chem, dise):\n",
    "    \"\"\"For a given relation, look at the sentence that the\n",
    "    disease is in and look for true relations using the\n",
    "    chemical and another disease in the same sentence.\n",
    "    \n",
    "    Usually there is parallelism and the list of diseases\n",
    "    in the sentence will all be true (as a list of symptoms\n",
    "    for that chemical etc.)\n",
    "    \n",
    "    Example: PMID 3289726, where one sentence contains all the\n",
    "    true relations.\n",
    "    \"\"\"\n",
    "    paper = eval_gold[pmid]\n",
    "    \n",
    "    # find the sentences containing the disease id\n",
    "    chem_id = Ontology_ID(chem)\n",
    "    dise_id = Ontology_ID(dise)   \n",
    "    \n",
    "    res = 0\n",
    "    for sentence in paper.sentences:\n",
    "        concepts = get_concepts(\"disease\", sentence)\n",
    "\n",
    "        if dise_id in concepts:\n",
    "            other = concepts - set([dise_id])\n",
    "            \n",
    "            poss = [Relation(pmid, frozenset([chem_id]),\n",
    "                frozenset([concept])) for concept in other]\n",
    "            \n",
    "            ans = [int(paper.has_relation(val)) for val in poss]\n",
    "            res += sum(ans)\n",
    "            \n",
    "    return res       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_parallel(pred_res, gold_std, gold_full, test_type):\n",
    "    \"\"\"Determine whether the category of a relation is independent\n",
    "    of the number of other parallel relations in the same sentence.\n",
    "    \"\"\"\n",
    "    res = dict()\n",
    "    for e_type, sub in category_splitter(pred_res, gold_std, \" and rel_origin == 'abs'\"):\n",
    "        res[e_type] = pd.Series(sub[TRIPLE].apply(\n",
    "            lambda r: count_parallel(r[\"pmid\"], r[\"chemical_id\"], r[\"disease_id\"]),\n",
    "            axis = 1\n",
    "        ))\n",
    "        \n",
    "    two_samp_test(res, test_type)        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t.test between TP and FP\n",
      "\n",
      "\tWelch Two Sample t-test\n",
      "\n",
      "data:  0\n",
      "t = 5.3173, df = 138.49, p-value = 4.119e-07\n",
      "alternative hypothesis: true difference in means is not equal to 0\n",
      "95 percent confidence interval:\n",
      " 0.7783989 1.6999795\n",
      "sample estimates:\n",
      "mean of x mean of y \n",
      " 1.689189  0.450000 \n",
      "\n",
      "\n",
      "-----------------------------\n",
      "t.test between TP and FN\n",
      "\n",
      "\tWelch Two Sample t-test\n",
      "\n",
      "data:  0\n",
      "t = -0.34741, df = 121.76, p-value = 0.7289\n",
      "alternative hypothesis: true difference in means is not equal to 0\n",
      "95 percent confidence interval:\n",
      " -0.7422382  0.5206165\n",
      "sample estimates:\n",
      "mean of x mean of y \n",
      " 1.689189  1.800000 \n",
      "\n",
      "\n",
      "-----------------------------\n",
      "t.test between FP and FN\n",
      "\n",
      "\tWelch Two Sample t-test\n",
      "\n",
      "data:  0\n",
      "t = -4.6709, df = 99.281, p-value = 9.427e-06\n",
      "alternative hypothesis: true difference in means is not equal to 0\n",
      "95 percent confidence interval:\n",
      " -1.9234712 -0.7765288\n",
      "sample estimates:\n",
      "mean of x mean of y \n",
      "     0.45      1.80 \n",
      "\n",
      "\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "res = test_parallel(crowd_no_ner.query(\"num_votes >= 4\"), crowd_good_gold, eval_gold, \"t.test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wilcox.test between TP and FP\n",
      "\n",
      "\tWilcoxon rank sum test with continuity correction\n",
      "\n",
      "data:  0\n",
      "W = 5771, p-value = 1.196e-12\n",
      "alternative hypothesis: true location shift is not equal to 0\n",
      "\n",
      "\n",
      "-----------------------------\n",
      "wilcox.test between TP and FN\n",
      "\n",
      "\tWilcoxon rank sum test with continuity correction\n",
      "\n",
      "data:  0\n",
      "W = 2534, p-value = 0.5759\n",
      "alternative hypothesis: true location shift is not equal to 0\n",
      "\n",
      "\n",
      "-----------------------------\n",
      "wilcox.test between FP and FN\n",
      "\n",
      "\tWilcoxon rank sum test with continuity correction\n",
      "\n",
      "data:  0\n",
      "W = 1923.5, p-value = 9.321e-08\n",
      "alternative hypothesis: true location shift is not equal to 0\n",
      "\n",
      "\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "res = test_parallel(crowd_no_ner.query(\"num_votes >= 4\"), crowd_good_gold, eval_gold, \"wilcox.test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    21\n",
       "0    20\n",
       "1    18\n",
       "3     6\n",
       "6     4\n",
       "5     3\n",
       "4     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"TP\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    83\n",
       "1     8\n",
       "3     4\n",
       "7     3\n",
       "2     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"FP\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29\n",
       "4    10\n",
       "1     8\n",
       "2     7\n",
       "5     5\n",
       "6     4\n",
       "3     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"FN\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fps = crowd_summary.query(\"~in_gold and in_predict and rel_origin == 'abs'\")\n",
    "\n",
    "fps.loc[:, \"link\"] = fps.loc[:, \"unit_ids\"].map(lambda v: \"https://crowdflower.com/jobs/767273/units/{}\".format(v))\n",
    "\n",
    "fps.loc[:, \"parallel\"] = fps.loc[:, TRIPLE].apply(\n",
    "    lambda r: count_parallel(r[\"pmid\"], r[\"chemical_id\"], r[\"disease_id\"]),\n",
    "    axis = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chemical_id</th>\n",
       "      <th>disease_id</th>\n",
       "      <th>in_gold</th>\n",
       "      <th>in_predict</th>\n",
       "      <th>num_votes</th>\n",
       "      <th>pmid</th>\n",
       "      <th>rel_origin</th>\n",
       "      <th>unit_ids</th>\n",
       "      <th>link</th>\n",
       "      <th>parallel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>MESH:D016190</td>\n",
       "      <td>MESH:D060831</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>11745287</td>\n",
       "      <td>abs</td>\n",
       "      <td>773937706</td>\n",
       "      <td>https://crowdflower.com/jobs/767273/units/773937706</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>MESH:D004317</td>\n",
       "      <td>MESH:D013280</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>11745287</td>\n",
       "      <td>abs</td>\n",
       "      <td>773937712</td>\n",
       "      <td>https://crowdflower.com/jobs/767273/units/773937712</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>MESH:D004317</td>\n",
       "      <td>MESH:D060831</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>11745287</td>\n",
       "      <td>abs</td>\n",
       "      <td>773937713</td>\n",
       "      <td>https://crowdflower.com/jobs/767273/units/773937713</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>MESH:D003613</td>\n",
       "      <td>MESH:D063806</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>2358093</td>\n",
       "      <td>abs</td>\n",
       "      <td>773936830</td>\n",
       "      <td>https://crowdflower.com/jobs/767273/units/773936830</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>MESH:D005047</td>\n",
       "      <td>MESH:D006970</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>3289726</td>\n",
       "      <td>abs</td>\n",
       "      <td>773936980</td>\n",
       "      <td>https://crowdflower.com/jobs/767273/units/773936980</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>MESH:D002231</td>\n",
       "      <td>MESH:D005076</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>19263707</td>\n",
       "      <td>abs</td>\n",
       "      <td>773938382</td>\n",
       "      <td>https://crowdflower.com/jobs/767273/units/773938382</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>MESH:D014635</td>\n",
       "      <td>MESH:D001523</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>24614773</td>\n",
       "      <td>abs</td>\n",
       "      <td>773936176</td>\n",
       "      <td>https://crowdflower.com/jobs/767273/units/773936176</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      chemical_id    disease_id in_gold in_predict  num_votes      pmid  \\\n",
       "318  MESH:D016190  MESH:D060831   False       True          4  11745287   \n",
       "320  MESH:D004317  MESH:D013280   False       True          5  11745287   \n",
       "321  MESH:D004317  MESH:D060831   False       True          5  11745287   \n",
       "64   MESH:D003613  MESH:D063806   False       True          5   2358093   \n",
       "108  MESH:D005047  MESH:D006970   False       True          5   3289726   \n",
       "439  MESH:D002231  MESH:D005076   False       True          4  19263707   \n",
       "546  MESH:D014635  MESH:D001523   False       True          4  24614773   \n",
       "\n",
       "    rel_origin   unit_ids  \\\n",
       "318        abs  773937706   \n",
       "320        abs  773937712   \n",
       "321        abs  773937713   \n",
       "64         abs  773936830   \n",
       "108        abs  773936980   \n",
       "439        abs  773938382   \n",
       "546        abs  773936176   \n",
       "\n",
       "                                                    link  parallel  \n",
       "318  https://crowdflower.com/jobs/767273/units/773937706         7  \n",
       "320  https://crowdflower.com/jobs/767273/units/773937712         7  \n",
       "321  https://crowdflower.com/jobs/767273/units/773937713         7  \n",
       "64   https://crowdflower.com/jobs/767273/units/773936830         3  \n",
       "108  https://crowdflower.com/jobs/767273/units/773936980         3  \n",
       "439  https://crowdflower.com/jobs/767273/units/773938382         3  \n",
       "546  https://crowdflower.com/jobs/767273/units/773936176         3  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fps.query(\"parallel > 2\").sort(\"parallel\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      chemical_id    disease_id in_gold in_predict  num_votes      pmid  \\\n",
      "318  MESH:D016190  MESH:D060831   False       True          4  11745287   \n",
      "320  MESH:D004317  MESH:D013280   False       True          5  11745287   \n",
      "321  MESH:D004317  MESH:D060831   False       True          5  11745287   \n",
      "64   MESH:D003613  MESH:D063806   False       True          5   2358093   \n",
      "108  MESH:D005047  MESH:D006970   False       True          5   3289726   \n",
      "439  MESH:D002231  MESH:D005076   False       True          4  19263707   \n",
      "546  MESH:D014635  MESH:D001523   False       True          4  24614773   \n",
      "\n",
      "    rel_origin   unit_ids  \\\n",
      "318        abs  773937706   \n",
      "320        abs  773937712   \n",
      "321        abs  773937713   \n",
      "64         abs  773936830   \n",
      "108        abs  773936980   \n",
      "439        abs  773938382   \n",
      "546        abs  773936176   \n",
      "\n",
      "                                                    link  parallel  \n",
      "318  https://crowdflower.com/jobs/767273/units/773937706         7  \n",
      "320  https://crowdflower.com/jobs/767273/units/773937712         7  \n",
      "321  https://crowdflower.com/jobs/767273/units/773937713         7  \n",
      "64   https://crowdflower.com/jobs/767273/units/773936830         3  \n",
      "108  https://crowdflower.com/jobs/767273/units/773936980         3  \n",
      "439  https://crowdflower.com/jobs/767273/units/773938382         3  \n",
      "546  https://crowdflower.com/jobs/767273/units/773936176         3  \n"
     ]
    }
   ],
   "source": [
    "print(fps.query(\"parallel > 2\").sort(\"parallel\", ascending = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Based on the data, we see that the true positive abstract-scope relations usually use diseases which occur in sentences with other diseases which also are related to the current chemical (mean 1.7 other instances). However, with the false positives, this is no longer true (mean 0.45). Based on these data, we propose using the number of parallel relations as a filter for determining errors in the gold standard. As in, relations which were left out in the gold standard, but should really be true because they are in sentences where the other relations were all related to the same chemical. We posit that these relations were missed due to human error. The list is given in the cell above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence-bound relations\n",
    "\n",
    "**Hypothesis**: for sentence-bound relations, the crowd performs better when the amount of context increases, that is, the number of tasks (sentences) that the two concepts cooccur in increases. If there is too little context, i.e. only one task (sentence) for a single relation, then we would expect the workers to do poorly because the sentence is taken out of context. In contrast, if there were multiple tasks, then we expect that it is more likely that one of the sentences will have captured the true relationship between the concepts, and therefore giving a higher probability that the crowd will identify the true relation.\n",
    "\n",
    "Therefore we expect that the category of a relation (TP, FP, FN) will not be independent of the number of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_freq(summary, test_type):\n",
    "    error_type = [\"TP\", \"FP\", \"FN\"]\n",
    "    vals = [(True, True), (False, True), (True, False)] # gold, predict\n",
    "    \n",
    "    res = dict()\n",
    "    for etype, val in zip(error_type, vals):\n",
    "        sub = summary.query(\"in_gold == {} and in_predict == {} and rel_origin == 'sent'\".format(\n",
    "            val[0], val[1])\n",
    "        ).dropna() # CID relations are filtered out!\n",
    "        \n",
    "        print(etype, len(sub))\n",
    "        \n",
    "        res[etype] = pd.Series(sub[\"unit_ids\"].map(lambda v: len(v.split(\"|\"))))\n",
    "\n",
    "    two_samp_test(res, test_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP 188\n",
      "FP 156\n",
      "FN 55\n",
      "t.test between TP and FP\n",
      "\n",
      "\tWelch Two Sample t-test\n",
      "\n",
      "data:  0\n",
      "t = 3.3959, df = 340.99, p-value = 0.0007648\n",
      "alternative hypothesis: true difference in means is not equal to 0\n",
      "95 percent confidence interval:\n",
      " 0.1562751 0.5864964\n",
      "sample estimates:\n",
      "mean of x mean of y \n",
      " 1.845745  1.474359 \n",
      "\n",
      "\n",
      "-----------------------------\n",
      "t.test between TP and FN\n",
      "\n",
      "\tWelch Two Sample t-test\n",
      "\n",
      "data:  0\n",
      "t = 3.8217, df = 121.59, p-value = 0.0002104\n",
      "alternative hypothesis: true difference in means is not equal to 0\n",
      "95 percent confidence interval:\n",
      " 0.2411333 0.7594470\n",
      "sample estimates:\n",
      "mean of x mean of y \n",
      " 1.845745  1.345455 \n",
      "\n",
      "\n",
      "-----------------------------\n",
      "t.test between FP and FN\n",
      "\n",
      "\tWelch Two Sample t-test\n",
      "\n",
      "data:  0\n",
      "t = 0.99852, df = 114.69, p-value = 0.3201\n",
      "alternative hypothesis: true difference in means is not equal to 0\n",
      "95 percent confidence interval:\n",
      " -0.1268162  0.3846251\n",
      "sample estimates:\n",
      "mean of x mean of y \n",
      " 1.474359  1.345455 \n",
      "\n",
      "\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "test_freq(crowd_summary, \"t.test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP 188\n",
      "FP 156\n",
      "FN 55\n",
      "wilcox.test between TP and FP\n",
      "\n",
      "\tWilcoxon rank sum test with continuity correction\n",
      "\n",
      "data:  0\n",
      "W = 17874, p-value = 7.472e-05\n",
      "alternative hypothesis: true location shift is not equal to 0\n",
      "\n",
      "\n",
      "-----------------------------\n",
      "wilcox.test between TP and FN\n",
      "\n",
      "\tWilcoxon rank sum test with continuity correction\n",
      "\n",
      "data:  0\n",
      "W = 6680.5, p-value = 0.0002358\n",
      "alternative hypothesis: true location shift is not equal to 0\n",
      "\n",
      "\n",
      "-----------------------------\n",
      "wilcox.test between FP and FN\n",
      "\n",
      "\tWilcoxon rank sum test with continuity correction\n",
      "\n",
      "data:  0\n",
      "W = 4670.5, p-value = 0.2124\n",
      "alternative hypothesis: true location shift is not equal to 0\n",
      "\n",
      "\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "test_freq(crowd_summary, \"wilcox.test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the two sample t-test, it seems that there are significant differences in the number of sentence tasks between the true positives and both false positives and false negatives. There are no differences between the false positive and false negatives. From this I conclude that the null hypothesis is false, and that sentence-scoped relations with greater numbers of tasks are more likely to be classified by the crowd as true positives instead of as either type of error.\n",
    "\n",
    "Therefore it does seem that a lack of context is affecting crowd performance. When there are more sentences containing the relation pair, it is more likely to be classified properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title sentences\n",
    "\n",
    "**Hypothesis**: titles are confusing sentences which are more likely to state a tested hypothesis rather than the results of testing that hypothesis. Therefore we hypothesize that the errors are more likely to contain titles than the true positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ttest_title(summary):\n",
    "    temp = pd.merge(summary, sent_res[TRIPLE + [\"sentence_ids\"]], how = \"left\", on = TRIPLE)\n",
    "    \n",
    "    error_type = [\"TP\", \"FP\", \"FN\"]\n",
    "    vals = [(True, True), (False, True), (True, False)] # gold, predict\n",
    "    \n",
    "    chisqtest = robjects.r[\"chisq.test\"]\n",
    "    \n",
    "    res = dict()\n",
    "    for etype, val in zip(error_type, vals):\n",
    "        sub = temp.query(\"in_gold == {} and in_predict == {} and rel_origin == 'sent'\".format(\n",
    "            val[0], val[1])\n",
    "        ).dropna()\n",
    "\n",
    "        sub.loc[:, \"title\"] = sub.loc[:, \"sentence_ids\"].map(\n",
    "            lambda v:\n",
    "                sum(int(val == \"0\") for val in map(lambda f: f.split(\"_\")[1], v.split(\"|\")))\n",
    "        )\n",
    "        \n",
    "        res[etype] = sub[\"title\"].value_counts()[[0, 1]]\n",
    "\n",
    "    res = pd.DataFrame(res)\n",
    "    \n",
    "    print(chisqtest(res))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tPearson's Chi-squared test\n",
      "\n",
      "data:  structure(list(FN = structure(c(47L, 8L), .Dim = 2L), FP = structure(c(123L, 33L), .Dim = 2L), TP = structure(c(114L, 74L), .Dim = 2L)), .Names = c(\"FN\", \"FP\", \"TP\"), row.names = c(\"0\", \"1\"), class = \"data.frame\")\n",
      "X-squared = 20.116, df = 2, p-value = 4.285e-05\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FN</th>\n",
       "      <th>FP</th>\n",
       "      <th>TP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47</td>\n",
       "      <td>123</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FN   FP   TP\n",
       "0  47  123  114\n",
       "1   8   33   74"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_title(crowd_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a significant difference between the distributions, but it seems that this implies that the crowd does better on relations where they were showed the title as a sentence as well. However I think this really means that there were more tasks that the workers saw, which also makes it more likely that the tasks included the title as a sentence task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ttest_title2(summary, test_type):\n",
    "    temp = pd.merge(summary, sent_res[TRIPLE + [\"sentence_ids\"]], how = \"left\", on = TRIPLE)\n",
    "    \n",
    "    error_type = [\"TP\", \"FP\", \"FN\"]\n",
    "    vals = [(True, True), (False, True), (True, False)] # gold, predict\n",
    "    \n",
    "    res = dict()\n",
    "    for etype, val in zip(error_type, vals):\n",
    "        sub = temp.query(\"in_gold == {} and in_predict == {} and rel_origin == 'sent'\".format(\n",
    "            val[0], val[1])\n",
    "        ).dropna()\n",
    "        \n",
    "        res[etype] = pd.Series(sub.loc[:, \"sentence_ids\"].map(\n",
    "            lambda v:\n",
    "                sum(map(lambda f: int(int(f.split(\"_\")[1]) != 0), v.split(\"|\"))) / len(v.split(\"|\"))\n",
    "        ))\n",
    "        \n",
    "    two_samp_test(res, test_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t.test between TP and FP\n",
      "\n",
      "\tWelch Two Sample t-test\n",
      "\n",
      "data:  0\n",
      "t = -2.2956, df = 333.88, p-value = 0.02232\n",
      "alternative hypothesis: true difference in means is not equal to 0\n",
      "95 percent confidence interval:\n",
      " -0.122151721 -0.009413758\n",
      "sample estimates:\n",
      "mean of x mean of y \n",
      "0.8157801 0.8815629 \n",
      "\n",
      "\n",
      "-----------------------------\n",
      "t.test between TP and FN\n",
      "\n",
      "\tWelch Two Sample t-test\n",
      "\n",
      "data:  0\n",
      "t = -2.5979, df = 95.959, p-value = 0.01086\n",
      "alternative hypothesis: true difference in means is not equal to 0\n",
      "95 percent confidence interval:\n",
      " -0.1752987 -0.0234440\n",
      "sample estimates:\n",
      "mean of x mean of y \n",
      "0.8157801 0.9151515 \n",
      "\n",
      "\n",
      "-----------------------------\n",
      "t.test between FP and FN\n",
      "\n",
      "\tWelch Two Sample t-test\n",
      "\n",
      "data:  0\n",
      "t = -0.8633, df = 100.77, p-value = 0.39\n",
      "alternative hypothesis: true difference in means is not equal to 0\n",
      "95 percent confidence interval:\n",
      " -0.11077254  0.04359527\n",
      "sample estimates:\n",
      "mean of x mean of y \n",
      "0.8815629 0.9151515 \n",
      "\n",
      "\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "ttest_title2(crowd_summary, \"t.test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These data tell us that the ratio of non-title sentences to total sentences is closer to 1 (only non-titles) in the false positives and false negatives compared to the true positives. This is the opposite of what we expect based on our original hypothesis that titles are confusing. I think that the titles are perhaps not as big of a deal as we thought, and that the more important factor is that fewer tasks = poorer performance, since there is a loss of context surrounding the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_links(df, job_id):\n",
    "    df.loc[:, \"link\"] = df.loc[:, \"unit_ids\"].map(lambda v: v.split(\"|\"))\n",
    "    df = expand_df(df)\n",
    "    \n",
    "    df.loc[:, \"link\"] = df.loc[:, \"link\"].map(\n",
    "        lambda v: \"https://crowdflower.com/jobs/{}/units/{}\".format(job_id, v)\n",
    "    )\n",
    "    \n",
    "    print(df[TRIPLE + [\"link\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_links(df, origin):\n",
    "    df.loc[:, \"link\"] = df.loc[:, \"unit_ids\"].map(lambda v: str(v).split(\"|\"))\n",
    "\n",
    "    df = expand_df(df)\n",
    "    \n",
    "    job_id = 767262 if origin == \"sent\" else 767273\n",
    "    df.loc[:, \"link\"] = df.loc[:, \"link\"].map(\n",
    "        lambda v: \"https://crowdflower.com/jobs/{}/units/{}\".format(job_id, v)\n",
    "    )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def manual_inspect(crowd_summary):\n",
    "    etypes = [\"TP\", \"FP\", \"FN\"]\n",
    "    ervals = [(True, True), (False, True), (True, False)]\n",
    "\n",
    "    res = []\n",
    "    for etype, vals in zip(etypes, ervals):\n",
    "        for origin in [\"sent\", \"abs\"]:\n",
    "            sub = crowd_summary.query(\"in_gold == {} and in_predict == {} and rel_origin == '{}'\".format(\n",
    "                vals[0], vals[1], origin)\n",
    "            ).dropna() # ignore cid relations\n",
    "\n",
    "            print(etype, origin)\n",
    "\n",
    "            samp = sub.sample(n = 15, random_state = RAND_KEY)\n",
    "            samp = format_links(samp, origin)\n",
    "            \n",
    "            samp.loc[:, \"pubmed_link\"] = samp.loc[:, \"pmid\"].map(\n",
    "                lambda v: \"http://www.ncbi.nlm.nih.gov/pubmed/?term={}%5Buid%5D\".format(int(v))\n",
    "            )\n",
    "\n",
    "            samp.loc[:, \"etype\"] = etype\n",
    "\n",
    "            res.append(samp)\n",
    "\n",
    "    return pd.concat(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP sent\n",
      "TP abs\n",
      "FP sent\n",
      "FP abs\n",
      "FN sent\n",
      "FN abs\n"
     ]
    }
   ],
   "source": [
    "res = manual_inspect(crowd_summary)\n",
    "res[TRIPLE + [\"rel_origin\", \"num_votes\", \"pubmed_link\", \"link\", \"etype\"]].to_excel(\"errors.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of manual error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loc = os.path.abspath(os.path.join(\"..\", \"data\", \"final_eval\",\n",
    "    \"analysis\", \"crowd_testset_perfect_ner_errors.xlsx\"))\n",
    "\n",
    "error_res = pd.read_excel(loc)\n",
    "\n",
    "# drop the crowdflower link column\n",
    "error_res = error_res.drop(\"link\", axis = 1)\n",
    "\n",
    "error_res = error_res.query(\"etype != 'TP'\")\n",
    "error_res = error_res.drop_duplicates()\n",
    "\n",
    "cols = [\"crowd_wrong\", \"task_limitation\", \"gold_rel_error\"]\n",
    "error_res.loc[:, cols] = error_res.loc[:, cols].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>chemical_id</th>\n",
       "      <th>disease_id</th>\n",
       "      <th>rel_origin</th>\n",
       "      <th>num_votes</th>\n",
       "      <th>etype</th>\n",
       "      <th>crowd_wrong</th>\n",
       "      <th>task_limitation</th>\n",
       "      <th>gold_rel_error</th>\n",
       "      <th>error_reason</th>\n",
       "      <th>discussion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>448423</td>\n",
       "      <td>MESH:D000614</td>\n",
       "      <td>MESH:D013345</td>\n",
       "      <td>sent</td>\n",
       "      <td>4</td>\n",
       "      <td>FP</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>lack_of_context</td>\n",
       "      <td>Aminocaproic acid and epsilon aminocaproic acid are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1735570</td>\n",
       "      <td>MESH:D014294</td>\n",
       "      <td>MESH:D001919</td>\n",
       "      <td>sent</td>\n",
       "      <td>4</td>\n",
       "      <td>FP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>missing_relation</td>\n",
       "      <td>Trimethaphan caused different results depending on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2907577</td>\n",
       "      <td>MESH:D013806</td>\n",
       "      <td>MESH:D058186</td>\n",
       "      <td>sent</td>\n",
       "      <td>4</td>\n",
       "      <td>FP</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>lack_of_comprehension</td>\n",
       "      <td>This is both a failure of the crowd's comprehension...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>3975902</td>\n",
       "      <td>MESH:D001464</td>\n",
       "      <td>MESH:D004342</td>\n",
       "      <td>sent</td>\n",
       "      <td>4</td>\n",
       "      <td>FP</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>lack_of_comprehension</td>\n",
       "      <td>Disagreement with the gold arises from whether “hyp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3987172</td>\n",
       "      <td>MESH:D010665</td>\n",
       "      <td>MESH:D002543</td>\n",
       "      <td>sent</td>\n",
       "      <td>5</td>\n",
       "      <td>FP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>missing_relation</td>\n",
       "      <td>Gold is missing relation.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pmid   chemical_id    disease_id rel_origin  num_votes etype  \\\n",
       "44   448423  MESH:D000614  MESH:D013345       sent          4    FP   \n",
       "45  1735570  MESH:D014294  MESH:D001919       sent          4    FP   \n",
       "46  2907577  MESH:D013806  MESH:D058186       sent          4    FP   \n",
       "47  3975902  MESH:D001464  MESH:D004342       sent          4    FP   \n",
       "49  3987172  MESH:D010665  MESH:D002543       sent          5    FP   \n",
       "\n",
       "    crowd_wrong  task_limitation  gold_rel_error           error_reason  \\\n",
       "44            0                1               0        lack_of_context   \n",
       "45            0                0               1       missing_relation   \n",
       "46            1                0               0  lack_of_comprehension   \n",
       "47            1                0               0  lack_of_comprehension   \n",
       "49            0                0               1       missing_relation   \n",
       "\n",
       "                                                discussion  \n",
       "44  Aminocaproic acid and epsilon aminocaproic acid are...  \n",
       "45  Trimethaphan caused different results depending on ...  \n",
       "46  This is both a failure of the crowd's comprehension...  \n",
       "47  Disagreement with the gold arises from whether “hyp...  \n",
       "49                               Gold is missing relation.  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FN    8\n",
       "FP    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_res.query(\"error_reason == 'lack_of_context'\")[\"etype\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lel = error_res.query(\"gold_rel_error == 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 11)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('abs', 'FN'): [106, 108, 112],\n",
       " ('abs', 'FP'): [69, 70, 71, 72, 73, 74, 75, 76, 77, 81, 82],\n",
       " ('sent', 'FN'): [85, 103],\n",
       " ('sent', 'FP'): [45, 49, 52, 55, 56, 58, 66]}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lel.groupby([\"rel_origin\", \"etype\"]).groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sent', 'FP')\n",
      "0.30434782608695654\n",
      "('abs', 'FN')\n",
      "0.13043478260869565\n",
      "('abs', 'FP')\n",
      "0.4782608695652174\n",
      "('sent', 'FN')\n",
      "0.08695652173913043\n"
     ]
    }
   ],
   "source": [
    "for key, val in lel.groupby([\"rel_origin\", \"etype\"]).groups.items():\n",
    "    print(key)\n",
    "    print(len(val) / 23)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sent', 'FP')\n",
      "181\n",
      "55.0869565217\n",
      "\n",
      "\n",
      "('abs', 'FN')\n",
      "65\n",
      "8.47826086957\n",
      "\n",
      "\n",
      "('abs', 'FP')\n",
      "100\n",
      "47.8260869565\n",
      "\n",
      "\n",
      "('sent', 'FN')\n",
      "55\n",
      "4.78260869565\n",
      "\n",
      "\n",
      "116.173913043\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for key, val in lel.groupby([\"rel_origin\", \"etype\"]).groups.items():\n",
    "    print(key)\n",
    "    \n",
    "    v = kek.loc[key[1], key[0]]\n",
    "    p = len(val) / 23\n",
    "    print(v)\n",
    "    print(v * p)\n",
    "    total += v * p\n",
    "    print(\"\\n\")\n",
    "    \n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2892768079800499"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "116/401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116.17391304347827"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tPearson's Chi-squared test\n",
      "\n",
      "data:  structure(list(sent = structure(c(55L, 181L, 290L), .Dim = 3L),     abs = structure(c(65L, 100L, 74L), .Dim = 3L)), .Names = c(\"sent\", \"abs\"), row.names = c(\"FN\", \"FP\", \"TP\"), class = \"data.frame\")\n",
      "X-squared = 52.006, df = 2, p-value = 5.095e-12\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kek = test_origin(crowd_no_ner.query(\"num_votes >= 4\"), crowd_good_gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FN</th>\n",
       "      <td>55</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FP</th>\n",
       "      <td>181</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP</th>\n",
       "      <td>290</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sent  abs\n",
       "FN    55   65\n",
       "FP   181  100\n",
       "TP   290   74"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "abs     14\n",
       "sent     9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_res.query(\"crowd_wrong == 1\")[\"rel_origin\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "abs     0.608696\n",
       "sent    0.391304\n",
       "dtype: float64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_res.query(\"crowd_wrong == 1\")[\"rel_origin\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sent    12\n",
       "abs      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_res.query(\"task_limitation == 1\")[\"rel_origin\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sent    0.857143\n",
       "abs     0.142857\n",
       "dtype: float64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_res.query(\"task_limitation == 1\")[\"rel_origin\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "abs     14\n",
       "sent     9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_res.query(\"gold_rel_error == 1\")[\"rel_origin\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crowd_wrong\n",
      "lack_of_comprehension          22\n",
      "not_covered_by_instructions     1\n",
      "dtype: int64\n",
      "----\n",
      "lack_of_comprehension          0.956522\n",
      "not_covered_by_instructions    0.043478\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "task_limitation\n",
      "lack_of_context                9\n",
      "not_covered_by_instructions    3\n",
      "hierarchy_error                2\n",
      "dtype: int64\n",
      "----\n",
      "lack_of_context                0.642857\n",
      "not_covered_by_instructions    0.214286\n",
      "hierarchy_error                0.142857\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "gold_rel_error\n",
      "missing_relation    18\n",
      "false_relation       5\n",
      "dtype: int64\n",
      "----\n",
      "missing_relation    0.782609\n",
      "false_relation      0.217391\n",
      "dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in [\"crowd_wrong\", \"task_limitation\", \"gold_rel_error\"]:\n",
    "    sub = error_res.query(\"{} == 1\".format(col))\n",
    "    print(col)\n",
    "    \n",
    "    print(sub[\"error_reason\"].value_counts())\n",
    "    print(\"----\")\n",
    "    print(sub[\"error_reason\"].value_counts(normalize = True))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 11)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_res[\"gold_rel_error\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_res[\"crowd_wrong\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_res[\"task_limitation\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lack_of_comprehension          21\n",
       "missing_relation               18\n",
       "lack_of_context                10\n",
       "false_relation                  5\n",
       "not_covered_by_instructions     4\n",
       "hierarchy_error                 2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_res[\"error_reason\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String used to build sankey diagram\n",
    "\n",
    "Used sankeymatic.com\n",
    "\n",
    "Relations [30] FP\n",
    "Relations [30] FN\n",
    "\n",
    "FP [15] Abstract scoped\n",
    "FP [15] Sentence scoped\n",
    "FN [15] Abstract scoped\n",
    "FN [15] Sentence scoped\n",
    "\n",
    "Sentence scoped [9] Crowd wrong\n",
    "Abstract scoped [14] Crowd wrong\n",
    "\n",
    "Sentence scoped [12] Task limitation\n",
    "Abstract scoped [2] Task limitation\n",
    "\n",
    "Sentence scoped [9] Gold mistake\n",
    "Abstract scoped [14] Gold mistake\n",
    "\n",
    "Crowd wrong [22] Lack of comprehension\n",
    "Crowd wrong [1] No instructions\n",
    "\n",
    "Task limitation [9] Lack of context\n",
    "Task limitation [3] No instructions\n",
    "Task limitation [2] Hierarchy error\n",
    "\n",
    "Gold mistake [18] Missing relation\n",
    "Gold mistake [5] False relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "false negatives\n",
    "\n",
    "PMID 753803: vitamin E and muscular dystrophy. Text states that \"The authors induced myodystrophy in the rat by giving it a diet lacking in vitamin E.\" It was not clear that this kind of relation should be treated as the same as \"giving aspirin causes cancer\". Crowd missed this relation. Could probably have been extracted if we changed the wording of the choice slightly. Did not see this kind of example in the guidelines or the other data, so did not word the choice to capture this variation.\n",
    "\n",
    "PMID 24927617: telaprevir and rhabdomyolysis. This is an example of where showing the whole abstract instead of just the title would have been better, since the text clearly states that the patient developed the disease after taking the drugs. Workers only saw the title.\n",
    "\n",
    "PMID 3191389: sodium salicylate and seizures. Single sentence is not enough context. Next sentence says that the chemical converted a non-convulsant dose of pilocarpine to a convulsant one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'crowd_summary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-5629d01ba9cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfp_abs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcrowd_summary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"~in_gold and in_predict and rel_origin == 'abs'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfp_abs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"link\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp_abs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"unit_ids\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"http://crowdflower.com/jobs/767273/units/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfp_abs_samp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp_abs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRAND_KEY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'crowd_summary' is not defined"
     ]
    }
   ],
   "source": [
    "fp_abs = crowd_summary.query(\"~in_gold and in_predict and rel_origin == 'abs'\")\n",
    "fp_abs.loc[:, \"link\"] = fp_abs.loc[:, \"unit_ids\"].map(lambda v: \"http://crowdflower.com/jobs/767273/units/{}\".format(v))\n",
    "\n",
    "fp_abs_samp = fp_abs.sample(n = 20, random_state = RAND_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'crowd_summary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-b9356dcaea69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfn_abs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcrowd_summary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"in_gold and ~in_predict and rel_origin == 'abs'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfn_abs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"link\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn_abs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"unit_ids\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"https://crowdflower.com/jobs/767273/units/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfn_abs_samp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn_abs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRAND_KEY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'crowd_summary' is not defined"
     ]
    }
   ],
   "source": [
    "fn_abs = crowd_summary.query(\"in_gold and ~in_predict and rel_origin == 'abs'\")\n",
    "fn_abs.loc[:, \"link\"] = fn_abs.loc[:, \"unit_ids\"].map(lambda v: \"https://crowdflower.com/jobs/767273/units/{}\".format(v))\n",
    "\n",
    "fn_abs_samp = fn_abs.sample(n = 20, random_state = RAND_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'crowd_summary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-97-80c0d3d3dc14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtp_abs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcrowd_summary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"in_gold and in_predict and rel_origin == 'abs'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtp_abs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"link\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtp_abs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"unit_ids\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"https://crowdflower.com/jobs/767273/units/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtp_abs_samp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtp_abs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRAND_KEY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'crowd_summary' is not defined"
     ]
    }
   ],
   "source": [
    "tp_abs = crowd_summary.query(\"in_gold and in_predict and rel_origin == 'abs'\")\n",
    "tp_abs.loc[:, \"link\"] = tp_abs.loc[:, \"unit_ids\"].map(lambda v: \"https://crowdflower.com/jobs/767273/units/{}\".format(v))\n",
    "\n",
    "tp_abs_samp = tp_abs.sample(n = 20, random_state = RAND_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tp_abs_samp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-4102bf48a2a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp_abs_samp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTRIPLE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"link\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tp_abs_samp' is not defined"
     ]
    }
   ],
   "source": [
    "print(tp_abs_samp[TRIPLE + [\"link\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fp_abs_samp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-b475562ddf14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_abs_samp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTRIPLE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"link\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'fp_abs_samp' is not defined"
     ]
    }
   ],
   "source": [
    "print(fp_abs_samp[TRIPLE + [\"link\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fn_abs_samp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-100-b7be10fa5e94>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn_abs_samp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTRIPLE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"link\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'fn_abs_samp' is not defined"
     ]
    }
   ],
   "source": [
    "print(fn_abs_samp[TRIPLE + [\"link\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept Venn diagrams\n",
    "\n",
    "What chemical and disease concepts were identified by each solution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# what were the MeSH ids of annotations for all papers in the testset?\n",
    "\n",
    "concepts = defaultdict(lambda: defaultdict(set))\n",
    "\n",
    "for method, dataset in zip([\"gold\", \"crowd\", \"befree\"], [eval_gold, crowd_full, befree_full]):\n",
    "    for pmid, paper in dataset.items():\n",
    "        for annot in paper.annotations:\n",
    "            concepts[method][annot.stype] |= set(annot.uid)\n",
    "            \n",
    "names = [\"gold\", \"crowd\", \"befree\"]\n",
    "for name in names:\n",
    "    for concept in [\"chemical\", \"disease\"]:\n",
    "        vals = {val.flat_repr for val in concepts[name][concept]}\n",
    "        print_to_file(\"temp/{}_{}.txt\".format(name, concept), format_set(vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analysis allows us to determine the performance for each of the NER methods. There may have been some concepts which the NER was never able to recognize properly.\n",
    "\n",
    "### Chemical MeSH ID overlap for all annotations\n",
    "<img src=\"../data/notebook/testset_chemical_id_venn.png\" style=\"width: 500px;\">\n",
    "\n",
    "### Disease MeSH ID overlap for all annotations\n",
    "<img src=\"../data/notebook/testset_disease_id_venn.png\" style=\"width: 500px;\">\n",
    "\n",
    "\n",
    "What we thankfully see is that the vast majority of the chemicals and diseases were identified by all three solutions. However, there exist small numbers of both chemicals and diseases for which the solutions could not come into agreement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the terms in each section of the venn diagrams above\n",
    "\n",
    "To look at the actual concepts, we can use word clouds where the size represents the frequency of the concept in the annotations of the testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mesh_name, hierarchy = load_mesh(\"hierarchy\")\n",
    "mesh_supp = load_mesh(\"supp\")\n",
    "\n",
    "assert set(mesh_name.keys()).isdisjoint(set(mesh_supp.keys()))\n",
    "# join the names together\n",
    "mesh_name.update(mesh_supp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_map_prep(concepts, reference):\n",
    "    \"\"\"Given a set of concepts, map them to their names\n",
    "    and output for word cloud generation.\n",
    "    \"\"\"\n",
    "    snippets = []\n",
    "    for pmid, paper in reference.items():\n",
    "        for annot in paper.annotations:\n",
    "            common = annot.uid & concepts\n",
    "            if len(common) > 0:\n",
    "                for concept in common:\n",
    "                    if concept.uid_type == \"MESH\":\n",
    "                        snippets.append(mesh_name[concept.uid])\n",
    "                    else:\n",
    "                        snippets.append(annot.text)\n",
    "                \n",
    "    return snippets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For UTexas, sometimes the MeSH ID doesn't match the stated semantic type. For example, in PMID 20009434, \"HD\" is identified as a disease but is assigned the id D008727 for methotrexate. When finding the frequencies, I am using the identifiers, and not verifying the semantic type. May need to adjust this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate word clouds with worditout, using the table feature for precise control over concepts\n",
    "# have to save to kemxjr@gmail.com account, then download (watch out for the watermark)\n",
    "\n",
    "common = concepts[\"befree\"][\"chemical\"] & concepts[\"crowd\"][\"chemical\"] - concepts[\"gold\"][\"chemical\"]\n",
    "\n",
    "res = word_map_prep(common, crowd_full)\n",
    "\n",
    "counts = pd.DataFrame(pd.Series(res).value_counts())\n",
    "counts.to_csv(\"temp/counts.txt\", sep = \":\", index = True, header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Venn diagram of relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# format triples to make venn diagrams using:\n",
    "# bioinformatics.lu/venn.php\n",
    "# bioinfogp.cnb.csic.es/tools/venny\n",
    "        \n",
    "names = [\"gold\", \"crowd\", \"befree\"]\n",
    "data = [gold_triples, crowd_trip, befree_trip]\n",
    "    \n",
    "for fname, dataset in zip(names, data):\n",
    "    print_to_file(\"{}.txt\".format(fname), format_set(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'crowd_good_gold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-b33b55e64e63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# venn diagram when using only relations with perfect annotations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcommon_gold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_triples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrowd_good_gold\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m|\u001b[0m \u001b[0mget_triples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbefree_good_gold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"gold\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"crowd\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"befree\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'crowd_good_gold' is not defined"
     ]
    }
   ],
   "source": [
    "# venn diagram when using only relations with perfect annotations\n",
    "\n",
    "common_gold = get_triples(crowd_good_gold) | get_triples(befree_good_gold)\n",
    "\n",
    "names = [\"gold\", \"crowd\", \"befree\"]\n",
    "data = [common_gold, get_triples(crowd_no_ner.query(\"num_votes >= 4\")), get_triples(befree_no_ner)]\n",
    "    \n",
    "for fname, dataset in zip(names, data):\n",
    "    print_to_file(\"{}.txt\".format(fname), format_set(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gold, crowd, and texas only\n",
    "<img src=\"../data/notebook/better_testset_cross_validation.png\" style=\"width: 500px;\">\n",
    "\n",
    "### Gold, crowd, texas, and befree\n",
    "<img src=\"../data/notebook/testset_all_cross_validation.png\" style=\"width: 500px;\">\n",
    "\n",
    "### Overlap using relations which had perfect annotations w.r.t. gold\n",
    "<img src=\"../data/notebook/testset_all_no_ner_cross_validation.png\", style=\"width: 500px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percent relations in each subset with ids missing in gold standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def missing_stats(triples, reference):\n",
    "    df = make_df(triples)\n",
    "    df = check_exists(df, reference)\n",
    "    \n",
    "    ans = dict()\n",
    "    for col in [\"chem\", \"dise\"]:\n",
    "        cname = \"{}_exists\".format(col)\n",
    "        norm = df[cname].value_counts(normalize = True)\n",
    "        res = norm.loc[False] if False in norm.keys() else 0\n",
    "        ans[col] = res * 100\n",
    "        \n",
    "    ans[\"any\"] = len(df.query(\"~chem_exists or ~dise_exists\")) / len(df) * 100\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract vs sentence relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rel_origin(triple, paper):\n",
    "    relation = Relation(paper.pmid, triple[1], triple[2], flat = False)\n",
    "\n",
    "    rename = {\n",
    "        \"CID\": \"CID\",\n",
    "        \"sentence_non_CID\": \"sent\",\n",
    "        \"not_sentence_bound\": \"abs\"\n",
    "    }\n",
    "    \n",
    "    ans = []\n",
    "    for key, val in paper.poss_relations.items():\n",
    "        value = converter(paper.pmid, val)\n",
    "        if relation in value:\n",
    "            ans.append(rename[key])\n",
    "\n",
    "    return ans\n",
    "\n",
    "def triple_origin(triples, reference, return_res = False):\n",
    "    lengths = []\n",
    "    vals = []\n",
    "    for trip in triples:\n",
    "        pmid = trip[0]\n",
    "        res = rel_origin(trip, reference[pmid])\n",
    "        \n",
    "        vals += res\n",
    "        lengths.append(len(res))\n",
    "        \n",
    "    if return_res:\n",
    "        return pd.Series(vals).value_counts(normalize = True) * 100    \n",
    "        \n",
    "    print(\"For this triple set of length {}\".format(len(triples)))\n",
    "    print(\"Origin group lengths:\")\n",
    "    print(pd.Series(lengths).value_counts())\n",
    "    print()\n",
    "    print(\"Origin counts:\")\n",
    "    print(pd.Series(vals).value_counts(normalize = True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relation co-occurrence for each dataset separately\n",
    "\n",
    "For each technique where did the predicted relations come from?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = triple_origin(gold_triples, eval_gold, return_res = True)\n",
    "b = triple_origin(crowd_trip, crowd_full, return_res = True)\n",
    "c = triple_origin(befree_trip, befree_full, return_res = True)\n",
    "\n",
    "rel_origins = pd.DataFrame([a, b, c], index = [\"gold\", \"crowd\", \"befree\"])\n",
    "\n",
    "ax = rel_origins.T.plot(kind = \"bar\", figsize = (5, 7),\n",
    "                    title = \"Origin for gold standard, crowd, and texas relations\")\n",
    "ax.set_ylabel(\"Percent relations\")\n",
    "rel_origins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make one comprehensive dataframe for easier analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_check_exists(df, reference, ref_name):\n",
    "    triple = [\"pmid\", \"chemical_id\", \"disease_id\"]\n",
    "    for col in [\"chemical\", \"disease\"]:\n",
    "        col_name = \"{0}_in_{1}\".format(col[:4], ref_name)\n",
    "        \n",
    "        df.loc[:, col_name] = df[triple].apply(\n",
    "            lambda row: has_concept(reference[int(row[\"pmid\"])], row[\"{}_id\".format(col)]), axis = 1)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def single_triple_origin(pmid, chemical_id, disease_id, reference):\n",
    "    triple = (pmid, chemical_id, disease_id)\n",
    "    \n",
    "    res = rel_origin(triple, reference[pmid])\n",
    "    return \"|\".join(sorted(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def num_times_cooccur(pmid, chemical_id, disease_id, rel_origin, reference):\n",
    "    \"\"\"Given a relation triple and a reference Paper object,\n",
    "    determines how many times the relation cooccurs (a sentence\n",
    "    if CID or sentence, and 1 otherwise (abstract)).\n",
    "    \"\"\"\n",
    "    if not rel_origin:\n",
    "        # was not found using this solution\n",
    "        return np.nan\n",
    "    \n",
    "    if rel_origin == \"abs\":\n",
    "        return 1\n",
    "    \n",
    "    paper = reference[pmid]\n",
    "    \n",
    "    rel = Relation(pmid, chemical_id, disease_id, flat = False)\n",
    "        \n",
    "    ans = 0\n",
    "    for sentence in paper.sentences:\n",
    "        all_rels = sentence.poss_relations[rel_origin == \"CID\"]\n",
    "        all_rels = [Relation(pmid, chem_set, dise_set) for chem_set, dise_set in all_rels]\n",
    "        ans += int(rel in all_rels)\n",
    "        \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creating one comprehensive dataframe for easy result aggregation and querying\n",
    "\n",
    "all_trips = gold_triples | crowd_trip | befree_trip\n",
    "all_df = make_df(all_trips)\n",
    "\n",
    "triple = [\"pmid\", \"chemical_id\", \"disease_id\"]\n",
    "\n",
    "# which triple was found by which solution?\n",
    "for name, reference in zip([\"gold\", \"crowd\", \"befree\"], [gold_triples, crowd_trip, befree_trip]):\n",
    "    all_df.loc[:, \"in_{}\".format(name)] = all_df.loc[:, triple].apply(\n",
    "        lambda row: (row[\"pmid\"], row[\"chemical_id\"], row[\"disease_id\"]) in reference,\n",
    "        axis = 1\n",
    "    )\n",
    "    \n",
    "# were the concepts present in each dataset's concepts?\n",
    "for name, reference in zip([\"gold\", \"crowd\", \"befree\"], [eval_gold, crowd_full, befree_full]):\n",
    "    all_df = new_check_exists(all_df, reference, name)\n",
    "\n",
    "# was the relation sentence bound or abstract level?\n",
    "for name, reference in zip([\"gold\", \"crowd\", \"befree\"], [eval_gold, crowd_full, befree_full]):\n",
    "    colname = \"rel_orig_{}\".format(name)\n",
    "    \n",
    "    all_df.loc[:, colname] = all_df.loc[:, triple].apply(\n",
    "        lambda row: single_triple_origin(row[\"pmid\"], row[\"chemical_id\"], row[\"disease_id\"], reference),\n",
    "        axis = 1\n",
    "    )\n",
    "    \n",
    "# how many times did the two concepts cooccur within the paper?    \n",
    "for name, reference in zip([\"gold\", \"crowd\", \"befree\"], [eval_gold, crowd_full, befree_full]):    \n",
    "    colname = \"cooccur_{}\".format(name)\n",
    "    rel_orig = \"rel_orig_{}\".format(name)\n",
    "    \n",
    "    all_df.loc[:, colname] = all_df.loc[:, triple + [rel_orig]].apply(\n",
    "        lambda row: num_times_cooccur(row[\"pmid\"], row[\"chemical_id\"], row[\"disease_id\"],\n",
    "                                     row[rel_orig], reference),\n",
    "        axis = 1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lel = all_df.query(\"~in_gold and in_crowd and ~in_befree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lel.query(\"~chem_in_gold or ~dise_in_gold\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "162/517"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lel = all_df.query(\"~in_gold and ~in_crowd and in_befree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lel.query(\"~chem_in_gold or ~dise_in_gold\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "150/312"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lel = all_df.query(\"~in_gold and in_crowd and ~in_befree and chem_in_gold and dise_in_gold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many of the sentence and abstract relations did each method find? What was the precision?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def found_stats():\n",
    "    recall = dict()\n",
    "    precision = dict()\n",
    "    for method in [\"crowd\", \"befree\"]:\n",
    "        rec_temp = dict()\n",
    "        pre_temp = dict()\n",
    "        for rel_type in [\"CID\", \"sent\", \"abs\"]:\n",
    "            sub = all_df.query(\"in_gold and rel_orig_gold == '{}'\".format(rel_type))\n",
    "            total = len(sub)\n",
    "            found = len(sub.query(\"in_{}\".format(method)))\n",
    "            \n",
    "            guesses = all_df.query(\"in_{0} and rel_orig_{0} == '{1}'\".format(method, rel_type))\n",
    "            guesses = len(guesses)\n",
    "            \n",
    "            rec_temp[rel_type] = found / total * 100\n",
    "            pre_temp[rel_type] = found / guesses * 100\n",
    "            \n",
    "        recall[method] = rec_temp\n",
    "        precision[method] = pre_temp\n",
    "        \n",
    "    print(recall)\n",
    "        \n",
    "    return (pd.DataFrame(recall), pd.DataFrame(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-108-6502dbd4c791>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrecall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfound_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-107-d03de00dad3f>\u001b[0m in \u001b[0;36mfound_stats\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mpre_temp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mrel_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"CID\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sent\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"abs\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m             \u001b[0msub\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"in_gold and rel_orig_gold == '{}'\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrel_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mfound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"in_{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'all_df' is not defined"
     ]
    }
   ],
   "source": [
    "recall, precision = found_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  etype origin  crowd_wrong  task_limitation  hierarchy_error  \\\n",
    "0    FN    abs     0.666667         0.133333         0.000000   \n",
    "1    FN   sent     0.333333         0.733333         0.000000   \n",
    "2    FP    abs     0.266667         0.133333         0.000000   \n",
    "3    FP   sent     0.333333         0.200000         0.133333   \n",
    "\n",
    "   implicit_relation  lack_of_context  ambiguous  lack_of_comprehension  \\\n",
    "0           0.133333         0.000000   0.000000               0.666667   \n",
    "1           0.000000         0.600000   0.000000               0.133333   \n",
    "2           0.000000         0.000000   0.000000               0.266667   \n",
    "3           0.000000         0.066667   0.066667               0.133333   \n",
    "\n",
    "   ner_error  gold_inconsistent  not_covered_by_instructions  gold_error  \n",
    "0   0.000000           0.000000                     0.000000    0.200000  \n",
    "1   0.000000           0.000000                     0.133333    0.133333  \n",
    "2   0.000000           0.000000                     0.000000    0.733333  \n",
    "3   0.066667           0.066667                     0.000000    0.466667  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'recall' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-110-371df507b184>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m ax = recall.plot(kind = \"bar\", figsize = (4, 5),\n\u001b[0m\u001b[0;32m      2\u001b[0m         title = \"Gold relation recall by relation category\")\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Percent gold relations found\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'recall' is not defined"
     ]
    }
   ],
   "source": [
    "ax = recall.plot(kind = \"bar\", figsize = (4, 5),\n",
    "        title = \"Gold relation recall by relation category\")\n",
    "\n",
    "ax.set_ylabel(\"Percent gold relations found\")\n",
    "\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'precision' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-cd5cd04b1e77>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m ax = precision.plot(kind = \"bar\", figsize = (4, 5),\n\u001b[0m\u001b[0;32m      2\u001b[0m         title = \"Gold relation precision by relation category\")\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Precision of guesses\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'precision' is not defined"
     ]
    }
   ],
   "source": [
    "ax = precision.plot(kind = \"bar\", figsize = (4, 5),\n",
    "        title = \"Gold relation precision by relation category\")\n",
    "\n",
    "ax.set_ylabel(\"Precision of guesses\")\n",
    "\n",
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two solutions found similar fractions of CID and abstract relations. The Texas solution found more sentence relations, but their predictions also contained more sentence-level relations overall. This is bad.. We are showing in different ways why the automated solution was better than our crowd.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Of the relations which neither technique got, why did we not get them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'missing_stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-112-816abef7845d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0munfound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgold_triples\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mcrowd_trip\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbefree_trip\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcrowd_miss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmissing_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munfound\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcrowd_full\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mut_miss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmissing_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munfound\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbefree_full\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'missing_stats' is not defined"
     ]
    }
   ],
   "source": [
    "unfound = gold_triples - crowd_trip - befree_trip\n",
    "\n",
    "crowd_miss = missing_stats(unfound, crowd_full)\n",
    "ut_miss = missing_stats(unfound, befree_full)\n",
    "\n",
    "missing = pd.DataFrame([crowd_miss, ut_miss], index = [\"crowd\", \"befree\"])\n",
    "\n",
    "ax = missing.T.plot(kind = \"bar\", figsize = (7, 7),\n",
    "             title = \"Percent of unfound relations using unknown identifiers\")\n",
    "\n",
    "ax.set_ylabel(\"Percent of concepts in gold relations with unknown IDs\")\n",
    "missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So a vast majority of the missed gold relations were unfound mainly because they used an ID which did not appear anywhere in the NER output for that paper.\n",
    "\n",
    "For the relations which were indexed, what was the scope of the relation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-113-f4e65d21219e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0munfound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"in_gold and ~in_crowd and ~in_texas\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcrowd_miss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munfound\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"chem_in_crowd and dise_in_crowd\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"rel_orig_gold\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtexas_miss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munfound\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"chem_in_texas and dise_in_texas\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"rel_orig_gold\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmissed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcrowd_miss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtexas_miss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"crowd\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"texas\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'all_df' is not defined"
     ]
    }
   ],
   "source": [
    "unfound = all_df.query(\"in_gold and ~in_crowd and ~in_texas\")\n",
    "crowd_miss = unfound.query(\"chem_in_crowd and dise_in_crowd\")[\"rel_orig_gold\"].value_counts(normalize = True) * 100\n",
    "texas_miss = unfound.query(\"chem_in_texas and dise_in_texas\")[\"rel_orig_gold\"].value_counts(normalize = True) * 100\n",
    "\n",
    "missed = pd.DataFrame([crowd_miss, texas_miss], index = [\"crowd\", \"texas\"])\n",
    "\n",
    "ax = missed.T.plot(kind = \"bar\", figsize = (6, 6),\n",
    "                title = \"Relation scope for indexable but missed gold relations\")\n",
    "\n",
    "ax.set_ylabel(\"Percent of gold relations\")\n",
    "missed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both solutions, at least half of the indexable, missed gold relations were abstract scoped, and therefore likely harder to determine correctly. Texas's solution seems to have a slight bias for the abstract scoped relations, but the different is probably not significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the relations which were false positives, what percentage were due to NER errors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'missing_stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-114-bc0c1a3a4bdb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcrowd_befree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcrowd_trip\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mbefree_trip\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mgold_triples\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mcr_miss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmissing_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrowd_only\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_gold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mbefree_miss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmissing_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbefree_only\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_gold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mboth_miss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmissing_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrowd_befree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_gold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'missing_stats' is not defined"
     ]
    }
   ],
   "source": [
    "crowd_only = crowd_trip - gold_triples - befree_trip\n",
    "befree_only = befree_trip - gold_triples - crowd_trip\n",
    "crowd_befree = crowd_trip & befree_trip - gold_triples\n",
    "\n",
    "cr_miss = missing_stats(crowd_only, eval_gold)\n",
    "befree_miss = missing_stats(befree_only, eval_gold)\n",
    "both_miss = missing_stats(crowd_befree, eval_gold)\n",
    "\n",
    "missing = pd.DataFrame([cr_miss, befree_miss, both_miss], index = [\"crowd_only\", \"befree_only\", \"crowd_and_befree\"])\n",
    "\n",
    "ax = missing.T.plot(kind = \"bar\", figsize = (7, 7),\n",
    "                   title = \"Percent of false positive relations\\nusing IDs not included in gold standard\")\n",
    "ax.set_ylabel(\"Percent of relations using IDs nonexistent in gold\")\n",
    "missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A significant number of the false positives for both solutions separately were a result of using MeSH IDs which did not occur in the gold standard. However, the false positives identified by both solutions have a significantly lower rate of NER error, suggesting that these were likely to be real relations which the gold does not include for some reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the gold relations which one solution got but the other missed, why did each solution miss the relations and what kind of relations are they?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-115-9673a240f55e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcrowd_gold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"in_gold and in_crowd and ~in_befree\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mbefree_gold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"in_gold and in_befree and ~in_crowd\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcrowd_gold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_triples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrowd_gold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mbefree_gold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_triples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbefree_gold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'all_df' is not defined"
     ]
    }
   ],
   "source": [
    "crowd_gold = all_df.query(\"in_gold and in_crowd and ~in_befree\")\n",
    "befree_gold = all_df.query(\"in_gold and in_befree and ~in_crowd\")\n",
    "\n",
    "crowd_gold = get_triples(crowd_gold)\n",
    "befree_gold = get_triples(befree_gold)\n",
    "\n",
    "# unindexable by texas, and by crowd\n",
    "miss_by_befree = missing_stats(crowd_gold, befree_full)\n",
    "miss_by_cr = missing_stats(befree_gold, crowd_full)\n",
    "\n",
    "missing = pd.DataFrame([miss_by_befree, miss_by_cr],\n",
    "                       index = [\"crowd_rels_missed_by_befree\", \"texas_rels_missed_by_crowd\"])\n",
    "ax = missing.plot(kind = \"bar\", figsize = (7, 7),\n",
    "                 title = \"Percentage relations found by one solution but\\n\"\n",
    "                 \"missing in the other due to unindexed concept IDs\")\n",
    "ax.set_ylabel(\"Percent of relations using IDs\\nnot indexable by other method\")\n",
    "ax.set_xticklabels(missing.index, rotation = 0)\n",
    "missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the graph above, we see that the relations which our crowd got but Texas didn't only contained a small subset where the relations contained IDs which were not indexed by Texas. In contrast, a lot of the relations (40%) that Texas got but the crowd didn't were because the IDs were never found, not because the crowd is bad at relation extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
