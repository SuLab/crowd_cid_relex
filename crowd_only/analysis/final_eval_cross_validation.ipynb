{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation analysis of final evaluation results between different techniques\n",
    "\n",
    "Tong Shu Li<br>\n",
    "Created on: 2015-10-08<br>\n",
    "Last updated: 2015-10-26\n",
    "\n",
    "The team at UTexas was kind enough to send their final predictions for the CID task. We will compare their results to the crowd's and see where their outputs differed.\n",
    "\n",
    "**Update**: The UTexas team does not want us to publish their results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import rpy2\n",
    "import rpy2.robjects as robjects\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RAND_KEY = np.random.RandomState(20151007)\n",
    "matplotlib.rcParams.update({'font.size': 12})\n",
    "TRIPLE = [\"pmid\", \"chemical_id\", \"disease_id\"]\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option(\"max_colwidth\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from src.lingpipe.file_util import read_file\n",
    "from src.lingpipe.file_util import save_file\n",
    "\n",
    "from src.data_model import Ontology_ID\n",
    "from src.data_model import Relation\n",
    "from src.data_model import parse_input\n",
    "from src.data_model import parse_file\n",
    "from src.data_model import Annotation\n",
    "\n",
    "from src.eval_perf import performance\n",
    "from src.eval_perf import official_F_score\n",
    "from src.parse_mesh import load_mesh\n",
    "from src.get_mesh_terms import Article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_df(triples):\n",
    "    \"\"\"Converts a given set of (pmid, chemical_id, disease_id)\n",
    "    triples into a three column dataframe.\"\"\"\n",
    "    return pd.DataFrame(list(triples), columns = TRIPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_triples(dataframe):\n",
    "    return set(dataframe[TRIPLE].apply(\n",
    "                lambda row: (int(row[\"pmid\"]), row[\"chemical_id\"], row[\"disease_id\"]), axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_set(v):\n",
    "    return \"\\n\".join(map(str, v))\n",
    "\n",
    "def print_to_file(fname, dataset):\n",
    "    with open(fname, \"w\") as fout:\n",
    "        fout.write(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the gold standard and various solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_output(fname):\n",
    "    \"\"\"Read only the CID relations from a Pubtator-formatted\n",
    "    text file.\n",
    "    \"\"\"\n",
    "    temp = defaultdict(list)\n",
    "    for line in read_file(fname):\n",
    "        vals = line.split(\"\\t\")\n",
    "        \n",
    "        if len(vals) > 1 and vals[1] == \"CID\":\n",
    "            temp[\"pmid\"].append(int(vals[0]))\n",
    "            temp[\"chemical_id\"].append(Ontology_ID(vals[2]).flat_repr)\n",
    "            temp[\"disease_id\"].append(Ontology_ID(vals[3]).flat_repr)\n",
    "            \n",
    "            if len(vals) > 4:\n",
    "                temp[\"threshold\"].append(float(vals[4]))\n",
    "\n",
    "    return pd.DataFrame(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_gold_standard(dataset, file_format = \"list\"):\n",
    "    assert dataset in [\"training\", \"development\", \"test\"]\n",
    "    assert file_format in [\"list\", \"dict\"]\n",
    "    \n",
    "    fname = \"parsed_{0}_set_{1}.pickle\".format(dataset, file_format)\n",
    "    \n",
    "    save_loc = os.path.abspath(os.path.join(\"..\", \"data\", \"gold_standard\", fname))\n",
    "    \n",
    "    fname = \"CDR_{0}Set.txt\".format(dataset.capitalize())\n",
    "    loc = os.path.abspath(os.path.join(\"..\", \"data\", \"gold_standard\"))\n",
    "    \n",
    "    return parse_file(save_loc, loc = loc, fname = fname,\n",
    "        is_gold = True, return_format = file_format, fix_acronyms = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def has_concept(paper, concept_id):\n",
    "    concepts = set()\n",
    "    for annot in paper.annotations:\n",
    "        concepts |= set([iden.flat_repr for iden in annot.uid if iden.uid_type == \"MESH\"])\n",
    "    \n",
    "    return concept_id in concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_exists(df, reference):\n",
    "    for col in [\"chemical\", \"disease\"]:\n",
    "        df.loc[:, \"{}_exists\".format(col[:4])] = df[TRIPLE].apply(\n",
    "            lambda row: has_concept(reference[int(row[\"pmid\"])], row[\"{}_id\".format(col)]), axis = 1)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the PMID mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paper_mapping = save_file(\"testset_mapping.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the gold standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_gold = read_gold_standard(\"test\", file_format = \"dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fname = os.path.abspath(os.path.join(\"..\", \"data\", \"gold_standard\", \"CDR_TestSet.txt\"))\n",
    "gold_std = read_output(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab the official MeSH terms for the testset and save to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grab_mesh(papers):\n",
    "    loc = os.path.abspath(os.path.join(\"..\", \"data\", \"gold_standard\", \"testset_mesh_terms.pickle\"))\n",
    "\n",
    "    res = save_file(loc)\n",
    "    if res is not None:\n",
    "        return res\n",
    "    \n",
    "    res = dict()\n",
    "    for pmid in papers:\n",
    "        res[pmid] = Article(pmid)\n",
    "        \n",
    "    save_file(loc, res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mesh_terms = grab_mesh(set(eval_gold.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the crowd's results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loc = os.path.abspath(os.path.join(\"..\", \"data\", \"final_eval\", \"results\", \"crowd_testset.pickle\"))\n",
    "crowd_full = save_file(loc)\n",
    "crowd_res = save_file(\"testset_final_res.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loc = os.path.abspath(os.path.join(\"..\", \"data\", \"final_eval\", \"results\", \"abstract_relation_res.tsv\"))\n",
    "\n",
    "abs_res = pd.read_csv(loc, sep = '\\t', dtype = {\"unit_id\": str})\n",
    "abs_res = abs_res.rename(columns = {\"percent_agree\": \"norm_conf_score\",\n",
    "                                   \"unit_id\": \"unit_ids\"})\n",
    "\n",
    "abs_res.loc[:, \"pmid\"] = abs_res.loc[:, \"pmid\"].map(lambda val: paper_mapping[val])\n",
    "abs_res.loc[:, \"unit_ids\"] = abs_res.loc[:, \"unit_ids\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loc = os.path.abspath(os.path.join(\"..\", \"data\", \"final_eval\", \"results\", \"sentence_relation_abs_res.tsv\"))\n",
    "sent_res = pd.read_csv(loc, sep = '\\t', dtype = {\"unit_ids\": str})\n",
    "\n",
    "sent_res = sent_res.rename(columns = {\"conf_score\": \"norm_conf_score\",\n",
    "                                      \"score_vote_max\": \"num_votes\"})\n",
    "\n",
    "sent_res.loc[:, \"pmid\"] = sent_res.loc[:, \"pmid\"].map(lambda val: paper_mapping[val])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read BeFree's results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = os.path.abspath(os.path.join(\"..\", \"data\", \"befree\", \"final_eval\", \"befree_testset_results.txt\"))\n",
    "befree_res = read_output(fname)\n",
    "\n",
    "befree_res.loc[:, \"pmid\"] = befree_res[\"pmid\"].map(lambda val: paper_mapping[val])\n",
    "befree_res[\"threshold\"] = 1\n",
    "\n",
    "befree_res = check_exists(befree_res, eval_gold)\n",
    "\n",
    "#----------------------------------\n",
    "\n",
    "def get_befree():\n",
    "    loc = os.path.join(\"..\", \"data\", \"befree\", \"final_eval\")\n",
    "\n",
    "    save_loc = os.path.abspath(os.path.join(loc, \"befree_testset_full.pickle\"))\n",
    "    res = save_file(save_loc)\n",
    "    if res is not None:\n",
    "        return res\n",
    "\n",
    "    befree_full = parse_input(os.path.abspath(loc), \"befree_testset_results.txt\",\n",
    "                         is_gold = True, return_format = \"dict\", fix_acronyms = False)\n",
    "\n",
    "    temp = dict()\n",
    "    for pmid, paper in befree_full.items():\n",
    "        paper.pmid = paper_mapping[pmid]\n",
    "        temp[paper_mapping[pmid]] = paper\n",
    "\n",
    "    save_file(save_loc, temp)\n",
    "    return temp\n",
    "    \n",
    "befree_full = get_befree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chemical_id</th>\n",
       "      <th>disease_id</th>\n",
       "      <th>pmid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MESH:D015738</td>\n",
       "      <td>MESH:D003693</td>\n",
       "      <td>8701013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MESH:D007213</td>\n",
       "      <td>MESH:D007022</td>\n",
       "      <td>439781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MESH:D016572</td>\n",
       "      <td>MESH:D057049</td>\n",
       "      <td>22836123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MESH:D000305</td>\n",
       "      <td>MESH:D012595</td>\n",
       "      <td>22836123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MESH:D016559</td>\n",
       "      <td>MESH:D012595</td>\n",
       "      <td>22836123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    chemical_id    disease_id      pmid\n",
       "0  MESH:D015738  MESH:D003693   8701013\n",
       "1  MESH:D007213  MESH:D007022    439781\n",
       "2  MESH:D016572  MESH:D057049  22836123\n",
       "3  MESH:D000305  MESH:D012595  22836123\n",
       "4  MESH:D016559  MESH:D012595  22836123"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chemical_id</th>\n",
       "      <th>disease_id</th>\n",
       "      <th>norm_conf_score</th>\n",
       "      <th>num_votes</th>\n",
       "      <th>pmid</th>\n",
       "      <th>rel_origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MESH:C009695</td>\n",
       "      <td>MESH:D000699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>35781</td>\n",
       "      <td>sentence_task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MESH:C009695</td>\n",
       "      <td>MESH:D002375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>35781</td>\n",
       "      <td>sentence_task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MESH:D003000</td>\n",
       "      <td>MESH:D000699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>35781</td>\n",
       "      <td>sentence_task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MESH:D009278</td>\n",
       "      <td>MESH:D002375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>35781</td>\n",
       "      <td>sentence_task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MESH:D009638</td>\n",
       "      <td>MESH:D000699</td>\n",
       "      <td>0.185347</td>\n",
       "      <td>1</td>\n",
       "      <td>35781</td>\n",
       "      <td>abstract_task</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    chemical_id    disease_id  norm_conf_score  num_votes   pmid  \\\n",
       "0  MESH:C009695  MESH:D000699         0.000000          0  35781   \n",
       "1  MESH:C009695  MESH:D002375         0.000000          0  35781   \n",
       "2  MESH:D003000  MESH:D000699         0.000000          0  35781   \n",
       "3  MESH:D009278  MESH:D002375         0.000000          0  35781   \n",
       "4  MESH:D009638  MESH:D000699         0.185347          1  35781   \n",
       "\n",
       "      rel_origin  \n",
       "0  sentence_task  \n",
       "1  sentence_task  \n",
       "2  sentence_task  \n",
       "3  sentence_task  \n",
       "4  abstract_task  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crowd_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chemical_id</th>\n",
       "      <th>disease_id</th>\n",
       "      <th>pmid</th>\n",
       "      <th>threshold</th>\n",
       "      <th>chem_exists</th>\n",
       "      <th>dise_exists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MESH:D015738</td>\n",
       "      <td>MESH:D003693</td>\n",
       "      <td>8701013</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MESH:D007213</td>\n",
       "      <td>MESH:D007022</td>\n",
       "      <td>439781</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MESH:D016559</td>\n",
       "      <td>MESH:D045743</td>\n",
       "      <td>22836123</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MESH:D008694</td>\n",
       "      <td>MESH:D011618</td>\n",
       "      <td>23433219</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MESH:D007980</td>\n",
       "      <td>MESH:D004409</td>\n",
       "      <td>23535177</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    chemical_id    disease_id      pmid  threshold chem_exists dise_exists\n",
       "0  MESH:D015738  MESH:D003693   8701013          1        True        True\n",
       "1  MESH:D007213  MESH:D007022    439781          1        True        True\n",
       "2  MESH:D016559  MESH:D045743  22836123          1        True       False\n",
       "3  MESH:D008694  MESH:D011618  23433219          1        True       False\n",
       "4  MESH:D007980  MESH:D004409  23535177          1        True        True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "befree_res.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall performance against the gold standard\n",
    "\n",
    "Using the official evaluation of the CID relation performance, how did each solution do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the gold standard triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gold_triples = get_triples(gold_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crowd performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.267624</td>\n",
       "      <td>0.162805</td>\n",
       "      <td>0.751407</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.356317</td>\n",
       "      <td>0.236486</td>\n",
       "      <td>0.722326</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.444779</td>\n",
       "      <td>0.327426</td>\n",
       "      <td>0.693246</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.496480</td>\n",
       "      <td>0.410288</td>\n",
       "      <td>0.628518</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.505929</td>\n",
       "      <td>0.475640</td>\n",
       "      <td>0.540338</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.465066</td>\n",
       "      <td>0.556136</td>\n",
       "      <td>0.399625</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.003742</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    F_score  precision    recall  threshold\n",
       "0  0.267624   0.162805  0.751407          0\n",
       "1  0.356317   0.236486  0.722326          1\n",
       "2  0.444779   0.327426  0.693246          2\n",
       "3  0.496480   0.410288  0.628518          3\n",
       "4  0.505929   0.475640  0.540338          4\n",
       "5  0.465066   0.556136  0.399625          5\n",
       "6  0.003742   0.666667  0.001876          6"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "official_F_score(\"num_votes\", gold_triples, crowd_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BeFree performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.486874</td>\n",
       "      <td>0.382739</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    F_score  precision    recall  threshold\n",
       "0  0.428571   0.486874  0.382739          1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "official_F_score(\"threshold\", gold_triples, befree_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My calculations show that BeFree's official published performance (F 0.4281) is slightly worse than what I have calculated, despite my method accurately reproducing both UTexas's and our results. Perhaps Alex sent me a slightly modified version of the data they submitted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crowd_trip = get_triples(crowd_res.query(\"num_votes >= 4\"))\n",
    "befree_trip = get_triples(befree_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance on a subset of relations where the annotations were perfectly identified\n",
    "\n",
    "Since we have seen that NER has a huge influence on the performance, we will look backwards to see what performance was like on relations where both the chemical and disease were perfectly identified (i.e. the annotations all match the gold standard)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_ids(annotations):\n",
    "    concepts = defaultdict(set)\n",
    "    for annot in annotations:\n",
    "        concepts[annot.stype].add(annot.uid)\n",
    "\n",
    "    return concepts\n",
    "\n",
    "def expand_set(vals):\n",
    "    res = set()\n",
    "    for v in vals:\n",
    "        res |= v\n",
    "        \n",
    "    return res\n",
    "\n",
    "def find_perfect_subset(reference, gold_std):\n",
    "    \"\"\"Given a gold standard, the predictions, and the triple sets,\n",
    "    removes relations which used concepts that had annotation mismatches\n",
    "    between the predictions and the gold.\n",
    "    \"\"\"\n",
    "    good_trips = set()\n",
    "    for pmid, gold_paper in gold_std.items():\n",
    "        paper = reference[pmid]\n",
    "\n",
    "        # annotations\n",
    "        predict_annot = set(paper.annotations)\n",
    "        gold_annot = set(gold_paper.annotations)\n",
    "        \n",
    "        shared_concepts = extract_ids(gold_annot & predict_annot)\n",
    "        missed_concepts = extract_ids(gold_annot ^ predict_annot)\n",
    "        \n",
    "        perf_chem = shared_concepts[\"chemical\"] - missed_concepts[\"chemical\"]\n",
    "        perf_dise = shared_concepts[\"disease\"] - missed_concepts[\"disease\"]\n",
    "        \n",
    "        chems = expand_set(perf_chem)\n",
    "        dises = expand_set(perf_dise)\n",
    "            \n",
    "        good_trips |= set([(pmid, chem.flat_repr, dise.flat_repr) for chem in chems for dise in dises])\n",
    "\n",
    "    return good_trips\n",
    "\n",
    "def perfect_perf(predict_full, orig_df, threshold, gold_std, gold_trip):\n",
    "    poss_good_trips = find_perfect_subset(predict_full, gold_std)\n",
    "    \n",
    "    # all pmids where there was at least one (chemical, disease) pair\n",
    "    # where both concepts were annotated perfectly between the gold\n",
    "    # and the method's NER outputs\n",
    "    good_pmids = {val[0] for val in poss_good_trips}\n",
    "    \n",
    "    predict_trip = get_triples(orig_df)    \n",
    "    \n",
    "    # filter gold standard relations and predicted relations by\n",
    "    # whether both concepts were perfectly annotated in both gold\n",
    "    # and the predictions\n",
    "    good_pred_trip = poss_good_trips & predict_trip\n",
    "    good_gold_trip = poss_good_trips & gold_trip\n",
    "    \n",
    "    assert good_pmids >= {v[0] for v in good_pred_trip} | {v[0] for v in good_gold_trip}\n",
    "    \n",
    "    print(\"# of gold triples {}\".format(len(good_gold_trip)))\n",
    "    \n",
    "    # subset the original predictions down to those with perfect\n",
    "    # annotations\n",
    "    good_pred_df = make_df(good_pred_trip)\n",
    "    pred_sub = pd.merge(good_pred_df, orig_df, how = \"left\", on = [\"pmid\", \"chemical_id\", \"disease_id\"])\n",
    "    \n",
    "    return (pred_sub, official_F_score(threshold, good_gold_trip, pred_sub),\n",
    "            make_df(good_gold_trip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of gold triples 485\n"
     ]
    }
   ],
   "source": [
    "crowd_no_ner, crowd_no_ner_perf, crowd_good_gold = perfect_perf(crowd_full,\n",
    "                                crowd_res, \"num_votes\", eval_gold, gold_triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.318346</td>\n",
       "      <td>0.189305</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.434339</td>\n",
       "      <td>0.280240</td>\n",
       "      <td>0.964948</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.381356</td>\n",
       "      <td>0.927835</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.615958</td>\n",
       "      <td>0.482477</td>\n",
       "      <td>0.851546</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.645447</td>\n",
       "      <td>0.565015</td>\n",
       "      <td>0.752577</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.603732</td>\n",
       "      <td>0.645540</td>\n",
       "      <td>0.567010</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.008214</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004124</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    F_score  precision    recall  threshold\n",
       "0  0.318346   0.189305  1.000000          0\n",
       "1  0.434339   0.280240  0.964948          1\n",
       "2  0.540541   0.381356  0.927835          2\n",
       "3  0.615958   0.482477  0.851546          3\n",
       "4  0.645447   0.565015  0.752577          4\n",
       "5  0.603732   0.645540  0.567010          5\n",
       "6  0.008214   1.000000  0.004124          6"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crowd_no_ner_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are slightly better than the simple NER filtering that I was using before, where I only check whether the concept was identified at all in the paper. However, the performance is basically the same, still in the low 0.6 F range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of gold triples 460\n"
     ]
    }
   ],
   "source": [
    "befree_no_ner, befree_no_ner_perf, befree_good_gold = perfect_perf(befree_full, befree_res, \"threshold\", eval_gold, gold_triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.588774</td>\n",
       "      <td>0.622276</td>\n",
       "      <td>0.558696</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    F_score  precision    recall  threshold\n",
       "0  0.588774   0.622276  0.558696          1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "befree_no_ner_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error analysis\n",
    "\n",
    "Null hypothesis: the origin of a relation is independent of the category that the relation belongs to (true positive, false positive, false negative).\n",
    "\n",
    "We use the Chi square test to determine whether the null hypothesis is true. We will group CID and sentence bound relations together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def converter(pmid, poss_relations):\n",
    "    return [Relation(pmid, rel[0], rel[1]) for rel in poss_relations]\n",
    "\n",
    "def rel_origin(triple, paper):\n",
    "    relation = Relation(paper.pmid, triple[1], triple[2], flat = False)\n",
    "\n",
    "    rename = {\n",
    "        \"CID\": \"sent\",\n",
    "        \"sentence_non_CID\": \"sent\",\n",
    "        \"not_sentence_bound\": \"abs\"\n",
    "    }\n",
    "    \n",
    "    ans = []\n",
    "    for key, val in paper.poss_relations.items():\n",
    "        value = converter(paper.pmid, val)\n",
    "        if relation in value:\n",
    "            ans.append(rename[key])\n",
    "\n",
    "    return \"|\".join(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def single_triple(row):\n",
    "    return (int(row[\"pmid\"]), row[\"chemical_id\"], row[\"disease_id\"])\n",
    "\n",
    "def make_summary(predictions, gold_std):\n",
    "    temp = pd.merge(predictions[TRIPLE], gold_std[TRIPLE], how = \"outer\", on = TRIPLE)\n",
    "    \n",
    "    pred_trip = get_triples(predictions)\n",
    "    gold_trip = get_triples(gold_std)\n",
    "    \n",
    "    temp.loc[:, \"in_gold\"] = temp.loc[:, TRIPLE].apply(\n",
    "        lambda row: single_triple(row) in gold_trip, axis = 1\n",
    "    )\n",
    "    \n",
    "    temp.loc[:, \"in_predict\"] = temp.loc[:, TRIPLE].apply(\n",
    "        lambda row: single_triple(row) in pred_trip, axis = 1\n",
    "    )\n",
    "    \n",
    "    temp.loc[:, \"rel_origin\"] = temp.loc[:, TRIPLE].apply(\n",
    "        lambda row: rel_origin(single_triple(row), eval_gold[row[\"pmid\"]]), axis = 1\n",
    "    )\n",
    "    \n",
    "    temp.loc[:, \"pmid\"] = temp.loc[:, \"pmid\"].astype(int)\n",
    "    \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def category_splitter(predict_res, gold_std, option = \"\"):\n",
    "    \"\"\"A generator for categories of relations.\"\"\"\n",
    "    predict = make_summary(predict_res, gold_std)\n",
    "    \n",
    "    error_type = [\"TP\", \"FP\", \"FN\"]\n",
    "    vals = [(True, True), (False, True), (True, False)] # gold, predict\n",
    "    \n",
    "    for etype, val in zip(error_type, vals):\n",
    "        sub = predict.query(\"in_gold == {} and in_predict == {}{}\".format(\n",
    "            val[0], val[1], option\n",
    "        )).dropna()\n",
    "        \n",
    "        yield (etype, sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def two_samp_ttest(res):\n",
    "    ttest = robjects.r[\"t.test\"]\n",
    "    for a, b in combinations([\"TP\", \"FP\", \"FN\"], 2):\n",
    "        print(\"T test between {} and {}\".format(a, b))\n",
    "        result = ttest(res[a], res[b])\n",
    "        # don't print the acutal series themselves\n",
    "        # result[8] contains the data.name vectors\n",
    "        # overwriting with zero suppresses superfluous output\n",
    "        result[8] = 0\n",
    "        print(result)\n",
    "        print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_origin(pred_res, gold_std):\n",
    "    \"\"\"Apply the Chi-square test to see if a relation's\n",
    "    origin is independent of the category of error it\n",
    "    belongs to.\n",
    "    \"\"\"\n",
    "    chisqtest = robjects.r[\"chisq.test\"]\n",
    "    \n",
    "    res = dict()\n",
    "    for etype, sub in category_splitter(pred_res, gold_std):\n",
    "        res[etype] = sub[\"rel_origin\"].value_counts()[[\"sent\", \"abs\"]]\n",
    "        \n",
    "    res = pd.DataFrame(res).T\n",
    "    \n",
    "    print(chisqtest(res))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tPearson's Chi-squared test\n",
      "\n",
      "data:  structure(list(sent = structure(c(55L, 181L, 290L), .Dim = 3L),     abs = structure(c(65L, 100L, 74L), .Dim = 3L)), .Names = c(\"sent\", \"abs\"), row.names = c(\"FN\", \"FP\", \"TP\"), class = \"data.frame\")\n",
      "X-squared = 52.006, df = 2, p-value = 5.095e-12\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FN</th>\n",
       "      <td>55</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FP</th>\n",
       "      <td>181</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP</th>\n",
       "      <td>290</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sent  abs\n",
       "FN    55   65\n",
       "FP   181  100\n",
       "TP   290   74"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_origin(crowd_no_ner.query(\"num_votes >= 4\"), crowd_good_gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tPearson's Chi-squared test\n",
      "\n",
      "data:  structure(list(sent = structure(c(109L, 77L, 212L), .Dim = 3L),     abs = structure(c(93L, 79L, 45L), .Dim = 3L)), .Names = c(\"sent\", \"abs\"), row.names = c(\"FN\", \"FP\", \"TP\"), class = \"data.frame\")\n",
      "X-squared = 61.902, df = 2, p-value = 3.615e-14\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FN</th>\n",
       "      <td>109</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FP</th>\n",
       "      <td>77</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP</th>\n",
       "      <td>212</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sent  abs\n",
       "FN   109   93\n",
       "FP    77   79\n",
       "TP   212   45"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_origin(befree_no_ner, befree_good_gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So based on the high values of the test statistic, it seems that the relation origin is not independent of the category of the relation for all three different solutions. This means that the three different subgroups have different proportions of abstract and sentence bound relations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual error analysis sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crowd_summary = make_summary(crowd_no_ner.query(\"num_votes >= 4\"), crowd_good_gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = crowd_summary.columns | [\"unit_ids\"]\n",
    "\n",
    "crowd_summary = pd.merge(crowd_summary,\n",
    "    pd.concat([sent_res, abs_res]), how = \"left\", on = TRIPLE)[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null unit ids section is for CID relations which have no corresponding work units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-test of length for abstract scope errors\n",
    "\n",
    "For the relations which are abstract scoped, does crowd performance depend upon how long the abstracts are? I.e., do workers perform worse on longer abstracts because there's more reading?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ttest_length(pred_res, gold_std, gold_full, test):\n",
    "    \"\"\"Apply the Student's t-test to see if the category an\n",
    "    abstract relation falls into is determined by the length\n",
    "    of the abstract or the number of sentences.\n",
    "    \"\"\"\n",
    "    assert test in [\"length\", \"sentences\"]\n",
    "    \n",
    "    res = dict()    \n",
    "    for e_type, sub in category_splitter(pred_res, gold_std, \" and rel_origin == 'abs'\"):\n",
    "        papers = list(sub[\"pmid\"])\n",
    "        if test == \"length\":\n",
    "            res[e_type] = pd.Series([\n",
    "                len(gold_full[pmid].title) + len(gold_full[pmid].abstract) + 1\n",
    "                for pmid in papers\n",
    "            ])\n",
    "        elif test == \"sentences\":\n",
    "            res[e_type] = pd.Series([\n",
    "                len(gold_full[pmid].sentences) for pmid in papers\n",
    "            ])\n",
    "        \n",
    "    two_samp_ttest(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T test between TP and FP\n",
      "\n",
      "\tWelch Two Sample t-test\n",
      "\n",
      "data:  0\n",
      "t = 1.4014, df = 159.92, p-value = 0.163\n",
      "alternative hypothesis: true difference in means is not equal to 0\n",
      "95 percent confidence interval:\n",
      " -41.2189 242.6632\n",
      "sample estimates:\n",
      "mean of x mean of y \n",
      " 1364.662  1263.940 \n",
      "\n",
      "\n",
      "-----------------------------\n",
      "T test between TP and FN\n",
      "\n",
      "\tWelch Two Sample t-test\n",
      "\n",
      "data:  0\n",
      "t = -1.9551, df = 129.78, p-value = 0.05272\n",
      "alternative hypothesis: true difference in means is not equal to 0\n",
      "95 percent confidence interval:\n",
      " -328.40695    1.94666\n",
      "sample estimates:\n",
      "mean of x mean of y \n",
      " 1364.662  1527.892 \n",
      "\n",
      "\n",
      "-----------------------------\n",
      "T test between FP and FN\n",
      "\n",
      "\tWelch Two Sample t-test\n",
      "\n",
      "data:  0\n",
      "t = -3.3129, df = 129.25, p-value = 0.001198\n",
      "alternative hypothesis: true difference in means is not equal to 0\n",
      "95 percent confidence interval:\n",
      " -421.5881 -106.3165\n",
      "sample estimates:\n",
      "mean of x mean of y \n",
      " 1263.940  1527.892 \n",
      "\n",
      "\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "ttest_length(crowd_no_ner.query(\"num_votes >= 4\"), crowd_good_gold, eval_gold, \"length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T test between TP and FP\n",
      "\n",
      "\tWelch Two Sample t-test\n",
      "\n",
      "data:  0\n",
      "t = 0.75537, df = 165.67, p-value = 0.4511\n",
      "alternative hypothesis: true difference in means is not equal to 0\n",
      "95 percent confidence interval:\n",
      " -0.6210935  1.3908233\n",
      "sample estimates:\n",
      "mean of x mean of y \n",
      " 9.864865  9.480000 \n",
      "\n",
      "\n",
      "-----------------------------\n",
      "T test between TP and FN\n",
      "\n",
      "\tWelch Two Sample t-test\n",
      "\n",
      "data:  0\n",
      "t = -1.8031, df = 122.4, p-value = 0.07384\n",
      "alternative hypothesis: true difference in means is not equal to 0\n",
      "95 percent confidence interval:\n",
      " -2.3168117  0.1080799\n",
      "sample estimates:\n",
      "mean of x mean of y \n",
      " 9.864865 10.969231 \n",
      "\n",
      "\n",
      "-----------------------------\n",
      "T test between FP and FN\n",
      "\n",
      "\tWelch Two Sample t-test\n",
      "\n",
      "data:  0\n",
      "t = -2.4676, df = 125.71, p-value = 0.01495\n",
      "alternative hypothesis: true difference in means is not equal to 0\n",
      "95 percent confidence interval:\n",
      " -2.6835931 -0.2948684\n",
      "sample estimates:\n",
      "mean of x mean of y \n",
      "  9.48000  10.96923 \n",
      "\n",
      "\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "ttest_length(crowd_no_ner.query(\"num_votes >= 4\"), crowd_good_gold, eval_gold, \"sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T test between TP and FP\n",
      "\n",
      "\tWelch Two Sample t-test\n",
      "\n",
      "data:  0\n",
      "t = -1.3116, df = 80.476, p-value = 0.1934\n",
      "alternative hypothesis: true difference in means is not equal to 0\n",
      "95 percent confidence interval:\n",
      " -275.64730   56.63352\n",
      "sample estimates:\n",
      "mean of x mean of y \n",
      " 1447.822  1557.329 \n",
      "\n",
      "\n",
      "-----------------------------\n",
      "T test between TP and FN\n",
      "\n",
      "\tWelch Two Sample t-test\n",
      "\n",
      "data:  0\n",
      "t = -0.23017, df = 104.82, p-value = 0.8184\n",
      "alternative hypothesis: true difference in means is not equal to 0\n",
      "95 percent confidence interval:\n",
      " -204.0291  161.5875\n",
      "sample estimates:\n",
      "mean of x mean of y \n",
      " 1447.822  1469.043 \n",
      "\n",
      "\n",
      "-----------------------------\n",
      "T test between FP and FN\n",
      "\n",
      "\tWelch Two Sample t-test\n",
      "\n",
      "data:  0\n",
      "t = 1.1763, df = 164.1, p-value = 0.2412\n",
      "alternative hypothesis: true difference in means is not equal to 0\n",
      "95 percent confidence interval:\n",
      " -59.91545 236.48766\n",
      "sample estimates:\n",
      "mean of x mean of y \n",
      " 1557.329  1469.043 \n",
      "\n",
      "\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "ttest_length(befree_no_ner, befree_good_gold, eval_gold, \"length\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crowd:\n",
    "\n",
    "**Hypothesis**: Workers are more likely to have difficulty with long abstracts due to the amount of reading and long-distance word dependencies.\n",
    "\n",
    "Based on the t-test results, it seems that there is no difference in length between the true positives and false positives or false negatives. However, there does seem to be a difference in length between the false positives and the false negatives. The false positives were significantly more likely to arise from abstracts which were shorter in length, while the false negatives were more likely to be in longer abstracts.\n",
    "\n",
    "We see no such evidence of such a dependency in both of the machine learning approaches. Length of the abstract has no bearing on what kind of category the relation will fall into.\n",
    "\n",
    "Number of sentences has no effect either.\n",
    "\n",
    "I think that the last result supports the hypothesis that workers are more likely to miss relations in longer abstracts due to more reading and long scale word dependency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallelism test\n",
    "\n",
    "**Hypothesis**: false positives are likely to show up in sentences containing other true positives.\n",
    "\n",
    "Example: in PMID 3289726, the gold has three relations, between etoposide (D005047) and three diseases: confusion (D003221), seizure (D012640), and papilledema (D010211). The abstract states: \"Significant clinical manifestations have included confusion, papilledema, somnolence, exacerbation of motor deficits, and sharp increase in seizure activity.\"\n",
    "\n",
    "Therefore all of the mentioned diseases are related to etoposide. There should in reality be 5 relations in the gold, but one is not possible (motor deficits) because there is no corresponding MeSH term, and the other seems to be a missing relation (a mistake) in the gold standard. However, the missing relation was stated as true with high confidence by our crowd, so we can use this as a filter to find false positives by the crowd which are likely to be true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_concepts(stype, sentence):\n",
    "    res = set()\n",
    "    for annot in sentence.annotations:\n",
    "        if annot.stype == stype:\n",
    "            res |= annot.uid\n",
    "        \n",
    "    return res\n",
    "\n",
    "def count_parallel(pmid, chem, dise):\n",
    "    \"\"\"For a given relation, look at the sentence that the\n",
    "    disease is in and look for true relations using the\n",
    "    chemical and another disease in the same sentence.\n",
    "    \n",
    "    Usually there is parallelism and the list of diseases\n",
    "    in the sentence will all be true (as a list of symptoms\n",
    "    for that chemical etc.)\n",
    "    \n",
    "    Example: PMID 3289726, where one sentence contains all the\n",
    "    true relations.\n",
    "    \"\"\"\n",
    "    paper = eval_gold[pmid]\n",
    "    \n",
    "    # find the sentences containing the disease id\n",
    "    chem_id = Ontology_ID(chem)\n",
    "    dise_id = Ontology_ID(dise)   \n",
    "    \n",
    "    res = 0\n",
    "    for sentence in paper.sentences:\n",
    "        concepts = get_concepts(\"disease\", sentence)\n",
    "\n",
    "        if dise_id in concepts:\n",
    "            other = concepts - set([dise_id])\n",
    "            \n",
    "            poss = [Relation(pmid, frozenset([chem_id]),\n",
    "                frozenset([concept])) for concept in other]\n",
    "            \n",
    "            ans = [int(paper.has_relation(val)) for val in poss]\n",
    "            res += sum(ans)\n",
    "            \n",
    "    return res       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ttest_parallel(pred_res, gold_std, gold_full):\n",
    "    \"\"\"Determine whether the category of a relation is independent\n",
    "    of the number of other parallel relations in the same sentence.\n",
    "    \"\"\"\n",
    "    res = dict()\n",
    "    for e_type, sub in category_splitter(pred_res, gold_std, \" and rel_origin == 'abs'\"):\n",
    "        res[e_type] = pd.Series(sub[TRIPLE].apply(\n",
    "            lambda r: count_parallel(r[\"pmid\"], r[\"chemical_id\"], r[\"disease_id\"]),\n",
    "            axis = 1\n",
    "        ))\n",
    "        \n",
    "    two_samp_ttest(res)        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T test between TP and FP\n",
      "\n",
      "\tWelch Two Sample t-test\n",
      "\n",
      "data:  0\n",
      "t = 5.3173, df = 138.49, p-value = 4.119e-07\n",
      "alternative hypothesis: true difference in means is not equal to 0\n",
      "95 percent confidence interval:\n",
      " 0.7783989 1.6999795\n",
      "sample estimates:\n",
      "mean of x mean of y \n",
      " 1.689189  0.450000 \n",
      "\n",
      "\n",
      "-----------------------------\n",
      "T test between TP and FN\n",
      "\n",
      "\tWelch Two Sample t-test\n",
      "\n",
      "data:  0\n",
      "t = -0.34741, df = 121.76, p-value = 0.7289\n",
      "alternative hypothesis: true difference in means is not equal to 0\n",
      "95 percent confidence interval:\n",
      " -0.7422382  0.5206165\n",
      "sample estimates:\n",
      "mean of x mean of y \n",
      " 1.689189  1.800000 \n",
      "\n",
      "\n",
      "-----------------------------\n",
      "T test between FP and FN\n",
      "\n",
      "\tWelch Two Sample t-test\n",
      "\n",
      "data:  0\n",
      "t = -4.6709, df = 99.281, p-value = 9.427e-06\n",
      "alternative hypothesis: true difference in means is not equal to 0\n",
      "95 percent confidence interval:\n",
      " -1.9234712 -0.7765288\n",
      "sample estimates:\n",
      "mean of x mean of y \n",
      "     0.45      1.80 \n",
      "\n",
      "\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "res = ttest_parallel(crowd_no_ner.query(\"num_votes >= 4\"), crowd_good_gold, eval_gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    21\n",
       "0    20\n",
       "1    18\n",
       "3     6\n",
       "6     4\n",
       "5     3\n",
       "4     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"TP\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    83\n",
       "1     8\n",
       "3     4\n",
       "7     3\n",
       "2     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"FP\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29\n",
       "4    10\n",
       "1     8\n",
       "2     7\n",
       "5     5\n",
       "6     4\n",
       "3     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"FN\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fps = crowd_summary.query(\"~in_gold and in_predict and rel_origin == 'abs'\")\n",
    "\n",
    "fps.loc[:, \"link\"] = fps.loc[:, \"unit_ids\"].map(lambda v: \"https://crowdflower.com/jobs/767273/units/{}\".format(v))\n",
    "\n",
    "fps.loc[:, \"parallel\"] = fps.loc[:, TRIPLE].apply(\n",
    "    lambda r: count_parallel(r[\"pmid\"], r[\"chemical_id\"], r[\"disease_id\"]),\n",
    "    axis = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chemical_id</th>\n",
       "      <th>disease_id</th>\n",
       "      <th>in_gold</th>\n",
       "      <th>in_predict</th>\n",
       "      <th>pmid</th>\n",
       "      <th>rel_origin</th>\n",
       "      <th>unit_ids</th>\n",
       "      <th>link</th>\n",
       "      <th>parallel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>MESH:D004317</td>\n",
       "      <td>MESH:D060831</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>11745287</td>\n",
       "      <td>abs</td>\n",
       "      <td>773937713</td>\n",
       "      <td>https://crowdflower.com/jobs/767273/units/773937713</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>MESH:D016190</td>\n",
       "      <td>MESH:D060831</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>11745287</td>\n",
       "      <td>abs</td>\n",
       "      <td>773937706</td>\n",
       "      <td>https://crowdflower.com/jobs/767273/units/773937706</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>MESH:D004317</td>\n",
       "      <td>MESH:D013280</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>11745287</td>\n",
       "      <td>abs</td>\n",
       "      <td>773937712</td>\n",
       "      <td>https://crowdflower.com/jobs/767273/units/773937712</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>MESH:D005047</td>\n",
       "      <td>MESH:D006970</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3289726</td>\n",
       "      <td>abs</td>\n",
       "      <td>773936980</td>\n",
       "      <td>https://crowdflower.com/jobs/767273/units/773936980</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>MESH:D003613</td>\n",
       "      <td>MESH:D063806</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2358093</td>\n",
       "      <td>abs</td>\n",
       "      <td>773936830</td>\n",
       "      <td>https://crowdflower.com/jobs/767273/units/773936830</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>MESH:D002231</td>\n",
       "      <td>MESH:D005076</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>19263707</td>\n",
       "      <td>abs</td>\n",
       "      <td>773938382</td>\n",
       "      <td>https://crowdflower.com/jobs/767273/units/773938382</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>MESH:D014635</td>\n",
       "      <td>MESH:D001523</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>24614773</td>\n",
       "      <td>abs</td>\n",
       "      <td>773936176</td>\n",
       "      <td>https://crowdflower.com/jobs/767273/units/773936176</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      chemical_id    disease_id in_gold in_predict      pmid rel_origin  \\\n",
       "207  MESH:D004317  MESH:D060831   False       True  11745287        abs   \n",
       "440  MESH:D016190  MESH:D060831   False       True  11745287        abs   \n",
       "566  MESH:D004317  MESH:D013280   False       True  11745287        abs   \n",
       "110  MESH:D005047  MESH:D006970   False       True   3289726        abs   \n",
       "415  MESH:D003613  MESH:D063806   False       True   2358093        abs   \n",
       "548  MESH:D002231  MESH:D005076   False       True  19263707        abs   \n",
       "602  MESH:D014635  MESH:D001523   False       True  24614773        abs   \n",
       "\n",
       "      unit_ids                                                 link  parallel  \n",
       "207  773937713  https://crowdflower.com/jobs/767273/units/773937713         7  \n",
       "440  773937706  https://crowdflower.com/jobs/767273/units/773937706         7  \n",
       "566  773937712  https://crowdflower.com/jobs/767273/units/773937712         7  \n",
       "110  773936980  https://crowdflower.com/jobs/767273/units/773936980         3  \n",
       "415  773936830  https://crowdflower.com/jobs/767273/units/773936830         3  \n",
       "548  773938382  https://crowdflower.com/jobs/767273/units/773938382         3  \n",
       "602  773936176  https://crowdflower.com/jobs/767273/units/773936176         3  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fps.query(\"parallel > 2\").sort(\"parallel\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Based on the data, we see that the true positive abstract-scope relations usually use diseases which occur in sentences with other diseases which also are related to the current chemical (mean 1.7 other instances). However, with the false positives, this is no longer true (mean 0.45). Based on these data, we propose using the number of parallel relations as a filter for determining errors in the gold standard. As in, relations which were left out in the gold standard, but should really be true because they are in sentences where the other relations were all related to the same chemical. We posit that these relations were missed due to human error. The list is given in the cell above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence-bound relations\n",
    "\n",
    "**Hypothesis**: for sentence-bound relations, the crowd performs better when the amount of context increases, that is, the number of tasks (sentences) that the two concepts cooccur in increases. If there is too little context, i.e. only one task (sentence) for a single relation, then we would expect the workers to do poorly because the sentence is taken out of context. In contrast, if there were multiple tasks, then we expect that it is more likely that one of the sentences will have captured the true relationship between the concepts, and therefore giving a higher probability that the crowd will identify the true relation.\n",
    "\n",
    "Therefore we expect that the category of a relation (TP, FP, FN) will not be independent of the number of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ttest_freq(summary):\n",
    "    error_type = [\"TP\", \"FP\", \"FN\"]\n",
    "    vals = [(True, True), (False, True), (True, False)] # gold, predict\n",
    "    \n",
    "    res = dict()\n",
    "    for etype, val in zip(error_type, vals):\n",
    "        sub = summary.query(\"in_gold == {} and in_predict == {} and rel_origin == 'sent'\".format(\n",
    "            val[0], val[1])\n",
    "        ).dropna() # CID relations are filtered out!\n",
    "        \n",
    "        res[etype] = pd.Series(sub[\"unit_ids\"].map(lambda v: len(v.split(\"|\"))))\n",
    "\n",
    "    two_samp_ttest(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T test between TP and FP\n",
      "\n",
      "\tWelch Two Sample t-test\n",
      "\n",
      "data:  0\n",
      "t = 3.3959, df = 340.99, p-value = 0.0007648\n",
      "alternative hypothesis: true difference in means is not equal to 0\n",
      "95 percent confidence interval:\n",
      " 0.1562751 0.5864964\n",
      "sample estimates:\n",
      "mean of x mean of y \n",
      " 1.845745  1.474359 \n",
      "\n",
      "\n",
      "-----------------------------\n",
      "T test between TP and FN\n",
      "\n",
      "\tWelch Two Sample t-test\n",
      "\n",
      "data:  0\n",
      "t = 3.8217, df = 121.59, p-value = 0.0002104\n",
      "alternative hypothesis: true difference in means is not equal to 0\n",
      "95 percent confidence interval:\n",
      " 0.2411333 0.7594470\n",
      "sample estimates:\n",
      "mean of x mean of y \n",
      " 1.845745  1.345455 \n",
      "\n",
      "\n",
      "-----------------------------\n",
      "T test between FP and FN\n",
      "\n",
      "\tWelch Two Sample t-test\n",
      "\n",
      "data:  0\n",
      "t = 0.99852, df = 114.69, p-value = 0.3201\n",
      "alternative hypothesis: true difference in means is not equal to 0\n",
      "95 percent confidence interval:\n",
      " -0.1268162  0.3846251\n",
      "sample estimates:\n",
      "mean of x mean of y \n",
      " 1.474359  1.345455 \n",
      "\n",
      "\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "ttest_freq(crowd_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the two sample t-test, it seems that there are significant differences in the number of sentence tasks between the true positives and both false positives and false negatives. There are no differences between the false positive and false negatives. From this I conclude that the null hypothesis is false, and that sentence-scoped relations with greater numbers of tasks are more likely to be classified by the crowd as true positives instead of as either type of error.\n",
    "\n",
    "Therefore it does seem that a lack of context is affecting crowd performance. When there are more sentences containing the relation pair, it is more likely to be classified properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title sentences\n",
    "\n",
    "**Hypothesis**: titles are confusing sentences which are more likely to state a tested hypothesis rather than the results of testing that hypothesis. Therefore we hypothesize that the errors are more likely to contain titles than the true positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ttest_title(summary):\n",
    "    temp = pd.merge(summary, sent_res[TRIPLE + [\"sentence_ids\"]], how = \"left\", on = TRIPLE)\n",
    "    \n",
    "    error_type = [\"TP\", \"FP\", \"FN\"]\n",
    "    vals = [(True, True), (False, True), (True, False)] # gold, predict\n",
    "    \n",
    "    chisqtest = robjects.r[\"chisq.test\"]\n",
    "    \n",
    "    res = dict()\n",
    "    for etype, val in zip(error_type, vals):\n",
    "        sub = temp.query(\"in_gold == {} and in_predict == {} and rel_origin == 'sent'\".format(\n",
    "            val[0], val[1])\n",
    "        ).dropna()\n",
    "\n",
    "        sub.loc[:, \"title\"] = sub.loc[:, \"sentence_ids\"].map(\n",
    "            lambda v:\n",
    "                sum(int(val == \"0\") for val in map(lambda f: f.split(\"_\")[1], v.split(\"|\")))\n",
    "        )\n",
    "        \n",
    "        res[etype] = sub[\"title\"].value_counts()[[0, 1]]\n",
    "\n",
    "    res = pd.DataFrame(res)\n",
    "    \n",
    "    print(chisqtest(res))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tPearson's Chi-squared test\n",
      "\n",
      "data:  structure(list(FN = structure(c(47L, 8L), .Dim = 2L), FP = structure(c(123L, 33L), .Dim = 2L), TP = structure(c(114L, 74L), .Dim = 2L)), .Names = c(\"FN\", \"FP\", \"TP\"), row.names = c(\"0\", \"1\"), class = \"data.frame\")\n",
      "X-squared = 20.116, df = 2, p-value = 4.285e-05\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FN</th>\n",
       "      <th>FP</th>\n",
       "      <th>TP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47</td>\n",
       "      <td>123</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FN   FP   TP\n",
       "0  47  123  114\n",
       "1   8   33   74"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_title(crowd_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a significant difference between the distributions, but it seems that this implies that the crowd does better on relations where they were showed the title as a sentence as well. However I think this really means that there were more tasks that the workers saw, which also makes it more likely that the tasks included the title as a sentence task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ttest_title2(summary):\n",
    "    temp = pd.merge(summary, sent_res[TRIPLE + [\"sentence_ids\"]], how = \"left\", on = TRIPLE)\n",
    "    \n",
    "    error_type = [\"TP\", \"FP\", \"FN\"]\n",
    "    vals = [(True, True), (False, True), (True, False)] # gold, predict\n",
    "    \n",
    "    res = dict()\n",
    "    for etype, val in zip(error_type, vals):\n",
    "        sub = temp.query(\"in_gold == {} and in_predict == {} and rel_origin == 'sent'\".format(\n",
    "            val[0], val[1])\n",
    "        ).dropna()\n",
    "        \n",
    "        res[etype] = pd.Series(sub.loc[:, \"sentence_ids\"].map(\n",
    "            lambda v:\n",
    "                sum(map(lambda f: int(int(f.split(\"_\")[1]) != 0), v.split(\"|\"))) / len(v.split(\"|\"))\n",
    "        ))\n",
    "        \n",
    "    two_samp_ttest(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T test between TP and FP\n",
      "\n",
      "\tWelch Two Sample t-test\n",
      "\n",
      "data:  0\n",
      "t = -2.2956, df = 333.88, p-value = 0.02232\n",
      "alternative hypothesis: true difference in means is not equal to 0\n",
      "95 percent confidence interval:\n",
      " -0.122151721 -0.009413758\n",
      "sample estimates:\n",
      "mean of x mean of y \n",
      "0.8157801 0.8815629 \n",
      "\n",
      "\n",
      "-----------------------------\n",
      "T test between TP and FN\n",
      "\n",
      "\tWelch Two Sample t-test\n",
      "\n",
      "data:  0\n",
      "t = -2.5979, df = 95.959, p-value = 0.01086\n",
      "alternative hypothesis: true difference in means is not equal to 0\n",
      "95 percent confidence interval:\n",
      " -0.1752987 -0.0234440\n",
      "sample estimates:\n",
      "mean of x mean of y \n",
      "0.8157801 0.9151515 \n",
      "\n",
      "\n",
      "-----------------------------\n",
      "T test between FP and FN\n",
      "\n",
      "\tWelch Two Sample t-test\n",
      "\n",
      "data:  0\n",
      "t = -0.8633, df = 100.77, p-value = 0.39\n",
      "alternative hypothesis: true difference in means is not equal to 0\n",
      "95 percent confidence interval:\n",
      " -0.11077254  0.04359527\n",
      "sample estimates:\n",
      "mean of x mean of y \n",
      "0.8815629 0.9151515 \n",
      "\n",
      "\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "ttest_title2(crowd_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These data tell us that the ratio of non-title sentences to total sentences is closer to 1 (only non-titles) in the false positives and false negatives compared to the true positives. This is the opposite of what we expect based on our original hypothesis that titles are confusing. I think that the titles are perhaps not as big of a deal as we thought, and that the more important factor is that fewer tasks = poorer performance, since there is a loss of context surrounding the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def expand_df(df):\n",
    "    res = []\n",
    "    for triple, group in df.groupby(TRIPLE):\n",
    "        temp = pd.Series(group.iloc[0][\"link\"]).to_frame()\n",
    "        \n",
    "        for col in group.columns:\n",
    "            temp.loc[:, col] = group.iloc[0][col]\n",
    "            \n",
    "        res.append(temp)\n",
    "        \n",
    "    return pd.concat(res).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fp_sent = crowd_summary.query(\"~in_gold and in_predict and rel_origin == 'sent'\").dropna()\n",
    "\n",
    "fp_sent_samp = fp_sent.sample(n = 35, random_state = RAND_KEY)\n",
    "\n",
    "fp_sent_samp.loc[:, \"link\"] = fp_sent_samp.loc[:, \"unit_ids\"].map(lambda v: v.split(\"|\"))\n",
    "\n",
    "fp_sent_samp = expand_df(fp_sent_samp)\n",
    "\n",
    "fp_sent_samp.loc[:, \"link\"] = fp_sent_samp.loc[:, \"link\"].map(\n",
    "    lambda v: \"https://crowdflower.com/jobs/767262/units/{}\".format(v)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        pmid   chemical_id    disease_id  \\\n",
      "0    1420650  MESH:D008094  MESH:D020258   \n",
      "1    2083961  MESH:D012293  MESH:D009325   \n",
      "2    2553470  MESH:D008094  MESH:D012640   \n",
      "3    2553470  MESH:D008094  MESH:D012640   \n",
      "4    2553470  MESH:D008094  MESH:D012640   \n",
      "5    2553470  MESH:D008094  MESH:D012640   \n",
      "6    2710809  MESH:C036432  MESH:D003680   \n",
      "7    3383127  MESH:D002945  MESH:D066126   \n",
      "8    3383127  MESH:D002945  MESH:D066126   \n",
      "9    3383127  MESH:D005472  MESH:D066126   \n",
      "10   3383127  MESH:D005472  MESH:D066126   \n",
      "11   3475563  MESH:D011241  MESH:D002177   \n",
      "12   3708328  MESH:D010862  MESH:D004833   \n",
      "13   6310832  MESH:D001379  MESH:D013203   \n",
      "14   6585590  MESH:D004317  MESH:D066126   \n",
      "15   6585590  MESH:D004317  MESH:D066126   \n",
      "16   6585590  MESH:D004317  MESH:D066126   \n",
      "17   6615679  MESH:D006221  MESH:D001919   \n",
      "18   6615679  MESH:D006221  MESH:D001919   \n",
      "19   8135424  MESH:D001569  MESH:D012640   \n",
      "20   9759693  MESH:D018170  MESH:D009203   \n",
      "21   9881641  MESH:D005905  MESH:D007022   \n",
      "22   9881641  MESH:D005905  MESH:D007022   \n",
      "23   9881641  MESH:D005905  MESH:D007022   \n",
      "24  11380496  MESH:D011441  MESH:D014657   \n",
      "25  11380496  MESH:D011441  MESH:D014657   \n",
      "26  11380496  MESH:D011441  MESH:D014657   \n",
      "27  11380496  MESH:D011441  MESH:D014657   \n",
      "28  12452552  MESH:D018967  MESH:D007676   \n",
      "29  12828076  MESH:D000082  MESH:D062787   \n",
      "30  12828076  MESH:D000082  MESH:D062787   \n",
      "31  16309808  MESH:D004298  MESH:D012148   \n",
      "32  16309808  MESH:D004298  MESH:D012148   \n",
      "33  16309808  MESH:D004298  MESH:D012148   \n",
      "34  17035713  MESH:C004656  MESH:D007674   \n",
      "35  17035713  MESH:C004656  MESH:D007674   \n",
      "36  19293073  MESH:D001241  MESH:D006470   \n",
      "37  19293073  MESH:D001241  MESH:D006470   \n",
      "38  19531695  MESH:D005424  MESH:D064420   \n",
      "39  19681452  MESH:D000431  MESH:D012131   \n",
      "40  19681452  MESH:D003042  MESH:D001145   \n",
      "41  19728177  MESH:D000082  MESH:D064420   \n",
      "42  20046642  MESH:D002330  MESH:D009336   \n",
      "43  20859899  MESH:D000809  MESH:D006947   \n",
      "44  21195121  MESH:D001120  MESH:D012640   \n",
      "45  22836123  MESH:D016559  MESH:D007674   \n",
      "46  22836123  MESH:D016559  MESH:D007674   \n",
      "47  24535067  MESH:D005045  MESH:D009069   \n",
      "48  24659727  MESH:D003520  MESH:D064420   \n",
      "49  24665854  MESH:D014635  MESH:D001927   \n",
      "50  24665854  MESH:D014635  MESH:D001927   \n",
      "51  24671324  MESH:C400082  MESH:D009503   \n",
      "52  24671324  MESH:D003907  MESH:D008258   \n",
      "53  24671324  MESH:D003907  MESH:D008258   \n",
      "54  24894748  MESH:C041359  MESH:D003221   \n",
      "55  25907210  MESH:D010755  MESH:D008175   \n",
      "\n",
      "                                                   link  \n",
      "0   https://crowdflower.com/jobs/767262/units/773932534  \n",
      "1   https://crowdflower.com/jobs/767262/units/773932609  \n",
      "2   https://crowdflower.com/jobs/767262/units/773932662  \n",
      "3   https://crowdflower.com/jobs/767262/units/773932665  \n",
      "4   https://crowdflower.com/jobs/767262/units/773932668  \n",
      "5   https://crowdflower.com/jobs/767262/units/773932669  \n",
      "6   https://crowdflower.com/jobs/767262/units/773932703  \n",
      "7   https://crowdflower.com/jobs/767262/units/773932850  \n",
      "8   https://crowdflower.com/jobs/767262/units/773932859  \n",
      "9   https://crowdflower.com/jobs/767262/units/773932852  \n",
      "10  https://crowdflower.com/jobs/767262/units/773932860  \n",
      "11  https://crowdflower.com/jobs/767262/units/773932874  \n",
      "12  https://crowdflower.com/jobs/767262/units/773932905  \n",
      "13  https://crowdflower.com/jobs/767262/units/773932997  \n",
      "14  https://crowdflower.com/jobs/767262/units/773933024  \n",
      "15  https://crowdflower.com/jobs/767262/units/773933025  \n",
      "16  https://crowdflower.com/jobs/767262/units/773933029  \n",
      "17  https://crowdflower.com/jobs/767262/units/773933037  \n",
      "18  https://crowdflower.com/jobs/767262/units/773933043  \n",
      "19  https://crowdflower.com/jobs/767262/units/773933223  \n",
      "20  https://crowdflower.com/jobs/767262/units/773933476  \n",
      "21  https://crowdflower.com/jobs/767262/units/773933487  \n",
      "22  https://crowdflower.com/jobs/767262/units/773933488  \n",
      "23  https://crowdflower.com/jobs/767262/units/773933490  \n",
      "24  https://crowdflower.com/jobs/767262/units/773933674  \n",
      "25  https://crowdflower.com/jobs/767262/units/773933676  \n",
      "26  https://crowdflower.com/jobs/767262/units/773933679  \n",
      "27  https://crowdflower.com/jobs/767262/units/773933683  \n",
      "28  https://crowdflower.com/jobs/767262/units/773933790  \n",
      "29  https://crowdflower.com/jobs/767262/units/773933843  \n",
      "30  https://crowdflower.com/jobs/767262/units/773933846  \n",
      "31  https://crowdflower.com/jobs/767262/units/773934019  \n",
      "32  https://crowdflower.com/jobs/767262/units/773934021  \n",
      "33  https://crowdflower.com/jobs/767262/units/773934032  \n",
      "34  https://crowdflower.com/jobs/767262/units/773934093  \n",
      "35  https://crowdflower.com/jobs/767262/units/773934095  \n",
      "36  https://crowdflower.com/jobs/767262/units/773934388  \n",
      "37  https://crowdflower.com/jobs/767262/units/773934394  \n",
      "38  https://crowdflower.com/jobs/767262/units/773934436  \n",
      "39  https://crowdflower.com/jobs/767262/units/773932374  \n",
      "40  https://crowdflower.com/jobs/767262/units/773932376  \n",
      "41  https://crowdflower.com/jobs/767262/units/773934465  \n",
      "42  https://crowdflower.com/jobs/767262/units/773934504  \n",
      "43  https://crowdflower.com/jobs/767262/units/773934583  \n",
      "44  https://crowdflower.com/jobs/767262/units/773934618  \n",
      "45  https://crowdflower.com/jobs/767262/units/773931706  \n",
      "46  https://crowdflower.com/jobs/767262/units/773931701  \n",
      "47  https://crowdflower.com/jobs/767262/units/773931893  \n",
      "48  https://crowdflower.com/jobs/767262/units/773931953  \n",
      "49  https://crowdflower.com/jobs/767262/units/773931962  \n",
      "50  https://crowdflower.com/jobs/767262/units/773931963  \n",
      "51  https://crowdflower.com/jobs/767262/units/773931977  \n",
      "52  https://crowdflower.com/jobs/767262/units/773931969  \n",
      "53  https://crowdflower.com/jobs/767262/units/773931976  \n",
      "54  https://crowdflower.com/jobs/767262/units/773932132  \n",
      "55  https://crowdflower.com/jobs/767262/units/773932250  \n"
     ]
    }
   ],
   "source": [
    "print(fp_sent_samp[TRIPLE + [\"link\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fp_abs = crowd_summary.query(\"~in_gold and in_predict and rel_origin == 'abs'\")\n",
    "fp_abs.loc[:, \"link\"] = fp_abs.loc[:, \"unit_ids\"].map(lambda v: \"http://crowdflower.com/jobs/767273/units/{}\".format(v))\n",
    "\n",
    "fp_abs_samp = fp_abs.sample(n = 20, random_state = RAND_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fn_abs = crowd_summary.query(\"in_gold and ~in_predict and rel_origin == 'abs'\")\n",
    "fn_abs.loc[:, \"link\"] = fn_abs.loc[:, \"unit_ids\"].map(lambda v: \"https://crowdflower.com/jobs/767273/units/{}\".format(v))\n",
    "\n",
    "fn_abs_samp = fn_abs.sample(n = 20, random_state = RAND_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tp_abs = crowd_summary.query(\"in_gold and in_predict and rel_origin == 'abs'\")\n",
    "tp_abs.loc[:, \"link\"] = tp_abs.loc[:, \"unit_ids\"].map(lambda v: \"https://crowdflower.com/jobs/767273/units/{}\".format(v))\n",
    "\n",
    "tp_abs_samp = tp_abs.sample(n = 20, random_state = RAND_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         pmid   chemical_id    disease_id  \\\n",
      "449  18165598  MESH:D002045  MESH:D007249   \n",
      "479   2931989  MESH:D015474  MESH:D010787   \n",
      "512  24928523  MESH:C400082  MESH:D009503   \n",
      "470  24928523  MESH:D003907  MESH:D013921   \n",
      "313  19139825  MESH:D019772  MESH:D009503   \n",
      "333   2358093  MESH:D003613  MESH:D015430   \n",
      "385  23892921  MESH:C467567  MESH:D020246   \n",
      "136    256433  MESH:D002228  MESH:D053099   \n",
      "441  24778426  MESH:D002945  MESH:D058186   \n",
      "397  11745287  MESH:D004317  MESH:D013921   \n",
      "448  24088636  MESH:C098010  MESH:C531767   \n",
      "194   8755612  MESH:D004054  MESH:D010911   \n",
      "250  23892921  MESH:D003907  MESH:D020246   \n",
      "114   6517710  MESH:D011796  MESH:D006332   \n",
      "347  19020118  MESH:D014148  MESH:D012640   \n",
      "187  24618873  MESH:D008614  MESH:D002524   \n",
      "356  24928523  MESH:C400082  MESH:D010523   \n",
      "186  12644816  MESH:D013792  MESH:D004244   \n",
      "202  11745287  MESH:D016190  MESH:D052016   \n",
      "595   9578276  MESH:C020731  MESH:D006473   \n",
      "\n",
      "                                                    link  \n",
      "449  https://crowdflower.com/jobs/767273/units/773938268  \n",
      "479  https://crowdflower.com/jobs/767273/units/773936917  \n",
      "512  https://crowdflower.com/jobs/767273/units/773936384  \n",
      "470  https://crowdflower.com/jobs/767273/units/773936377  \n",
      "313  https://crowdflower.com/jobs/767273/units/773938371  \n",
      "333  https://crowdflower.com/jobs/767273/units/773936832  \n",
      "385  https://crowdflower.com/jobs/767273/units/773936000  \n",
      "136  https://crowdflower.com/jobs/767273/units/773936603  \n",
      "441  https://crowdflower.com/jobs/767273/units/773936307  \n",
      "397  https://crowdflower.com/jobs/767273/units/773937709  \n",
      "448  https://crowdflower.com/jobs/767273/units/773936026  \n",
      "194  https://crowdflower.com/jobs/767273/units/773937504  \n",
      "250  https://crowdflower.com/jobs/767273/units/773935998  \n",
      "114  https://crowdflower.com/jobs/767273/units/773937256  \n",
      "347  https://crowdflower.com/jobs/767273/units/773938348  \n",
      "187  https://crowdflower.com/jobs/767273/units/773936185  \n",
      "356  https://crowdflower.com/jobs/767273/units/773936378  \n",
      "186  https://crowdflower.com/jobs/767273/units/773937839  \n",
      "202  https://crowdflower.com/jobs/767273/units/773937710  \n",
      "595  https://crowdflower.com/jobs/767273/units/773936532  \n"
     ]
    }
   ],
   "source": [
    "print(tp_abs_samp[TRIPLE + [\"link\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         pmid   chemical_id    disease_id  \\\n",
      "629   6806735  MESH:D002945  MESH:D005767   \n",
      "177   1837756  MESH:D005473  MESH:D003866   \n",
      "440  11745287  MESH:D016190  MESH:D060831   \n",
      "181   1837756  MESH:D005473  MESH:D011605   \n",
      "100  19392810  MESH:D008691  MESH:D058186   \n",
      "602  24614773  MESH:D014635  MESH:D001523   \n",
      "126    448423  MESH:D000614  MESH:D006973   \n",
      "206  24665854  MESH:D014635  MESH:D009422   \n",
      "407   8755612  MESH:D004054  MESH:D009369   \n",
      "478  24158386  MESH:D002945  MESH:D009503   \n",
      "180  24190587  MESH:D006854  MESH:D003866   \n",
      "477  17035713  MESH:D014343  MESH:D009336   \n",
      "628  12359538  MESH:D003042  MESH:D003643   \n",
      "566  11745287  MESH:D004317  MESH:D013280   \n",
      "19    3323259  MESH:D009553  MESH:D004487   \n",
      "30    7173007  MESH:D003973  MESH:D015746   \n",
      "278   3538855  MESH:D000617  MESH:D012769   \n",
      "205  19392810  MESH:D008691  MESH:D001037   \n",
      "399  20927253  MESH:D019386  MESH:D059352   \n",
      "174  19531695  MESH:D014859  MESH:D003693   \n",
      "\n",
      "                                                   link  \n",
      "629  http://crowdflower.com/jobs/767273/units/773937275  \n",
      "177  http://crowdflower.com/jobs/767273/units/773936787  \n",
      "440  http://crowdflower.com/jobs/767273/units/773937706  \n",
      "181  http://crowdflower.com/jobs/767273/units/773936785  \n",
      "100  http://crowdflower.com/jobs/767273/units/773938424  \n",
      "602  http://crowdflower.com/jobs/767273/units/773936176  \n",
      "126  http://crowdflower.com/jobs/767273/units/773936613  \n",
      "206  http://crowdflower.com/jobs/767273/units/773936214  \n",
      "407  http://crowdflower.com/jobs/767273/units/773937503  \n",
      "478  http://crowdflower.com/jobs/767273/units/773936067  \n",
      "180  http://crowdflower.com/jobs/767273/units/773936071  \n",
      "477  http://crowdflower.com/jobs/767273/units/773938113  \n",
      "628  http://crowdflower.com/jobs/767273/units/773937777  \n",
      "566  http://crowdflower.com/jobs/767273/units/773937712  \n",
      "19   http://crowdflower.com/jobs/767273/units/773936995  \n",
      "30   http://crowdflower.com/jobs/767273/units/773937299  \n",
      "278  http://crowdflower.com/jobs/767273/units/773937120  \n",
      "205  http://crowdflower.com/jobs/767273/units/773938423  \n",
      "399  http://crowdflower.com/jobs/767273/units/773938610  \n",
      "174  http://crowdflower.com/jobs/767273/units/773938476  \n"
     ]
    }
   ],
   "source": [
    "print(fp_abs_samp[TRIPLE + [\"link\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         pmid   chemical_id    disease_id  \\\n",
      "744  19549709  MESH:C107135  MESH:D013921   \n",
      "657  24842192  MESH:D007545  MESH:D018487   \n",
      "680  23892921  MESH:D003907  MESH:D010523   \n",
      "743  17356399  MESH:D003907  MESH:D001037   \n",
      "727   9428298  MESH:D000420  MESH:D001145   \n",
      "654   9071336  MESH:D017239  MESH:D009503   \n",
      "700  12119460  MESH:D005472  MESH:D007970   \n",
      "651  16723784  MESH:D011188  MESH:D016171   \n",
      "679    931801  MESH:D007612  MESH:D058186   \n",
      "655     48835  MESH:D011433  MESH:D006973   \n",
      "723  17356399  MESH:D014750  MESH:D001037   \n",
      "692  24928523  MESH:D013792  MESH:D010523   \n",
      "717  11745287  MESH:D016190  MESH:D003248   \n",
      "726  24675088  MESH:D004317  MESH:D005355   \n",
      "659  17356399  MESH:D003907  MESH:D006212   \n",
      "730   9578276  MESH:C020731  MESH:D014839   \n",
      "669  17879100  MESH:D007052  MESH:D058186   \n",
      "729  20859899  MESH:D011188  MESH:D001919   \n",
      "652  24928523  MESH:C400082  MESH:D013921   \n",
      "664   6106951  MESH:D010433  MESH:D012640   \n",
      "\n",
      "                                                    link  \n",
      "744  https://crowdflower.com/jobs/767273/units/773938486  \n",
      "657  https://crowdflower.com/jobs/767273/units/773936329  \n",
      "680  https://crowdflower.com/jobs/767273/units/773935999  \n",
      "743  https://crowdflower.com/jobs/767273/units/773938199  \n",
      "727  https://crowdflower.com/jobs/767273/units/773937562  \n",
      "654  https://crowdflower.com/jobs/767273/units/773937547  \n",
      "700  https://crowdflower.com/jobs/767273/units/773937756  \n",
      "651  https://crowdflower.com/jobs/767273/units/773938048  \n",
      "679  https://crowdflower.com/jobs/767273/units/773936667  \n",
      "655  https://crowdflower.com/jobs/767273/units/773936584  \n",
      "723  https://crowdflower.com/jobs/767273/units/773938200  \n",
      "692  https://crowdflower.com/jobs/767273/units/773936380  \n",
      "717  https://crowdflower.com/jobs/767273/units/773937714  \n",
      "726  https://crowdflower.com/jobs/767273/units/773936225  \n",
      "659  https://crowdflower.com/jobs/767273/units/773938201  \n",
      "730  https://crowdflower.com/jobs/767273/units/773936531  \n",
      "669  https://crowdflower.com/jobs/767273/units/773938253  \n",
      "729  https://crowdflower.com/jobs/767273/units/773938583  \n",
      "652  https://crowdflower.com/jobs/767273/units/773936386  \n",
      "664  https://crowdflower.com/jobs/767273/units/773937213  \n"
     ]
    }
   ],
   "source": [
    "print(fn_abs_samp[TRIPLE + [\"link\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept Venn diagrams\n",
    "\n",
    "What chemical and disease concepts were identified by each solution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# what were the MeSH ids of annotations for all papers in the testset?\n",
    "\n",
    "concepts = defaultdict(lambda: defaultdict(set))\n",
    "\n",
    "for method, dataset in zip([\"gold\", \"crowd\", \"befree\"], [eval_gold, crowd_full, befree_full]):\n",
    "    for pmid, paper in dataset.items():\n",
    "        for annot in paper.annotations:\n",
    "            concepts[method][annot.stype] |= set(annot.uid)\n",
    "            \n",
    "names = [\"gold\", \"crowd\", \"befree\"]\n",
    "for name in names:\n",
    "    for concept in [\"chemical\", \"disease\"]:\n",
    "        vals = {val.flat_repr for val in concepts[name][concept]}\n",
    "        print_to_file(\"temp/{}_{}.txt\".format(name, concept), format_set(vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analysis allows us to determine the performance for each of the NER methods. There may have been some concepts which the NER was never able to recognize properly.\n",
    "\n",
    "### Chemical MeSH ID overlap for all annotations\n",
    "<img src=\"../data/notebook/testset_chemical_id_venn.png\" style=\"width: 500px;\">\n",
    "\n",
    "### Disease MeSH ID overlap for all annotations\n",
    "<img src=\"../data/notebook/testset_disease_id_venn.png\" style=\"width: 500px;\">\n",
    "\n",
    "\n",
    "What we thankfully see is that the vast majority of the chemicals and diseases were identified by all three solutions. However, there exist small numbers of both chemicals and diseases for which the solutions could not come into agreement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the terms in each section of the venn diagrams above\n",
    "\n",
    "To look at the actual concepts, we can use word clouds where the size represents the frequency of the concept in the annotations of the testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mesh_name, hierarchy = load_mesh(\"hierarchy\")\n",
    "mesh_supp = load_mesh(\"supp\")\n",
    "\n",
    "assert set(mesh_name.keys()).isdisjoint(set(mesh_supp.keys()))\n",
    "# join the names together\n",
    "mesh_name.update(mesh_supp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_map_prep(concepts, reference):\n",
    "    \"\"\"Given a set of concepts, map them to their names\n",
    "    and output for word cloud generation.\n",
    "    \"\"\"\n",
    "    snippets = []\n",
    "    for pmid, paper in reference.items():\n",
    "        for annot in paper.annotations:\n",
    "            common = annot.uid & concepts\n",
    "            if len(common) > 0:\n",
    "                for concept in common:\n",
    "                    if concept.uid_type == \"MESH\":\n",
    "                        snippets.append(mesh_name[concept.uid])\n",
    "                    else:\n",
    "                        snippets.append(annot.text)\n",
    "                \n",
    "    return snippets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For UTexas, sometimes the MeSH ID doesn't match the stated semantic type. For example, in PMID 20009434, \"HD\" is identified as a disease but is assigned the id D008727 for methotrexate. When finding the frequencies, I am using the identifiers, and not verifying the semantic type. May need to adjust this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate word clouds with worditout, using the table feature for precise control over concepts\n",
    "# have to save to kemxjr@gmail.com account, then download (watch out for the watermark)\n",
    "\n",
    "common = concepts[\"befree\"][\"chemical\"] & concepts[\"crowd\"][\"chemical\"] - concepts[\"gold\"][\"chemical\"]\n",
    "\n",
    "res = word_map_prep(common, crowd_full)\n",
    "\n",
    "counts = pd.DataFrame(pd.Series(res).value_counts())\n",
    "counts.to_csv(\"temp/counts.txt\", sep = \":\", index = True, header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Venn diagram of relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# format triples to make venn diagrams using:\n",
    "# bioinformatics.lu/venn.php\n",
    "# bioinfogp.cnb.csic.es/tools/venny\n",
    "        \n",
    "names = [\"gold\", \"crowd\", \"befree\"]\n",
    "data = [gold_triples, crowd_trip, befree_trip]\n",
    "    \n",
    "for fname, dataset in zip(names, data):\n",
    "    print_to_file(\"{}.txt\".format(fname), format_set(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gold, crowd, and texas only\n",
    "<img src=\"../data/notebook/better_testset_cross_validation.png\" style=\"width: 500px;\">\n",
    "\n",
    "### Gold, crowd, texas, and befree\n",
    "<img src=\"../data/notebook/testset_all_cross_validation.png\" style=\"width: 500px;\">\n",
    "\n",
    "### Overlap using relations which had perfect annotations w.r.t. gold\n",
    "<img src=\"../data/notebook/testset_all_no_ner_cross_validation.png\", style=\"width: 500px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percent relations in each subset with ids missing in gold standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def missing_stats(triples, reference):\n",
    "    df = make_df(triples)\n",
    "    df = check_exists(df, reference)\n",
    "    \n",
    "    ans = dict()\n",
    "    for col in [\"chem\", \"dise\"]:\n",
    "        cname = \"{}_exists\".format(col)\n",
    "        norm = df[cname].value_counts(normalize = True)\n",
    "        res = norm.loc[False] if False in norm.keys() else 0\n",
    "        ans[col] = res * 100\n",
    "        \n",
    "    ans[\"any\"] = len(df.query(\"~chem_exists or ~dise_exists\")) / len(df) * 100\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract vs sentence relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rel_origin(triple, paper):\n",
    "    relation = Relation(paper.pmid, triple[1], triple[2], flat = False)\n",
    "\n",
    "    rename = {\n",
    "        \"CID\": \"CID\",\n",
    "        \"sentence_non_CID\": \"sent\",\n",
    "        \"not_sentence_bound\": \"abs\"\n",
    "    }\n",
    "    \n",
    "    ans = []\n",
    "    for key, val in paper.poss_relations.items():\n",
    "        value = converter(paper.pmid, val)\n",
    "        if relation in value:\n",
    "            ans.append(rename[key])\n",
    "\n",
    "    return ans\n",
    "\n",
    "def triple_origin(triples, reference, return_res = False):\n",
    "    lengths = []\n",
    "    vals = []\n",
    "    for trip in triples:\n",
    "        pmid = trip[0]\n",
    "        res = rel_origin(trip, reference[pmid])\n",
    "        \n",
    "        vals += res\n",
    "        lengths.append(len(res))\n",
    "        \n",
    "    if return_res:\n",
    "        return pd.Series(vals).value_counts(normalize = True) * 100    \n",
    "        \n",
    "    print(\"For this triple set of length {}\".format(len(triples)))\n",
    "    print(\"Origin group lengths:\")\n",
    "    print(pd.Series(lengths).value_counts())\n",
    "    print()\n",
    "    print(\"Origin counts:\")\n",
    "    print(pd.Series(vals).value_counts(normalize = True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relation co-occurrence for each dataset separately\n",
    "\n",
    "For each technique where did the predicted relations come from?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>abs</th>\n",
       "      <th>CID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gold</th>\n",
       "      <td>54.562384</td>\n",
       "      <td>29.888268</td>\n",
       "      <td>15.549348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crowd</th>\n",
       "      <td>52.848885</td>\n",
       "      <td>31.131296</td>\n",
       "      <td>16.019818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>befree</th>\n",
       "      <td>50.797546</td>\n",
       "      <td>30.552147</td>\n",
       "      <td>18.650307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sent        abs        CID\n",
       "gold    54.562384  29.888268  15.549348\n",
       "crowd   52.848885  31.131296  16.019818\n",
       "befree  50.797546  30.552147  18.650307"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVMAAAG8CAYAAABjWUYjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb8af9cba20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = triple_origin(gold_triples, eval_gold, return_res = True)\n",
    "b = triple_origin(crowd_trip, crowd_full, return_res = True)\n",
    "c = triple_origin(befree_trip, befree_full, return_res = True)\n",
    "\n",
    "rel_origins = pd.DataFrame([a, b, c], index = [\"gold\", \"crowd\", \"befree\"])\n",
    "\n",
    "ax = rel_origins.T.plot(kind = \"bar\", figsize = (5, 7),\n",
    "                    title = \"Origin for gold standard, crowd, and texas relations\")\n",
    "ax.set_ylabel(\"Percent relations\")\n",
    "rel_origins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make one comprehensive dataframe for easier analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_check_exists(df, reference, ref_name):\n",
    "    triple = [\"pmid\", \"chemical_id\", \"disease_id\"]\n",
    "    for col in [\"chemical\", \"disease\"]:\n",
    "        col_name = \"{0}_in_{1}\".format(col[:4], ref_name)\n",
    "        \n",
    "        df.loc[:, col_name] = df[triple].apply(\n",
    "            lambda row: has_concept(reference[int(row[\"pmid\"])], row[\"{}_id\".format(col)]), axis = 1)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def single_triple_origin(pmid, chemical_id, disease_id, reference):\n",
    "    triple = (pmid, chemical_id, disease_id)\n",
    "    \n",
    "    res = rel_origin(triple, reference[pmid])\n",
    "    return \"|\".join(sorted(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def num_times_cooccur(pmid, chemical_id, disease_id, rel_origin, reference):\n",
    "    \"\"\"Given a relation triple and a reference Paper object,\n",
    "    determines how many times the relation cooccurs (a sentence\n",
    "    if CID or sentence, and 1 otherwise (abstract)).\n",
    "    \"\"\"\n",
    "    if not rel_origin:\n",
    "        # was not found using this solution\n",
    "        return np.nan\n",
    "    \n",
    "    if rel_origin == \"abs\":\n",
    "        return 1\n",
    "    \n",
    "    paper = reference[pmid]\n",
    "    \n",
    "    rel = Relation(pmid, chemical_id, disease_id, flat = False)\n",
    "        \n",
    "    ans = 0\n",
    "    for sentence in paper.sentences:\n",
    "        all_rels = sentence.poss_relations[rel_origin == \"CID\"]\n",
    "        all_rels = [Relation(pmid, chem_set, dise_set) for chem_set, dise_set in all_rels]\n",
    "        ans += int(rel in all_rels)\n",
    "        \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creating one comprehensive dataframe for easy result aggregation and querying\n",
    "\n",
    "all_trips = gold_triples | crowd_trip | befree_trip\n",
    "all_df = make_df(all_trips)\n",
    "\n",
    "triple = [\"pmid\", \"chemical_id\", \"disease_id\"]\n",
    "\n",
    "# which triple was found by which solution?\n",
    "for name, reference in zip([\"gold\", \"crowd\", \"befree\"], [gold_triples, crowd_trip, befree_trip]):\n",
    "    all_df.loc[:, \"in_{}\".format(name)] = all_df.loc[:, triple].apply(\n",
    "        lambda row: (row[\"pmid\"], row[\"chemical_id\"], row[\"disease_id\"]) in reference,\n",
    "        axis = 1\n",
    "    )\n",
    "    \n",
    "# were the concepts present in each dataset's concepts?\n",
    "for name, reference in zip([\"gold\", \"crowd\", \"befree\"], [eval_gold, crowd_full, befree_full]):\n",
    "    all_df = new_check_exists(all_df, reference, name)\n",
    "\n",
    "# was the relation sentence bound or abstract level?\n",
    "for name, reference in zip([\"gold\", \"crowd\", \"befree\"], [eval_gold, crowd_full, befree_full]):\n",
    "    colname = \"rel_orig_{}\".format(name)\n",
    "    \n",
    "    all_df.loc[:, colname] = all_df.loc[:, triple].apply(\n",
    "        lambda row: single_triple_origin(row[\"pmid\"], row[\"chemical_id\"], row[\"disease_id\"], reference),\n",
    "        axis = 1\n",
    "    )\n",
    "    \n",
    "# how many times did the two concepts cooccur within the paper?    \n",
    "for name, reference in zip([\"gold\", \"crowd\", \"befree\"], [eval_gold, crowd_full, befree_full]):    \n",
    "    colname = \"cooccur_{}\".format(name)\n",
    "    rel_orig = \"rel_orig_{}\".format(name)\n",
    "    \n",
    "    all_df.loc[:, colname] = all_df.loc[:, triple + [rel_orig]].apply(\n",
    "        lambda row: num_times_cooccur(row[\"pmid\"], row[\"chemical_id\"], row[\"disease_id\"],\n",
    "                                     row[rel_orig], reference),\n",
    "        axis = 1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>chemical_id</th>\n",
       "      <th>disease_id</th>\n",
       "      <th>in_gold</th>\n",
       "      <th>in_crowd</th>\n",
       "      <th>in_befree</th>\n",
       "      <th>chem_in_gold</th>\n",
       "      <th>dise_in_gold</th>\n",
       "      <th>chem_in_crowd</th>\n",
       "      <th>dise_in_crowd</th>\n",
       "      <th>chem_in_befree</th>\n",
       "      <th>dise_in_befree</th>\n",
       "      <th>rel_orig_gold</th>\n",
       "      <th>rel_orig_crowd</th>\n",
       "      <th>rel_orig_befree</th>\n",
       "      <th>cooccur_gold</th>\n",
       "      <th>cooccur_crowd</th>\n",
       "      <th>cooccur_befree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3109094</td>\n",
       "      <td>MESH:D003520</td>\n",
       "      <td>MESH:D001745</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>CID</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4082192</td>\n",
       "      <td>MESH:D000082</td>\n",
       "      <td>MESH:D009956</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>sent</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3975902</td>\n",
       "      <td>MESH:D007649</td>\n",
       "      <td>MESH:D009202</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>abs</td>\n",
       "      <td>abs</td>\n",
       "      <td>abs</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8392553</td>\n",
       "      <td>MESH:D004837</td>\n",
       "      <td>MESH:D002545</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>sent</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24067251</td>\n",
       "      <td>MESH:C096918</td>\n",
       "      <td>MESH:D007674</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>abs</td>\n",
       "      <td>sent</td>\n",
       "      <td>sent</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pmid   chemical_id    disease_id in_gold in_crowd in_befree  \\\n",
       "0   3109094  MESH:D003520  MESH:D001745    True    False     False   \n",
       "1   4082192  MESH:D000082  MESH:D009956   False     True     False   \n",
       "2   3975902  MESH:D007649  MESH:D009202   False    False      True   \n",
       "3   8392553  MESH:D004837  MESH:D002545   False     True     False   \n",
       "4  24067251  MESH:C096918  MESH:D007674   False     True      True   \n",
       "\n",
       "  chem_in_gold dise_in_gold chem_in_crowd dise_in_crowd chem_in_befree  \\\n",
       "0         True         True          True         False           True   \n",
       "1         True        False          True          True           True   \n",
       "2         True         True          True          True           True   \n",
       "3         True        False          True          True           True   \n",
       "4         True         True          True          True           True   \n",
       "\n",
       "  dise_in_befree rel_orig_gold rel_orig_crowd rel_orig_befree  cooccur_gold  \\\n",
       "0          False           CID                                            1   \n",
       "1          False                         sent                           NaN   \n",
       "2           True           abs            abs             abs             1   \n",
       "3          False                         sent                           NaN   \n",
       "4           True           abs           sent            sent             1   \n",
       "\n",
       "   cooccur_crowd  cooccur_befree  \n",
       "0            NaN             NaN  \n",
       "1              1             NaN  \n",
       "2              1               1  \n",
       "3              2             NaN  \n",
       "4              1               1  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many of the sentence and abstract relations did each method find? What was the precision?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def found_stats():\n",
    "    recall = dict()\n",
    "    precision = dict()\n",
    "    for method in [\"crowd\", \"befree\"]:\n",
    "        rec_temp = dict()\n",
    "        pre_temp = dict()\n",
    "        for rel_type in [\"CID\", \"sent\", \"abs\"]:\n",
    "            sub = all_df.query(\"in_gold and rel_orig_gold == '{}'\".format(rel_type))\n",
    "            total = len(sub)\n",
    "            found = len(sub.query(\"in_{}\".format(method)))\n",
    "            \n",
    "            guesses = all_df.query(\"in_{0} and rel_orig_{0} == '{1}'\".format(method, rel_type))\n",
    "            guesses = len(guesses)\n",
    "            \n",
    "            rec_temp[rel_type] = found / total * 100\n",
    "            pre_temp[rel_type] = found / guesses * 100\n",
    "            \n",
    "        recall[method] = rec_temp\n",
    "        precision[method] = pre_temp\n",
    "        \n",
    "    print(recall)\n",
    "        \n",
    "    return (pd.DataFrame(recall), pd.DataFrame(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'befree': {'sent': 39.20552677029361, 'abs': 21.518987341772153, 'CID': 66.87116564417178}, 'crowd': {'sent': 54.0587219343696, 'abs': 36.392405063291136, 'CID': 87.11656441717791}}\n"
     ]
    }
   ],
   "source": [
    "recall, precision = found_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>befree</th>\n",
       "      <th>crowd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CID</th>\n",
       "      <td>66.871166</td>\n",
       "      <td>87.116564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs</th>\n",
       "      <td>21.518987</td>\n",
       "      <td>36.392405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent</th>\n",
       "      <td>39.205527</td>\n",
       "      <td>54.058722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         befree      crowd\n",
       "CID   66.871166  87.116564\n",
       "abs   21.518987  36.392405\n",
       "sent  39.205527  54.058722"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>befree</th>\n",
       "      <th>crowd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CID</th>\n",
       "      <td>66.871166</td>\n",
       "      <td>87.116564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs</th>\n",
       "      <td>21.518987</td>\n",
       "      <td>36.392405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent</th>\n",
       "      <td>39.205527</td>\n",
       "      <td>54.058722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         befree      crowd\n",
       "CID   66.871166  87.116564\n",
       "abs   21.518987  36.392405\n",
       "sent  39.205527  54.058722"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ax = recall.plot(kind = \"bar\", figsize = (4, 5),\n",
    "        title = \"Gold relation recall by relation category\")\n",
    "\n",
    "ax.set_ylabel(\"Percent gold relations found\")\n",
    "\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = precision.plot(kind = \"bar\", figsize = (4, 5),\n",
    "        title = \"Gold relation precision by relation category\")\n",
    "\n",
    "ax.set_ylabel(\"Precision of guesses\")\n",
    "\n",
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two solutions found similar fractions of CID and abstract relations. The Texas solution found more sentence relations, but their predictions also contained more sentence-level relations overall. This is bad.. We are showing in different ways why the automated solution was better than our crowd.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Of the relations which neither technique got, why did we not get them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unfound = gold_triples - crowd_trip - befree_trip\n",
    "\n",
    "crowd_miss = missing_stats(unfound, crowd_full)\n",
    "ut_miss = missing_stats(unfound, befree_full)\n",
    "\n",
    "missing = pd.DataFrame([crowd_miss, ut_miss], index = [\"crowd\", \"befree\"])\n",
    "\n",
    "ax = missing.T.plot(kind = \"bar\", figsize = (7, 7),\n",
    "             title = \"Percent of unfound relations using unknown identifiers\")\n",
    "\n",
    "ax.set_ylabel(\"Percent of concepts in gold relations with unknown IDs\")\n",
    "missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So a vast majority of the missed gold relations were unfound mainly because they used an ID which did not appear anywhere in the NER output for that paper.\n",
    "\n",
    "For the relations which were indexed, what was the scope of the relation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unfound = all_df.query(\"in_gold and ~in_crowd and ~in_texas\")\n",
    "crowd_miss = unfound.query(\"chem_in_crowd and dise_in_crowd\")[\"rel_orig_gold\"].value_counts(normalize = True) * 100\n",
    "texas_miss = unfound.query(\"chem_in_texas and dise_in_texas\")[\"rel_orig_gold\"].value_counts(normalize = True) * 100\n",
    "\n",
    "missed = pd.DataFrame([crowd_miss, texas_miss], index = [\"crowd\", \"texas\"])\n",
    "\n",
    "ax = missed.T.plot(kind = \"bar\", figsize = (6, 6),\n",
    "                title = \"Relation scope for indexable but missed gold relations\")\n",
    "\n",
    "ax.set_ylabel(\"Percent of gold relations\")\n",
    "missed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both solutions, at least half of the indexable, missed gold relations were abstract scoped, and therefore likely harder to determine correctly. Texas's solution seems to have a slight bias for the abstract scoped relations, but the different is probably not significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the relations which were false positives, what percentage were due to NER errors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crowd_only = crowd_trip - gold_triples - befree_trip\n",
    "befree_only = befree_trip - gold_triples - crowd_trip\n",
    "crowd_befree = crowd_trip & befree_trip - gold_triples\n",
    "\n",
    "cr_miss = missing_stats(crowd_only, eval_gold)\n",
    "befree_miss = missing_stats(befree_only, eval_gold)\n",
    "both_miss = missing_stats(crowd_befree, eval_gold)\n",
    "\n",
    "missing = pd.DataFrame([cr_miss, befree_miss, both_miss], index = [\"crowd_only\", \"befree_only\", \"crowd_and_befree\"])\n",
    "\n",
    "ax = missing.T.plot(kind = \"bar\", figsize = (7, 7),\n",
    "                   title = \"Percent of false positive relations\\nusing IDs not included in gold standard\")\n",
    "ax.set_ylabel(\"Percent of relations using IDs nonexistent in gold\")\n",
    "missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A significant number of the false positives for both solutions separately were a result of using MeSH IDs which did not occur in the gold standard. However, the false positives identified by both solutions have a significantly lower rate of NER error, suggesting that these were likely to be real relations which the gold does not include for some reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the gold relations which one solution got but the other missed, why did each solution miss the relations and what kind of relations are they?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crowd_gold = all_df.query(\"in_gold and in_crowd and ~in_befree\")\n",
    "befree_gold = all_df.query(\"in_gold and in_befree and ~in_crowd\")\n",
    "\n",
    "crowd_gold = get_triples(crowd_gold)\n",
    "befree_gold = get_triples(befree_gold)\n",
    "\n",
    "# unindexable by texas, and by crowd\n",
    "miss_by_befree = missing_stats(crowd_gold, befree_full)\n",
    "miss_by_cr = missing_stats(befree_gold, crowd_full)\n",
    "\n",
    "missing = pd.DataFrame([miss_by_befree, miss_by_cr],\n",
    "                       index = [\"crowd_rels_missed_by_befree\", \"texas_rels_missed_by_crowd\"])\n",
    "ax = missing.plot(kind = \"bar\", figsize = (7, 7),\n",
    "                 title = \"Percentage relations found by one solution but\\n\"\n",
    "                 \"missing in the other due to unindexed concept IDs\")\n",
    "ax.set_ylabel(\"Percent of relations using IDs\\nnot indexable by other method\")\n",
    "ax.set_xticklabels(missing.index, rotation = 0)\n",
    "missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the graph above, we see that the relations which our crowd got but Texas didn't only contained a small subset where the relations contained IDs which were not indexed by Texas. In contrast, a lot of the relations (40%) that Texas got but the crowd didn't were because the IDs were never found, not because the crowd is bad at relation extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
