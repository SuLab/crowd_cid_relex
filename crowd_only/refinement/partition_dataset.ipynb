{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting data for additional CrowdFlower tests\n",
    "\n",
    "Tong Shu Li<br>\n",
    "Created on: 2015-12-15<br>\n",
    "Last updated: 2015-12-15\n",
    "\n",
    "We are going to try and push the crowd's performance to the maximum possible before moving on from the BioCreative dataset.\n",
    "\n",
    "First we will subset data to use as our testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seed should be the integer 1916771088044731497"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# seed number generated by using hash() with a random string multiple times\n",
    "random.seed(a = 1916771088044731497, version = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from src.lingpipe.file_util import read_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab the set of all available PMIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pmid(line):\n",
    "    \"\"\"Parse the PMID out of a line of a PubTator file.\"\"\"\n",
    "    v = line.find(\"\\t\")\n",
    "    pos = v if v != -1 else line.find(\"|\")\n",
    "    return int(line[: pos])\n",
    "\n",
    "def get_pmids(fname):\n",
    "    return set([get_pmid(line) for line in read_file(fname) if line])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fname = os.path.join(\"..\", \"data\", \"gold_standard\", \"CDR_DevelopmentSet.txt\")\n",
    "devset_pmids = get_pmids(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(devset_pmids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = os.path.join(\"..\", \"data\", \"gold_standard\", \"CDR_TrainingSet.txt\")\n",
    "train_pmids = get_pmids(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_pmids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = os.path.join(\"..\", \"data\", \"devset_100_test\", \"processed_CDR_devset.txt\")\n",
    "dev100_pmids = get_pmids(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev100_pmids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a big summary dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.DataFrame({\n",
    "        \"pmid\": list(train_pmids),\n",
    "        \"dataset\": [\"train\"] * 500\n",
    "    })\n",
    "\n",
    "dev = pd.DataFrame({\n",
    "        \"pmid\": list(devset_pmids),\n",
    "        \"dataset\": [\"dev\"] * 500\n",
    "    })\n",
    "\n",
    "papers = pd.concat([train, dev]).sort(\"pmid\").reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for overlap between test questions and actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abs_data = pd.read_csv(\"../data/crowdflower/data_for_abs_task_job_771158.tsv\", sep = '\\t')\n",
    "abs_tq = set(abs_data.query(\"_golden == True\")[\"pmid\"].map(lambda v: int(v)))\n",
    "\n",
    "sent_data = pd.read_csv(\"../data/crowdflower/data_for_sent_task_job_771159.tsv\", sep = '\\t')\n",
    "sent_tq = set(sent_data.query(\"_golden == True\")[\"pmid\"].map(lambda v: int(v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115 261\n"
     ]
    }
   ],
   "source": [
    "print(len(abs_tq), len(sent_tq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add info to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "papers[\"used_as_sent_tq\"] = papers.loc[:, \"pmid\"].map(lambda v: v in sent_tq)\n",
    "papers[\"used_as_abs_tq\"] = papers.loc[:, \"pmid\"].map(lambda v: v in abs_tq)\n",
    "\n",
    "papers[\"used_as_devset_100\"] = papers.loc[:, \"pmid\"].map(lambda v: v in dev100_pmids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old test question dataset origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(papers.query(\"used_as_sent_tq & dataset == 'train'\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(papers.query(\"used_as_sent_tq & dataset == 'dev'\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(papers.query(\"used_as_sent_tq & used_as_devset_100\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(papers.query(\"used_as_abs_tq & dataset == 'train'\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(papers.query(\"used_as_abs_tq & dataset == 'dev'\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(papers.query(\"used_as_abs_tq & used_as_devset_100\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wasn't careful enough during the previous test question selection process, which used some abstracts as both test questions and as part of the actual data. This time I will be more careful and ensure that the two use separate sets of abstracts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing data\n",
    "\n",
    "We will take at least 100 abstracts from the training set to use as the data that we want our workers to work on. Unfortunately this won't let us compare directly with the previous development 100 dataset since there are overlaps with the actual data.\n",
    "\n",
    "We will also \"reserve\" another 200 abstracts (100 from training, 150 from development) from which we will not use to make test questions, so that if we want to scale up larger with the same number of test questions, then we can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unseen_train = set(papers.query(\"~used_as_abs_tq & ~used_as_sent_tq & dataset == 'train'\")[\"pmid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "405"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unseen_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unseen_dev = set(papers.query(\"~used_as_abs_tq & ~used_as_sent_tq & ~used_as_devset_100 & dataset == 'dev'\")[\"pmid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unseen_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have 405 abstracts from the training set and 211 abstracts from the development which the crowd have never seen before (either as a task or as a test question). We will choose 200 abstracts from each of the training and development sets as our official data that we will use to evaluate our crowd's performance. The rest of the seen data will be used for test questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_train = set(random.sample(unseen_train, 200))\n",
    "hidden_dev = set(random.sample(unseen_dev, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hidden_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hidden_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "small_hidden_train = set(random.sample(hidden_train, 50))\n",
    "small_hidden_dev = set(random.sample(hidden_dev, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the 400 abstracts which will never be used for test question purposes. We will use these to filter the original data to a new file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add information back to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 200 papers from each dataset (training, development) that the crowd has never\n",
    "# seen which we will use for performance evaluation\n",
    "papers[\"new_unseen_train\"] = papers.loc[:, \"pmid\"].map(lambda v: v in hidden_train)\n",
    "papers[\"new_unseen_dev\"] = papers.loc[:, \"pmid\"].map(lambda v: v in hidden_dev)\n",
    "\n",
    "# a smaller subset of 100 total (50 dev, 50 train) papers that the crowd\n",
    "# has never seen which we will use for our development iterations (too expensive to use larger sets)\n",
    "papers[\"new_unseen_small_train\"] = papers.loc[:, \"pmid\"].map(lambda v: v in small_hidden_train)\n",
    "papers[\"new_unseen_small_dev\"] = papers.loc[:, \"pmid\"].map(lambda v: v in small_hidden_dev)\n",
    "\n",
    "# the rest of the papers will be used to create test questions\n",
    "papers[\"for_test_ques_use\"] = ~(papers.loc[:, \"new_unseen_train\"] | papers.loc[:, \"new_unseen_dev\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>pmid</th>\n",
       "      <th>used_as_sent_tq</th>\n",
       "      <th>used_as_abs_tq</th>\n",
       "      <th>used_as_devset_100</th>\n",
       "      <th>new_unseen_train</th>\n",
       "      <th>new_unseen_dev</th>\n",
       "      <th>new_unseen_small_train</th>\n",
       "      <th>new_unseen_small_dev</th>\n",
       "      <th>for_test_ques_use</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dev</td>\n",
       "      <td>2004</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>26094</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dev</td>\n",
       "      <td>28952</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dev</td>\n",
       "      <td>33969</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dev</td>\n",
       "      <td>48362</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset   pmid used_as_sent_tq used_as_abs_tq used_as_devset_100  \\\n",
       "0     dev   2004           False          False              False   \n",
       "1   train  26094           False          False              False   \n",
       "2     dev  28952           False          False              False   \n",
       "3     dev  33969            True          False               True   \n",
       "4     dev  48362           False          False              False   \n",
       "\n",
       "  new_unseen_train new_unseen_dev new_unseen_small_train new_unseen_small_dev  \\\n",
       "0            False           True                  False                False   \n",
       "1             True          False                  False                False   \n",
       "2            False           True                  False                False   \n",
       "3            False          False                  False                False   \n",
       "4            False           True                  False                 True   \n",
       "\n",
       "  for_test_ques_use  \n",
       "0             False  \n",
       "1             False  \n",
       "2             False  \n",
       "3              True  \n",
       "4             False  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "papers.to_csv(\"../data/refinement/dataset_summary.tsv\", sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing data to new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pipe_and_filter(pmids, infile, outfile):\n",
    "    \"\"\"Redirect a subset of the gold standard to a new file.\"\"\"\n",
    "    skipped = True\n",
    "    with open(outfile, \"w\") as fout:\n",
    "        for line in read_file(infile):\n",
    "            if not line and not skipped:\n",
    "                fout.write(\"\\n\")\n",
    "                skipped = True\n",
    "            elif line and (get_pmid(line) in pmids):\n",
    "                fout.write(\"{}\\n\".format(line))\n",
    "                skipped = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing all the unseen abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "infile = os.path.join(\"..\", \"data\", \"gold_standard\", \"CDR_TrainingSet.txt\")\n",
    "outfile = os.path.join(\"..\", \"data\", \"refinement\", \"CDR_train_200_subset.txt\")\n",
    "\n",
    "pipe_and_filter(hidden_train, infile, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "infile = os.path.join(\"..\", \"data\", \"gold_standard\", \"CDR_DevelopmentSet.txt\")\n",
    "outfile = os.path.join(\"..\", \"data\", \"refinement\", \"CDR_dev_200_subset.txt\")\n",
    "\n",
    "pipe_and_filter(hidden_dev, infile, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "infile = os.path.join(\"..\", \"data\", \"gold_standard\", \"CDR_TrainingSet.txt\")\n",
    "outfile = os.path.join(\"..\", \"data\", \"refinement\", \"CDR_train_50_subset.txt\")\n",
    "\n",
    "pipe_and_filter(small_hidden_train, infile, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "infile = os.path.join(\"..\", \"data\", \"gold_standard\", \"CDR_DevelopmentSet.txt\")\n",
    "outfile = os.path.join(\"..\", \"data\", \"refinement\", \"CDR_dev_50_subset.txt\")\n",
    "\n",
    "pipe_and_filter(small_hidden_dev, infile, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing the abstracts for use as test questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "infile = os.path.join(\"..\", \"data\", \"gold_standard\", \"CDR_TrainingSet.txt\")\n",
    "outfile = os.path.join(\"..\", \"data\", \"refinement\", \"CDR_train_for_test_ques.txt\")\n",
    "\n",
    "pmids = set(papers.query(\"dataset == 'train' & for_test_ques_use\")[\"pmid\"])\n",
    "\n",
    "pipe_and_filter(pmids, infile, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "infile = os.path.join(\"..\", \"data\", \"gold_standard\", \"CDR_DevelopmentSet.txt\")\n",
    "outfile = os.path.join(\"..\", \"data\", \"refinement\", \"CDR_dev_for_test_ques.txt\")\n",
    "\n",
    "pmids = set(papers.query(\"dataset == 'dev' & for_test_ques_use\")[\"pmid\"])\n",
    "\n",
    "pipe_and_filter(pmids, infile, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all of our data partitioned into disjoint sets which we will use for actual performance evaluation and test question creation purposes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
